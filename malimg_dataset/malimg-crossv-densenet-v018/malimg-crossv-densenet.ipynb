{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Convolutional Neural Network","metadata":{}},{"cell_type":"markdown","source":"**Notes about this specific notebook**\n\nUses rgb, 64x64 images with ReLU activation and Adam optimizer. No class or sample specific weights are used. Same as cnn-kaggle-v021","metadata":{}},{"cell_type":"markdown","source":"# Changeable Parameters","metadata":{}},{"cell_type":"markdown","source":"_____________________________________________________________________","metadata":{}},{"cell_type":"code","source":"# Image size (height x width)\nih = 64\niw = 64\n\n# Grayscale or RGB\nch = 'rgb'\n\n# Batch size\nbatch_size = 40000\n\n# Number of epochs\nepoch_t = 35\n\n# Where computation is performed: Kaggle (0) or Local (1)\ncenv = 0\n\n# Division of the training vs. test set \ntest_size = 0.3\n\n# number of folds\nn_folds = 10","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:54:20.45658Z","iopub.status.busy":"2022-04-04T12:54:20.456317Z","iopub.status.idle":"2022-04-04T12:54:20.461217Z","shell.execute_reply":"2022-04-04T12:54:20.460255Z","shell.execute_reply.started":"2022-04-04T12:54:20.456552Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_____________________________________________________________________","metadata":{}},{"cell_type":"code","source":"# To check whether the right environment has been selected\nif cenv == 0:\n    print(\"Computation environment: Kaggle\")\nif cenv == 1:\n    print(\"Computation environment: Local\")","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:54:20.758272Z","iopub.status.busy":"2022-04-04T12:54:20.758045Z","iopub.status.idle":"2022-04-04T12:54:20.762812Z","shell.execute_reply":"2022-04-04T12:54:20.762096Z","shell.execute_reply.started":"2022-04-04T12:54:20.758247Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import the necessary libraries","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras import datasets, layers, models, losses, Model\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.utils import class_weight\nfrom sklearn import metrics\nimport sys\nimport os\nfrom math import log\nimport scipy as sp\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-04T12:54:20.927275Z","iopub.status.busy":"2022-04-04T12:54:20.925475Z","iopub.status.idle":"2022-04-04T12:54:20.932284Z","shell.execute_reply":"2022-04-04T12:54:20.931345Z","shell.execute_reply.started":"2022-04-04T12:54:20.927244Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check whether a, and which GPU is available for the computation","metadata":{}},{"cell_type":"code","source":"is_cuda_gpu_available = tf.config.list_physical_devices('GPU')\nprint(is_cuda_gpu_available)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:54:21.093735Z","iopub.status.busy":"2022-04-04T12:54:21.09347Z","iopub.status.idle":"2022-04-04T12:54:21.099596Z","shell.execute_reply":"2022-04-04T12:54:21.098416Z","shell.execute_reply.started":"2022-04-04T12:54:21.093698Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image size\nim_si = (ih, iw)\n\n# Convert the color channel to the corresponding number of layers\nif(ch == 'rgb'):\n    chnum = 3\nelif(ch == 'grayscale'):\n    chnum = 1","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:54:21.218656Z","iopub.status.busy":"2022-04-04T12:54:21.21844Z","iopub.status.idle":"2022-04-04T12:54:21.222873Z","shell.execute_reply":"2022-04-04T12:54:21.221912Z","shell.execute_reply.started":"2022-04-04T12:54:21.218631Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create new directory for saving output files if computation is done locally","metadata":{}},{"cell_type":"code","source":"if cenv == 1:\n    file_exists = []\n    vnum = 1\n    dir = \"C:/Users/Max/Documents/GitHub/cross_validation\"\n    for files in os.listdir(dir):\n        if \"densenet\" in files:\n            try:\n                vnum = max(vnum, int(files[-3:]))\n            except: \n                continue\n            new_vnum = vnum + 1\n            file_exists.append(True)\n        else: \n            file_exists.append(False)\n    # If this is the first notebook you want to save, a new folder will be created with version #001\n    if sum(file_exists) == 0:\n        new_vnum = 1\n        print(\"No matches found\")\n\n    else: \n        print(f\"{sum(file_exists)} matches(es) found\")\n        print(\"--------------\")\n\n    # Print new folder name\n    print(f\"New folder name: densenet-local-v{new_vnum:03}\")\n    print(\"--------------\")\n    \n    # Create new folder with the name of the notebook and the version number\n    new_dir = f\"/Users/Max/Documents/GitHub/cross_validation/densenet-local-v{new_vnum:03}\"\n    os.makedirs(new_dir)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:54:21.524082Z","iopub.status.busy":"2022-04-04T12:54:21.523822Z","iopub.status.idle":"2022-04-04T12:54:21.532904Z","shell.execute_reply":"2022-04-04T12:54:21.530442Z","shell.execute_reply.started":"2022-04-04T12:54:21.52405Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data**\n","metadata":{}},{"cell_type":"code","source":"if cenv == 0:\n    path_root = \"/kaggle/input/malimgdataset\"\n\nif cenv == 1:\n    path_root = \"C:/Users/Max/Documents/image_data/\"","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:54:22.029004Z","iopub.status.busy":"2022-04-04T12:54:22.028035Z","iopub.status.idle":"2022-04-04T12:54:22.034118Z","shell.execute_reply":"2022-04-04T12:54:22.032951Z","shell.execute_reply.started":"2022-04-04T12:54:22.028948Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the data. No data augmentation takes place","metadata":{}},{"cell_type":"code","source":"batches = ImageDataGenerator().flow_from_directory(\n    directory     = path_root, \n    color_mode    = ch, \n    target_size   = (ih,iw), \n    batch_size    = batch_size,\n    interpolation = 'bicubic'\n)\nimgs, labels = next(batches)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:54:22.320796Z","iopub.status.busy":"2022-04-04T12:54:22.320461Z","iopub.status.idle":"2022-04-04T12:55:08.312969Z","shell.execute_reply":"2022-04-04T12:55:08.312236Z","shell.execute_reply.started":"2022-04-04T12:54:22.320754Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plots images with labels within jupyter notebook\ndef plots(ims, figsize=(20,30), rows=10, interp=False, titles=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != chnum):\n            ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    cols = 10 # len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n    for i in range(0,50):\n        sp = f.add_subplot(rows, cols, i+1)\n        sp.axis('Off')\n        if titles is not None:\n            sp.set_title(list(batches.class_indices.keys())[np.argmax(titles[i])], fontsize=16)\n        plt.imshow(ims[i], cmap = 'gray',interpolation=None if interp else 'none')\n        \nplots(imgs, titles = labels)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:55:08.352665Z","iopub.status.busy":"2022-04-04T12:55:08.35192Z","iopub.status.idle":"2022-04-04T12:55:10.510229Z","shell.execute_reply":"2022-04-04T12:55:10.509612Z","shell.execute_reply.started":"2022-04-04T12:55:08.352627Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A dictionary of all the different classes\nclasses = batches.class_indices.keys()\nx_axis = np.arange(len(list(classes)))","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:55:10.511753Z","iopub.status.busy":"2022-04-04T12:55:10.51138Z","iopub.status.idle":"2022-04-04T12:55:10.515597Z","shell.execute_reply":"2022-04-04T12:55:10.514992Z","shell.execute_reply.started":"2022-04-04T12:55:10.511715Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot data distribution among all classes","metadata":{}},{"cell_type":"markdown","source":"Standardize images","metadata":{}},{"cell_type":"code","source":"imgs = tf.keras.applications.densenet.preprocess_input(imgs)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:55:10.831081Z","iopub.status.busy":"2022-04-04T12:55:10.830842Z","iopub.status.idle":"2022-04-04T12:55:11.137268Z","shell.execute_reply":"2022-04-04T12:55:11.136502Z","shell.execute_reply.started":"2022-04-04T12:55:10.831047Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot data distribution among train, val. and test set","metadata":{}},{"cell_type":"markdown","source":"# DenseNet\nWe will now build our **DenseNet** model using Tensorflow/Keras. This model will have the following layers :\n\n**Input shape** : 64 * 64 * 3","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential, Input, Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, LeakyReLU\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.model_selection import KFold","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:55:11.340255Z","iopub.status.busy":"2022-04-04T12:55:11.339609Z","iopub.status.idle":"2022-04-04T12:55:11.344998Z","shell.execute_reply":"2022-04-04T12:55:11.344338Z","shell.execute_reply.started":"2022-04-04T12:55:11.340218Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score\nfrom prettytable import PrettyTable, MSWORD_FRIENDLY","metadata":{"execution":{"iopub.execute_input":"2022-04-04T13:02:23.959269Z","iopub.status.busy":"2022-04-04T13:02:23.95904Z","iopub.status.idle":"2022-04-04T13:02:23.963939Z","shell.execute_reply":"2022-04-04T13:02:23.962847Z","shell.execute_reply.started":"2022-04-04T13:02:23.959241Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We want **11** classes","metadata":{"execution":{"iopub.execute_input":"2022-03-21T12:28:06.621919Z","iopub.status.busy":"2022-03-21T12:28:06.621373Z","iopub.status.idle":"2022-03-21T12:28:06.651878Z","shell.execute_reply":"2022-03-21T12:28:06.650937Z","shell.execute_reply.started":"2022-03-21T12:28:06.621794Z"}}},{"cell_type":"code","source":"num_classes = len(list(batches.class_indices))\nprint(\"The number of classes in our dataset: \", num_classes)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:55:11.346886Z","iopub.status.busy":"2022-04-04T12:55:11.346161Z","iopub.status.idle":"2022-04-04T12:55:11.355487Z","shell.execute_reply":"2022-04-04T12:55:11.354776Z","shell.execute_reply.started":"2022-04-04T12:55:11.346847Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Building the model","metadata":{}},{"cell_type":"markdown","source":"Reduce learning rate after 5 epochs of no improvement on the validition accuracy. Also save save checkpoints for the best performing model based on validation loss","metadata":{}},{"cell_type":"code","source":"def confusion_matrix(confusion_matrix, class_names_bin, figsize = (5,2), fontsize=7):\n\n        df_cm = pd.DataFrame(\n            confusion_matrix, index=class_names_bin, columns=class_names_bin, \n        )\n        fig = plt.figure(figsize=figsize)\n        try:\n            heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n        except ValueError:\n            raise ValueError(\"Confusion matrix values must be integers.\")\n        heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n        heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label')\n\nclass_names_bin= (\"ransomware\", \"benign\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-4)\nif cenv == 0:\n    checkpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\nif cenv == 1:\n    checkpoint = ModelCheckpoint(f'{new_dir}/model.h5', verbose=1, save_best_only=True)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Performance metrics\nmulti_acc_per_fold = []\nloss_per_fold = []\nmulti_f1_per_fold = []\nbin_acc_per_fold = []\nbin_tpr_per_fold = []\nbin_f1_per_fold = []\nbin_mcc_per_fold = []\n\ntp = []\nfp = []\nfn = []\ntn = []\n\ny_pred = []\ny_true = []\n\nrw_count = []\nbn_count = []\n\n# History\nhistory = []\n\n# Data distribution\ntrain_distr = []\ntest_distr= []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = KFold(n_splits=n_folds, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_no = 1\n\nfor train, test in kfold.split(imgs,labels):\n    \n    # DenseNet\n    base_model = tf.keras.applications.DenseNet169(weights = 'imagenet', include_top = False, input_shape = (64,64,3))\n    \n    x = layers.Flatten()(base_model.output)\n    x = layers.Dense(1000, activation='relu')(x)\n    predictions = layers.Dense(num_classes, activation = 'softmax')(x)\n    \n    # Compile the model\n    head_model = Model(inputs = base_model.input, outputs = predictions)\n    head_model.compile(optimizer='adam', loss=losses.categorical_crossentropy, metrics=['accuracy'])\n    \n    # Freeze all but last eight layers\n    for layer in head_model.layers[:-8]:\n        layer.trainable=False\n    \n    for layer in head_model.layers[-8:]:\n        layer.trainable=True\n    \n    \n    # Run the CNN\n    history.append(\n        head_model.fit(\n        imgs[train], \n        labels[train], \n        validation_data=(imgs[test], labels[test]), \n        epochs=epoch_t,\n        callbacks = [anne, checkpoint]) # The actual computation of the CNN\n    )\n    \n    # Generate generalization metrics\n    scores = head_model.evaluate(imgs[test], labels[test], verbose=0)\n    print(f'Score for fold {fold_no}: {head_model.metrics_names[0]} of {scores[0]}; {head_model.metrics_names[1]} of {scores[1]*100}%')\n    multi_acc_per_fold.append(scores[1])\n    loss_per_fold.append(scores[0])\n\n    # Increase fold number\n    fold_no = fold_no + 1\n    \n    # Create two 1D-arrays: one with the prediction per image of the model and one with the true labels\n    y_pred = np.append(y_pred, np.argmax(head_model.predict(imgs[test]), axis=-1))\n    y_true = np.append(y_true, np.argmax(labels[test], axis=1))\n    \n    y_pred2 = np.argmax(head_model.predict(imgs[test]), axis=-1)\n    y_true2 = np.argmax(labels[test], axis=1)\n    \n    # Binary\n    y_predbin = [] \n    y_truebin = []\n    for count, value in enumerate(y_true2):\n        if y_true2[count] in range(10): # range(10) is 0 to 9, meaning all ransomware families\n            y_truebin.append(0)\n        else: y_truebin.append(1) # if prediction is not one of the ransomware families, then it is benign\n\n        if y_pred2[count] in range(10): # range(10) is 0 to 9, meaning all ransomware families\n            y_predbin.append(0)\n        else: y_predbin.append(1) # if prediction is not one of the ransomware families, then it is benign\n        continue\n        \n    rw_count.append(len(y_truebin) - np.sum(y_truebin))\n    bn_count.append(np.sum(y_truebin))\n    \n    # Binary confusion Matrix\n    c_matrix_bin = metrics.confusion_matrix(y_truebin, y_predbin)\n    \n    confusion_matrix(c_matrix_bin, class_names_bin, figsize = (5,2), fontsize=10)\n    \n    tp.append(c_matrix_bin[0,0])\n    fp.append(c_matrix_bin[0,1])\n    fn.append(c_matrix_bin[1,0])\n    tn.append(c_matrix_bin[1,1])\n    \n    multi_f1_per_fold.append(f1_score(y_true2, y_pred2, average='macro'))\n    bin_tpr_per_fold.append(c_matrix_bin[0,0]/(c_matrix_bin[0,0] + c_matrix_bin[0,1])) #True Positive Rate\n    bin_acc_per_fold.append(accuracy_score(y_truebin, y_predbin)) # Accuracy\n    bin_f1_per_fold.append(f1_score(y_truebin, y_predbin, labels=0)) # F1 Score\n    bin_mcc_per_fold.append(matthews_corrcoef(y_truebin, y_predbin))  # Matthews Correlation Coefficient\n    \n    train_distr.append((sum(labels[train])/labels[train].shape[0])*100)\n    test_distr.append((sum(labels[test])/labels[test].shape[0])*100)\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(np.argmax(head_model.predict(imgs[test]), axis=-1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Run the model","metadata":{}},{"cell_type":"code","source":"# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(multi_acc_per_fold)):\n  print('------------------------------------------------------------------------')\n  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {multi_acc_per_fold[i]*100}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(multi_acc_per_fold)*100}% (+- {np.std(multi_acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","metadata":{"execution":{"iopub.execute_input":"2022-04-04T13:01:20.534601Z","iopub.status.busy":"2022-04-04T13:01:20.534175Z","iopub.status.idle":"2022-04-04T13:02:23.955893Z","shell.execute_reply":"2022-04-04T13:02:23.955106Z","shell.execute_reply.started":"2022-04-04T13:01:20.534568Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating performance","metadata":{}},{"cell_type":"markdown","source":"Create data distribution graph","metadata":{}},{"cell_type":"code","source":"perc_train = np.mean(train_distr, axis = 0)\nperc_test =  np.mean(test_distr, axis = 0)\n\nplt.bar(x_axis - 0.2, perc_train, 0.4, label = 'Training')\nplt.errorbar(x_axis - 0.2, perc_train, yerr = np.std(train_distr, axis = 0), \n             fmt='|', color='red', capsize = 0)\n\nplt.bar(x_axis + 0.2, perc_test,0.4, label = 'Test')\nplt.errorbar(x_axis + 0.2, perc_test, yerr = np.std(train_distr, axis = 0), \n             fmt='|', color='red', capsize=0.0)\n\n\nplt.title('Distribution of the dataset')\nplt.ylabel('Dataset distribution in percentage (%)')\nplt.xticks(x_axis, list(classes), rotation='vertical')\nplt.legend()\n\nif cenv == 0:\n    plt.savefig(\"multi_data_dist.png\", bbox_inches = 'tight', dpi = 150)\nif cenv == 1:\n    plt.savefig(f\"{new_dir}/multi_data_dist.png\", bbox_inches = 'tight', dpi = 150)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:55:10.517552Z","iopub.status.busy":"2022-04-04T12:55:10.517088Z","iopub.status.idle":"2022-04-04T12:55:10.829694Z","shell.execute_reply":"2022-04-04T12:55:10.82903Z","shell.execute_reply.started":"2022-04-04T12:55:10.517516Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = PrettyTable(['Metric', 'Performance', 'St.Deviation'])\nt.add_row(['M-Class', \"\", \"\"])\nt.add_row(['Acc    ', round(np.mean(multi_acc_per_fold),4), round(np.std(multi_acc_per_fold),4)])\nt.add_row(['Loss   ', round(np.mean(loss_per_fold),4), round(np.std(loss_per_fold),4)])\nt.add_row(['Macro F1', round(np.mean(multi_f1_per_fold), 4), round(np.std(multi_f1_per_fold),4)])\nt.border = True\nt.add_row(['', '', ''])\nt.add_row(['B-Class', \"\", \"\"])\nt.add_row(['TPR    ', round(np.mean(bin_tpr_per_fold),4), round(np.std(bin_tpr_per_fold),4)])\nt.add_row(['Acc    ', round(np.mean(bin_acc_per_fold),4), round(np.std(bin_acc_per_fold),4)])\nt.add_row(['F1     ', round(np.mean(bin_f1_per_fold),4), round(np.std(bin_f1_per_fold),4)])\nt.add_row(['MCC    ', round(np.mean(bin_mcc_per_fold),4), round(np.std(bin_mcc_per_fold),4)])\nt.header = True\nt.set_style(MSWORD_FRIENDLY)\nt.align = \"l\"\nt.title = \"Performance of DenseNet169\"\nprint(t)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving PrettyTable\ntable = t.get_string()\n\nif cenv == 0:\n    with open('multi_performance_table.txt', 'w') as f:\n        f.write(table)\nif cenv == 1:\n    with open(f'{new_dir}/multi_performance_table.txt', 'w') as f:\n        f.write(table)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:50:29.946553Z","iopub.status.busy":"2022-04-04T12:50:29.946315Z","iopub.status.idle":"2022-04-04T12:50:29.955595Z","shell.execute_reply":"2022-04-04T12:50:29.954905Z","shell.execute_reply.started":"2022-04-04T12:50:29.94652Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluate the model based on the test set","metadata":{}},{"cell_type":"markdown","source":"Save a table with the performance on the test set","metadata":{}},{"cell_type":"markdown","source":"**Evaluating overfitting and other model performance measures**","metadata":{}},{"cell_type":"code","source":"linecolours = ['gray', 'orange', 'blue', 'green','silver', 'cyan', 'red', 'purple', 'lightgreen', 'black', 'brown']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_metric(model, history, metric_name, ymin, ymax):\n    '''\n    Function to evaluate a trained model on a chosen metric. \n    Training and validation metric are plotted in a\n    line chart for each epoch.\n    \n    Parameters:\n        history : model training history\n        metric_name : loss or accuracy\n    Output:\n        line chart with epochs of x-axis and metric on\n        y-axis\n    '''\n    for i in range(n_folds-1):  \n        metric = history[i].history[metric_name]\n        val_metric = history[i].history['val_' + metric_name]\n        e = range(1, epoch_t + 1)\n        plt.plot(e, metric, marker = 'o', linestyle = 'none', color = linecolours[i])\n        plt.plot(e, val_metric, color = linecolours[i])\n        \n    metric = history[n_folds-1].history[metric_name]\n    val_metric = history[n_folds-1].history['val_' + metric_name]\n    e = range(1, epoch_t + 1)\n    plt.plot(e, metric, marker = 'o', linestyle = 'none', label = 'Training', color = linecolours[n_folds-1])\n    plt.plot(e, val_metric, label = 'Validation', color = linecolours[n_folds-1])\n    \n    plt.ylim(ymin, ymax)\n    \n    plt.xlabel('Epoch number')\n    plt.ylabel(metric_name)\n    plt.title('Comparing training and validation ' + metric_name + ' for DenseNet169 across folds')\n    plt.legend()\n    if cenv == 0:\n        plt.savefig(f\"cnn_model_{metric_name}.png\", bbox_inches = 'tight', dpi = 150)\n    if cenv == 1:\n        plt.savefig(f\"{new_dir}/cnn_model_{metric_name}.png\", bbox_inches = 'tight', dpi = 150)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:50:29.957303Z","iopub.status.busy":"2022-04-04T12:50:29.957045Z","iopub.status.idle":"2022-04-04T12:50:29.966375Z","shell.execute_reply":"2022-04-04T12:50:29.965614Z","shell.execute_reply.started":"2022-04-04T12:50:29.95727Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_metric(head_model, history, 'loss', 0,1)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:50:29.96775Z","iopub.status.busy":"2022-04-04T12:50:29.967464Z","iopub.status.idle":"2022-04-04T12:50:30.310797Z","shell.execute_reply":"2022-04-04T12:50:30.30906Z","shell.execute_reply.started":"2022-04-04T12:50:29.967715Z"},"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_metric(head_model, history, 'accuracy', 0.8,1)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:50:30.313052Z","iopub.status.busy":"2022-04-04T12:50:30.312583Z","iopub.status.idle":"2022-04-04T12:50:30.643457Z","shell.execute_reply":"2022-04-04T12:50:30.642795Z","shell.execute_reply.started":"2022-04-04T12:50:30.313007Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix\nAnalysing the results","metadata":{}},{"cell_type":"markdown","source":"# Binary classification\ny_predbin and y_testbin are the binary classification arrays. 0 = ransomware and 1 = benign","metadata":{}},{"cell_type":"markdown","source":"Plot the distribution of dataset as ransomware - benign","metadata":{}},{"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nx_lab = ['Ransomware', 'Benign']\ny_lab = [np.mean(rw_count), np.mean(bn_count)]\nplt.title('Distribution of the test set')\nplt.ylabel('Dataset distribution in absolute numbers')\nax.bar(x_lab, y_lab)\nax.errorbar(x_lab, y_lab, yerr = [np.std(rw_count), np.std(bn_count)], fmt = '|', ecolor='red')\nif cenv == 0:\n    plt.savefig(\"bin_data_dist.png\", bbox_inches = 'tight', dpi = 150)\nif cenv == 1:\n    plt.savefig(f\"{new_dir}/bin_data_dist.png\", bbox_inches = 'tight', dpi = 150)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:50:38.991361Z","iopub.status.busy":"2022-04-04T12:50:38.9907Z","iopub.status.idle":"2022-04-04T12:50:39.206684Z","shell.execute_reply":"2022-04-04T12:50:39.206041Z","shell.execute_reply.started":"2022-04-04T12:50:38.991325Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot binary confusion matrix","metadata":{}},{"cell_type":"code","source":"all_y_predbin = [] \nall_y_truebin = []\nfor count, value in enumerate(y_true):\n    if y_true[count] in range(10): # range(10) is 0 to 9, meaning all ransomware families\n        all_y_truebin.append(0)\n    else: all_y_truebin.append(1) # if prediction is not one of the ransomware families, then it is benign\n\n    if y_pred[count] in range(10): # range(10) is 0 to 9, meaning all ransomware families\n        all_y_predbin.append(0)\n    else: all_y_predbin.append(1) # if prediction is not one of the ransomware families, then it is benign\n    continue","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def confusion_matrix_bin(confusion_matrix, class_names_bin, name, figsize = (5,2), fontsize=7):\n   \n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names_bin, columns=class_names_bin, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.title(f\"{(name.capitalize())} Confusion Matrix - DenseNet169\")\n    if cenv == 0:\n        plt.savefig(f\"{name}_cmatrix.png\", bbox_inches = 'tight', dpi = 150)\n    if cenv == 1:\n        plt.savefig(f\"{new_dir}/{name}_cmatrix.png\", bbox_inches = 'tight', dpi = 150)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:50:39.208009Z","iopub.status.busy":"2022-04-04T12:50:39.207772Z","iopub.status.idle":"2022-04-04T12:50:39.224366Z","shell.execute_reply":"2022-04-04T12:50:39.223723Z","shell.execute_reply.started":"2022-04-04T12:50:39.207975Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_matrix_bin = metrics.confusion_matrix(all_y_truebin, all_y_predbin)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names_bin= (\"ransomware\", \"benign\")\nconfusion_matrix_bin(c_matrix_bin, class_names_bin, 'binary', figsize = (5,2), fontsize=10)","metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:50:39.226004Z","iopub.status.busy":"2022-04-04T12:50:39.225686Z","iopub.status.idle":"2022-04-04T12:50:39.780561Z","shell.execute_reply":"2022-04-04T12:50:39.779784Z","shell.execute_reply.started":"2022-04-04T12:50:39.225972Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_matrix = metrics.confusion_matrix(y_true, y_pred)\nclass_names= batches.class_indices.keys()\nconfusion_matrix_bin(c_matrix, class_names, 'multi-class', figsize = (20,7), fontsize=14)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}