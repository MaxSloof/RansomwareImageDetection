{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96345a4",
   "metadata": {
    "papermill": {
     "duration": 0.025459,
     "end_time": "2022-04-10T19:48:37.210976",
     "exception": false,
     "start_time": "2022-04-10T19:48:37.185517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conditional GAN\n",
    "\n",
    "Used to generate new training data for the ransomware families to overcome the skewed distribution of training data towards the benign samples. \n",
    "\n",
    "Dim Size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc9da04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:48:37.272252Z",
     "iopub.status.busy": "2022-04-10T19:48:37.271548Z",
     "iopub.status.idle": "2022-04-10T19:48:42.133165Z",
     "shell.execute_reply": "2022-04-10T19:48:42.132167Z"
    },
    "papermill": {
     "duration": 4.896022,
     "end_time": "2022-04-10T19:48:42.133324",
     "exception": false,
     "start_time": "2022-04-10T19:48:37.237302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17c9e4",
   "metadata": {
    "papermill": {
     "duration": 0.024115,
     "end_time": "2022-04-10T19:48:42.182190",
     "exception": false,
     "start_time": "2022-04-10T19:48:42.158075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Change parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50332e8",
   "metadata": {
    "papermill": {
     "duration": 0.024045,
     "end_time": "2022-04-10T19:48:42.230468",
     "exception": false,
     "start_time": "2022-04-10T19:48:42.206423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e038d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:48:42.283811Z",
     "iopub.status.busy": "2022-04-10T19:48:42.283092Z",
     "iopub.status.idle": "2022-04-10T19:48:42.285073Z",
     "shell.execute_reply": "2022-04-10T19:48:42.285520Z"
    },
    "papermill": {
     "duration": 0.03103,
     "end_time": "2022-04-10T19:48:42.285645",
     "exception": false,
     "start_time": "2022-04-10T19:48:42.254615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Color mode\n",
    "ch = 'grayscale'\n",
    "\n",
    "# Image size\n",
    "iw, ih = 64,64\n",
    "im_size = (iw,ih)\n",
    "\n",
    "# Latent dim size\n",
    "latent_dim = 128\n",
    "\n",
    "# Number of Epochs\n",
    "epoch_t = 500\n",
    "\n",
    "# Computation environment: Kaggle (0) or Local (1)\n",
    "cenv = 0\n",
    "\n",
    "# If weights are used: Weight factor\n",
    "wf = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131444f",
   "metadata": {
    "papermill": {
     "duration": 0.023871,
     "end_time": "2022-04-10T19:48:42.333689",
     "exception": false,
     "start_time": "2022-04-10T19:48:42.309818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ed66b",
   "metadata": {
    "papermill": {
     "duration": 0.026336,
     "end_time": "2022-04-10T19:48:42.385188",
     "exception": false,
     "start_time": "2022-04-10T19:48:42.358852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Automatic notebook preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f5843d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:48:42.438246Z",
     "iopub.status.busy": "2022-04-10T19:48:42.437442Z",
     "iopub.status.idle": "2022-04-10T19:48:42.441437Z",
     "shell.execute_reply": "2022-04-10T19:48:42.441849Z"
    },
    "papermill": {
     "duration": 0.032083,
     "end_time": "2022-04-10T19:48:42.442008",
     "exception": false,
     "start_time": "2022-04-10T19:48:42.409925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if(ch == 'rgb'):\n",
    "    chnum = 3\n",
    "elif(ch == 'grayscale'):\n",
    "    chnum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b1ec10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:48:42.499087Z",
     "iopub.status.busy": "2022-04-10T19:48:42.498191Z",
     "iopub.status.idle": "2022-04-10T19:48:42.499906Z",
     "shell.execute_reply": "2022-04-10T19:48:42.500377Z"
    },
    "papermill": {
     "duration": 0.033877,
     "end_time": "2022-04-10T19:48:42.500515",
     "exception": false,
     "start_time": "2022-04-10T19:48:42.466638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cenv == 1:\n",
    "    file_exists = []\n",
    "    vnum = 1\n",
    "    dir = \"C:/Users/Max/Documents/GitHub/malimg_dataset\"\n",
    "    for files in os.listdir(dir):\n",
    "        if \"cgan\" in files:\n",
    "            try:\n",
    "                vnum = max(vnum, int(files[-3:]))\n",
    "            except: \n",
    "                continue\n",
    "            new_vnum = vnum + 1\n",
    "            file_exists.append(True)\n",
    "        else: \n",
    "            file_exists.append(False)\n",
    "    # If this is the first notebook you want to save, a new folder will be created with version #001\n",
    "    if sum(file_exists) == 0:\n",
    "        new_vnum = 1\n",
    "        print(\"No matches found\")\n",
    "\n",
    "    else: \n",
    "        print(f\"{sum(file_exists)} matches(es) found\")\n",
    "        print(\"--------------\")\n",
    "\n",
    "    # Print new folder name\n",
    "    print(f\"New folder name: cgan-local-v{new_vnum:03}\")\n",
    "    print(\"--------------\")\n",
    "    \n",
    "    # Create new folder with the name of the notebook and the version number\n",
    "    new_dir = f\"C://Users/Max/Documents/GitHub/malimg_dataset/cgan-local-v{new_vnum:03}\"\n",
    "    os.makedirs(new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4a113b",
   "metadata": {
    "papermill": {
     "duration": 0.024802,
     "end_time": "2022-04-10T19:48:42.550102",
     "exception": false,
     "start_time": "2022-04-10T19:48:42.525300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12bbd891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:48:42.605118Z",
     "iopub.status.busy": "2022-04-10T19:48:42.604268Z",
     "iopub.status.idle": "2022-04-10T19:48:42.606299Z",
     "shell.execute_reply": "2022-04-10T19:48:42.606661Z"
    },
    "papermill": {
     "duration": 0.0316,
     "end_time": "2022-04-10T19:48:42.606793",
     "exception": false,
     "start_time": "2022-04-10T19:48:42.575193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cenv == 0:\n",
    "    path_root = \"/kaggle/input/malimgdataset\"\n",
    "    path_save_imgs = \"/kaggle/working/gen_images\"\n",
    "if cenv == 1:\n",
    "    path_root = \"C:/Users/Max/Documents/image_data/fixed_malimg_dataset\"\n",
    "    path_save_imgs = f\"C:/Users/Max/Documents/image_data/malimg-cgan-local-v{new_vnum:03}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b244f7c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:48:42.661054Z",
     "iopub.status.busy": "2022-04-10T19:48:42.660241Z",
     "iopub.status.idle": "2022-04-10T19:48:42.662517Z",
     "shell.execute_reply": "2022-04-10T19:48:42.662017Z"
    },
    "papermill": {
     "duration": 0.031047,
     "end_time": "2022-04-10T19:48:42.662623",
     "exception": false,
     "start_time": "2022-04-10T19:48:42.631576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4668d30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:48:42.717321Z",
     "iopub.status.busy": "2022-04-10T19:48:42.716615Z",
     "iopub.status.idle": "2022-04-10T19:50:28.911781Z",
     "shell.execute_reply": "2022-04-10T19:50:28.911240Z"
    },
    "papermill": {
     "duration": 106.224415,
     "end_time": "2022-04-10T19:50:28.911958",
     "exception": false,
     "start_time": "2022-04-10T19:48:42.687543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9339 images belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "prelim_dataset = datagen.flow_from_directory(\n",
    "    directory = path_root,\n",
    "    color_mode = ch,\n",
    "    target_size = im_size,\n",
    "    interpolation = 'bicubic',\n",
    "    batch_size = 40000\n",
    ")\n",
    "imgs, labels = next(prelim_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f2f741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:28.980985Z",
     "iopub.status.busy": "2022-04-10T19:50:28.980226Z",
     "iopub.status.idle": "2022-04-10T19:50:29.209302Z",
     "shell.execute_reply": "2022-04-10T19:50:29.209820Z"
    },
    "papermill": {
     "duration": 0.268594,
     "end_time": "2022-04-10T19:50:29.210026",
     "exception": false,
     "start_time": "2022-04-10T19:50:28.941432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ransomware family:  Yuner.A\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = 7099+10\n",
    "plt.imshow(np.array(imgs[z]*255).astype(np.uint8), cmap=\"gray\")\n",
    "print(\"Ransomware family: \",list(prelim_dataset.class_indices)[np.argmax(labels[z])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d2bd92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:29.277321Z",
     "iopub.status.busy": "2022-04-10T19:50:29.276468Z",
     "iopub.status.idle": "2022-04-10T19:50:29.279443Z",
     "shell.execute_reply": "2022-04-10T19:50:29.279000Z"
    },
    "papermill": {
     "duration": 0.038972,
     "end_time": "2022-04-10T19:50:29.279617",
     "exception": false,
     "start_time": "2022-04-10T19:50:29.240645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples = prelim_dataset.samples\n",
    "num_classes = max(prelim_dataset.labels) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f81a1c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:29.349608Z",
     "iopub.status.busy": "2022-04-10T19:50:29.348455Z",
     "iopub.status.idle": "2022-04-10T19:50:29.352013Z",
     "shell.execute_reply": "2022-04-10T19:50:29.352496Z"
    },
    "papermill": {
     "duration": 0.041718,
     "end_time": "2022-04-10T19:50:29.352629",
     "exception": false,
     "start_time": "2022-04-10T19:50:29.310911",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adialer.C': 0,\n",
       " 'Agent.FYI': 1,\n",
       " 'Allaple.A': 2,\n",
       " 'Allaple.L': 3,\n",
       " 'Alueron.gen!J': 4,\n",
       " 'Autorun.K': 5,\n",
       " 'C2LOP.P': 6,\n",
       " 'C2LOP.gen!g': 7,\n",
       " 'Dialplatform.B': 8,\n",
       " 'Dontovo.A': 9,\n",
       " 'Fakerean': 10,\n",
       " 'Instantaccess': 11,\n",
       " 'Lolyda.AA1': 12,\n",
       " 'Lolyda.AA2': 13,\n",
       " 'Lolyda.AA3': 14,\n",
       " 'Lolyda.AT': 15,\n",
       " 'Malex.gen!J': 16,\n",
       " 'Obfuscator.AD': 17,\n",
       " 'Rbot!gen': 18,\n",
       " 'Skintrim.N': 19,\n",
       " 'Swizzor.gen!E': 20,\n",
       " 'Swizzor.gen!I': 21,\n",
       " 'VB.AT': 22,\n",
       " 'Wintrim.BX': 23,\n",
       " 'Yuner.A': 24}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prelim_dataset.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfb94da",
   "metadata": {
    "papermill": {
     "duration": 0.030262,
     "end_time": "2022-04-10T19:50:29.413097",
     "exception": false,
     "start_time": "2022-04-10T19:50:29.382835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cfbced0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:32.075855Z",
     "iopub.status.busy": "2022-04-10T19:50:29.653924Z",
     "iopub.status.idle": "2022-04-10T19:50:32.206605Z",
     "shell.execute_reply": "2022-04-10T19:50:32.207060Z"
    },
    "papermill": {
     "duration": 2.76332,
     "end_time": "2022-04-10T19:50:32.207207",
     "exception": false,
     "start_time": "2022-04-10T19:50:29.443887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 19:50:29.533445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 19:50:29.650450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 19:50:29.651280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 19:50:29.654347: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-10 19:50:29.655472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 19:50:29.656342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 19:50:29.657119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 19:50:31.615557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 19:50:31.616423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 19:50:31.617080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 19:50:31.617662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((imgs, labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c515f5c5",
   "metadata": {
    "papermill": {
     "duration": 0.028084,
     "end_time": "2022-04-10T19:50:32.263528",
     "exception": false,
     "start_time": "2022-04-10T19:50:32.235444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Calculate number of input channel for Gen and Disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7ef232a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:32.324818Z",
     "iopub.status.busy": "2022-04-10T19:50:32.324132Z",
     "iopub.status.idle": "2022-04-10T19:50:32.326971Z",
     "shell.execute_reply": "2022-04-10T19:50:32.327367Z"
    },
    "papermill": {
     "duration": 0.035528,
     "end_time": "2022-04-10T19:50:32.327497",
     "exception": false,
     "start_time": "2022-04-10T19:50:32.291969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 26\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = chnum + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0160fa",
   "metadata": {
    "papermill": {
     "duration": 0.028245,
     "end_time": "2022-04-10T19:50:32.384101",
     "exception": false,
     "start_time": "2022-04-10T19:50:32.355856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb29ac9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:32.448721Z",
     "iopub.status.busy": "2022-04-10T19:50:32.448210Z",
     "iopub.status.idle": "2022-04-10T19:50:32.535503Z",
     "shell.execute_reply": "2022-04-10T19:50:32.534923Z"
    },
    "papermill": {
     "duration": 0.122948,
     "end_time": "2022-04-10T19:50:32.535631",
     "exception": false,
     "start_time": "2022-04-10T19:50:32.412683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((iw, ih, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e57cba84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:32.599321Z",
     "iopub.status.busy": "2022-04-10T19:50:32.598505Z",
     "iopub.status.idle": "2022-04-10T19:50:32.671910Z",
     "shell.execute_reply": "2022-04-10T19:50:32.671366Z"
    },
    "papermill": {
     "duration": 0.107367,
     "end_time": "2022-04-10T19:50:32.672066",
     "exception": false,
     "start_time": "2022-04-10T19:50:32.564699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        layers.Dense(8 * 8 * generator_in_channels),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((8, 8, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c3c1a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:32.737933Z",
     "iopub.status.busy": "2022-04-10T19:50:32.736845Z",
     "iopub.status.idle": "2022-04-10T19:50:32.743232Z",
     "shell.execute_reply": "2022-04-10T19:50:32.742766Z"
    },
    "papermill": {
     "duration": 0.042091,
     "end_time": "2022-04-10T19:50:32.743348",
     "exception": false,
     "start_time": "2022-04-10T19:50:32.701257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        15040     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 236,609\n",
      "Trainable params: 236,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "500d35bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:32.808769Z",
     "iopub.status.busy": "2022-04-10T19:50:32.807969Z",
     "iopub.status.idle": "2022-04-10T19:50:32.814118Z",
     "shell.execute_reply": "2022-04-10T19:50:32.813668Z"
    },
    "papermill": {
     "duration": 0.041075,
     "end_time": "2022-04-10T19:50:32.814232",
     "exception": false,
     "start_time": "2022-04-10T19:50:32.773157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 9792)              1507968   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 9792)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 153)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 16, 16, 128)       313472    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 1)         6273      \n",
      "=================================================================\n",
      "Total params: 2,352,257\n",
      "Trainable params: 2,352,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ecdef2",
   "metadata": {
    "papermill": {
     "duration": 0.02953,
     "end_time": "2022-04-10T19:50:32.873446",
     "exception": false,
     "start_time": "2022-04-10T19:50:32.843916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Create Conditional GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae1bafa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:32.938466Z",
     "iopub.status.busy": "2022-04-10T19:50:32.936735Z",
     "iopub.status.idle": "2022-04-10T19:50:32.954850Z",
     "shell.execute_reply": "2022-04-10T19:50:32.955267Z"
    },
    "papermill": {
     "duration": 0.051948,
     "end_time": "2022-04-10T19:50:32.955409",
     "exception": false,
     "start_time": "2022-04-10T19:50:32.903461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[ih * iw]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, iw, ih, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02013951",
   "metadata": {
    "papermill": {
     "duration": 0.030345,
     "end_time": "2022-04-10T19:50:33.016263",
     "exception": false,
     "start_time": "2022-04-10T19:50:32.985918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Optimizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc4c706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:33.082414Z",
     "iopub.status.busy": "2022-04-10T19:50:33.081642Z",
     "iopub.status.idle": "2022-04-10T19:50:33.084099Z",
     "shell.execute_reply": "2022-04-10T19:50:33.083595Z"
    },
    "papermill": {
     "duration": 0.03681,
     "end_time": "2022-04-10T19:50:33.084232",
     "exception": false,
     "start_time": "2022-04-10T19:50:33.047422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define optimizers\n",
    "d_optimizer=keras.optimizers.Adam(learning_rate=0.0003)\n",
    "g_optimizer=keras.optimizers.Adam(learning_rate=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cd6e49",
   "metadata": {
    "papermill": {
     "duration": 0.030304,
     "end_time": "2022-04-10T19:50:33.145418",
     "exception": false,
     "start_time": "2022-04-10T19:50:33.115114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a96810a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:33.211446Z",
     "iopub.status.busy": "2022-04-10T19:50:33.210895Z",
     "iopub.status.idle": "2022-04-10T19:50:33.213726Z",
     "shell.execute_reply": "2022-04-10T19:50:33.213334Z"
    },
    "papermill": {
     "duration": 0.038231,
     "end_time": "2022-04-10T19:50:33.213835",
     "exception": false,
     "start_time": "2022-04-10T19:50:33.175604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        # Save the model every 5 epochs \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "          checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5acf2aa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:33.280385Z",
     "iopub.status.busy": "2022-04-10T19:50:33.279637Z",
     "iopub.status.idle": "2022-04-10T19:50:33.281670Z",
     "shell.execute_reply": "2022-04-10T19:50:33.282068Z"
    },
    "papermill": {
     "duration": 0.038311,
     "end_time": "2022-04-10T19:50:33.282203",
     "exception": false,
     "start_time": "2022-04-10T19:50:33.243892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cenv == 0:\n",
    "    checkpoint_dir = '/kaggle/working/checkpoints'\n",
    "if cenv == 1:\n",
    "    checkpoint_dir = f'{new_dir}'\n",
    "    \n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=g_optimizer,\n",
    "                                 discriminator_optimizer=d_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bbf5c8",
   "metadata": {
    "papermill": {
     "duration": 0.030137,
     "end_time": "2022-04-10T19:50:33.342842",
     "exception": false,
     "start_time": "2022-04-10T19:50:33.312705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training C-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c560356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:50:33.410196Z",
     "iopub.status.busy": "2022-04-10T19:50:33.409352Z",
     "iopub.status.idle": "2022-04-10T22:00:52.304666Z",
     "shell.execute_reply": "2022-04-10T22:00:52.305198Z"
    },
    "papermill": {
     "duration": 7818.932139,
     "end_time": "2022-04-10T22:00:52.305367",
     "exception": false,
     "start_time": "2022-04-10T19:50:33.373228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 19:50:34.726331: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-10 19:50:36.509890: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 19s 76ms/step - g_loss: 1.9040 - d_loss: 0.6240\n",
      "Epoch 2/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 3.2934 - d_loss: 0.6636\n",
      "Epoch 3/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 2.2170 - d_loss: 0.6378\n",
      "Epoch 4/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.6833 - d_loss: 0.3977\n",
      "Epoch 5/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 2.0778 - d_loss: 0.3210\n",
      "Epoch 6/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9733 - d_loss: 0.6923\n",
      "Epoch 7/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9657 - d_loss: 0.6261\n",
      "Epoch 8/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7983 - d_loss: 0.6308\n",
      "Epoch 9/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 1.1392 - d_loss: 0.6005\n",
      "Epoch 10/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9334 - d_loss: 0.6318\n",
      "Epoch 11/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9071 - d_loss: 0.6281\n",
      "Epoch 12/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7353 - d_loss: 0.7401\n",
      "Epoch 13/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7322 - d_loss: 0.6846\n",
      "Epoch 14/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7469 - d_loss: 0.6680\n",
      "Epoch 15/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8250 - d_loss: 0.6452\n",
      "Epoch 16/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8942 - d_loss: 0.6180\n",
      "Epoch 17/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9773 - d_loss: 0.7799\n",
      "Epoch 18/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8102 - d_loss: 0.7060\n",
      "Epoch 19/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7460 - d_loss: 0.6939\n",
      "Epoch 20/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7245 - d_loss: 0.6762\n",
      "Epoch 21/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7266 - d_loss: 0.6707\n",
      "Epoch 22/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7466 - d_loss: 0.6627\n",
      "Epoch 23/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8021 - d_loss: 0.6824\n",
      "Epoch 24/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8300 - d_loss: 0.6780\n",
      "Epoch 25/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7690 - d_loss: 0.6842\n",
      "Epoch 26/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7879 - d_loss: 0.6409\n",
      "Epoch 27/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8165 - d_loss: 0.6444\n",
      "Epoch 28/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8143 - d_loss: 0.6526\n",
      "Epoch 29/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8529 - d_loss: 0.6845\n",
      "Epoch 30/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7468 - d_loss: 0.6937\n",
      "Epoch 31/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7596 - d_loss: 0.6632\n",
      "Epoch 32/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7468 - d_loss: 0.6739\n",
      "Epoch 33/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7581 - d_loss: 0.6761\n",
      "Epoch 34/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7787 - d_loss: 0.6725\n",
      "Epoch 35/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7424 - d_loss: 0.6888\n",
      "Epoch 36/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7775 - d_loss: 0.6710\n",
      "Epoch 37/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7740 - d_loss: 0.6737\n",
      "Epoch 38/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7797 - d_loss: 0.6601\n",
      "Epoch 39/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7595 - d_loss: 0.6726\n",
      "Epoch 40/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7868 - d_loss: 0.6716\n",
      "Epoch 41/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.7831 - d_loss: 0.6746\n",
      "Epoch 42/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7686 - d_loss: 0.6704\n",
      "Epoch 43/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.7822 - d_loss: 0.6811\n",
      "Epoch 44/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7473 - d_loss: 0.6843\n",
      "Epoch 45/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7519 - d_loss: 0.6794\n",
      "Epoch 46/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.7502 - d_loss: 0.6771\n",
      "Epoch 47/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7500 - d_loss: 0.6797\n",
      "Epoch 48/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.7640 - d_loss: 0.6799\n",
      "Epoch 49/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.7939 - d_loss: 0.6749\n",
      "Epoch 50/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.7718 - d_loss: 0.6908\n",
      "Epoch 51/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.7396 - d_loss: 0.6811\n",
      "Epoch 52/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7388 - d_loss: 0.6802\n",
      "Epoch 53/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7472 - d_loss: 0.6795\n",
      "Epoch 54/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7623 - d_loss: 0.6760\n",
      "Epoch 55/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7551 - d_loss: 0.6734\n",
      "Epoch 56/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7401 - d_loss: 0.6851\n",
      "Epoch 57/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7542 - d_loss: 0.6735\n",
      "Epoch 58/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7732 - d_loss: 0.6816\n",
      "Epoch 59/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7655 - d_loss: 0.6817\n",
      "Epoch 60/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7602 - d_loss: 0.6704\n",
      "Epoch 61/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7547 - d_loss: 0.6752\n",
      "Epoch 62/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7857 - d_loss: 0.6626\n",
      "Epoch 63/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7740 - d_loss: 0.6645\n",
      "Epoch 64/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8267 - d_loss: 0.6725\n",
      "Epoch 65/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7719 - d_loss: 0.6669\n",
      "Epoch 66/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.7598 - d_loss: 0.6830\n",
      "Epoch 67/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7662 - d_loss: 0.6790\n",
      "Epoch 68/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.7934 - d_loss: 0.6659\n",
      "Epoch 69/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7866 - d_loss: 0.6658\n",
      "Epoch 70/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7750 - d_loss: 0.6726\n",
      "Epoch 71/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7734 - d_loss: 0.6693\n",
      "Epoch 72/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7712 - d_loss: 0.6695\n",
      "Epoch 73/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7742 - d_loss: 0.6673\n",
      "Epoch 74/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.7877 - d_loss: 0.6629\n",
      "Epoch 75/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.8026 - d_loss: 0.6578\n",
      "Epoch 76/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8129 - d_loss: 0.6540\n",
      "Epoch 77/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8496 - d_loss: 0.6450\n",
      "Epoch 78/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8072 - d_loss: 0.6522\n",
      "Epoch 79/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7811 - d_loss: 0.6716\n",
      "Epoch 80/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7876 - d_loss: 0.6681\n",
      "Epoch 81/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8026 - d_loss: 0.6538\n",
      "Epoch 82/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7838 - d_loss: 0.6690\n",
      "Epoch 83/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8059 - d_loss: 0.6686\n",
      "Epoch 84/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.7799 - d_loss: 0.6809\n",
      "Epoch 85/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.7691 - d_loss: 0.6839\n",
      "Epoch 86/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.7984 - d_loss: 0.6601\n",
      "Epoch 87/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8195 - d_loss: 0.6524\n",
      "Epoch 88/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8156 - d_loss: 0.6645\n",
      "Epoch 89/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8256 - d_loss: 0.6542\n",
      "Epoch 90/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8046 - d_loss: 0.6573\n",
      "Epoch 91/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8112 - d_loss: 0.6497\n",
      "Epoch 92/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8097 - d_loss: 0.6559\n",
      "Epoch 93/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8529 - d_loss: 0.6503\n",
      "Epoch 94/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8159 - d_loss: 0.6614\n",
      "Epoch 95/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.7977 - d_loss: 0.6765\n",
      "Epoch 96/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8586 - d_loss: 0.6382\n",
      "Epoch 97/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.8219 - d_loss: 0.6609\n",
      "Epoch 98/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8260 - d_loss: 0.6499\n",
      "Epoch 99/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8307 - d_loss: 0.6472\n",
      "Epoch 100/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.8248 - d_loss: 0.6433\n",
      "Epoch 101/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8270 - d_loss: 0.6374\n",
      "Epoch 102/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8281 - d_loss: 0.6461\n",
      "Epoch 103/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8437 - d_loss: 0.6382\n",
      "Epoch 104/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8210 - d_loss: 0.6521\n",
      "Epoch 105/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8440 - d_loss: 0.6370\n",
      "Epoch 106/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8176 - d_loss: 0.6619\n",
      "Epoch 107/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8398 - d_loss: 0.6506\n",
      "Epoch 108/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.8259 - d_loss: 0.6596\n",
      "Epoch 109/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8226 - d_loss: 0.6431\n",
      "Epoch 110/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8544 - d_loss: 0.6422\n",
      "Epoch 111/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8204 - d_loss: 0.6509\n",
      "Epoch 112/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8431 - d_loss: 0.6324\n",
      "Epoch 113/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8556 - d_loss: 0.6331\n",
      "Epoch 114/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8393 - d_loss: 0.6497\n",
      "Epoch 115/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8472 - d_loss: 0.6338\n",
      "Epoch 116/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.8264 - d_loss: 0.6438\n",
      "Epoch 117/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8624 - d_loss: 0.6331\n",
      "Epoch 118/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8322 - d_loss: 0.6689\n",
      "Epoch 119/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8439 - d_loss: 0.6361\n",
      "Epoch 120/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8553 - d_loss: 0.6322\n",
      "Epoch 121/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8564 - d_loss: 0.6504\n",
      "Epoch 122/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8537 - d_loss: 0.6334\n",
      "Epoch 123/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8347 - d_loss: 0.6569\n",
      "Epoch 124/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8771 - d_loss: 0.6203\n",
      "Epoch 125/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8329 - d_loss: 0.6591\n",
      "Epoch 126/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8501 - d_loss: 0.6385\n",
      "Epoch 127/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8742 - d_loss: 0.6283\n",
      "Epoch 128/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8260 - d_loss: 0.6531\n",
      "Epoch 129/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8651 - d_loss: 0.6366\n",
      "Epoch 130/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8335 - d_loss: 0.6560\n",
      "Epoch 131/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8292 - d_loss: 0.6515\n",
      "Epoch 132/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8686 - d_loss: 0.6255\n",
      "Epoch 133/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8667 - d_loss: 0.6319\n",
      "Epoch 134/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8467 - d_loss: 0.6425\n",
      "Epoch 135/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8796 - d_loss: 0.6321\n",
      "Epoch 136/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8823 - d_loss: 0.6127\n",
      "Epoch 137/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8921 - d_loss: 0.6258\n",
      "Epoch 138/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8825 - d_loss: 0.6337\n",
      "Epoch 139/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.8859 - d_loss: 0.6165\n",
      "Epoch 140/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8462 - d_loss: 0.6608\n",
      "Epoch 141/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8805 - d_loss: 0.6229\n",
      "Epoch 142/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8999 - d_loss: 0.6071\n",
      "Epoch 143/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9071 - d_loss: 0.6113\n",
      "Epoch 144/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8920 - d_loss: 0.6239\n",
      "Epoch 145/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8937 - d_loss: 0.6203\n",
      "Epoch 146/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8553 - d_loss: 0.6328\n",
      "Epoch 147/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9039 - d_loss: 0.6172\n",
      "Epoch 148/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8422 - d_loss: 0.6670\n",
      "Epoch 149/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8679 - d_loss: 0.6598\n",
      "Epoch 150/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9297 - d_loss: 0.5991\n",
      "Epoch 151/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8849 - d_loss: 0.6190\n",
      "Epoch 152/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9211 - d_loss: 0.6001\n",
      "Epoch 153/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8907 - d_loss: 0.6239\n",
      "Epoch 154/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9177 - d_loss: 0.6105\n",
      "Epoch 155/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9111 - d_loss: 0.6148\n",
      "Epoch 156/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8980 - d_loss: 0.6218\n",
      "Epoch 157/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9110 - d_loss: 0.6061\n",
      "Epoch 158/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9092 - d_loss: 0.6094\n",
      "Epoch 159/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8855 - d_loss: 0.6331\n",
      "Epoch 160/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9492 - d_loss: 0.5813\n",
      "Epoch 161/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9237 - d_loss: 0.6179\n",
      "Epoch 162/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9079 - d_loss: 0.6097\n",
      "Epoch 163/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9249 - d_loss: 0.6105\n",
      "Epoch 164/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8533 - d_loss: 0.6744\n",
      "Epoch 165/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8821 - d_loss: 0.6428\n",
      "Epoch 166/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8880 - d_loss: 0.6268\n",
      "Epoch 167/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9285 - d_loss: 0.6090\n",
      "Epoch 168/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9037 - d_loss: 0.6242\n",
      "Epoch 169/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8858 - d_loss: 0.6228\n",
      "Epoch 170/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9060 - d_loss: 0.6165\n",
      "Epoch 171/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9171 - d_loss: 0.5995\n",
      "Epoch 172/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9325 - d_loss: 0.6030\n",
      "Epoch 173/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9331 - d_loss: 0.6257\n",
      "Epoch 174/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9344 - d_loss: 0.6004\n",
      "Epoch 175/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8923 - d_loss: 0.6400\n",
      "Epoch 176/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9849 - d_loss: 0.5730\n",
      "Epoch 177/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8796 - d_loss: 0.6310\n",
      "Epoch 178/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9355 - d_loss: 0.6087\n",
      "Epoch 179/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9254 - d_loss: 0.6050\n",
      "Epoch 180/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9400 - d_loss: 0.6062\n",
      "Epoch 181/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8802 - d_loss: 0.6329\n",
      "Epoch 182/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9776 - d_loss: 0.5932\n",
      "Epoch 183/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9835 - d_loss: 0.5877\n",
      "Epoch 184/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9553 - d_loss: 0.6057\n",
      "Epoch 185/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9262 - d_loss: 0.6176\n",
      "Epoch 186/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9469 - d_loss: 0.5891\n",
      "Epoch 187/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9528 - d_loss: 0.5970\n",
      "Epoch 188/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9367 - d_loss: 0.6052\n",
      "Epoch 189/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9468 - d_loss: 0.6030\n",
      "Epoch 190/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9751 - d_loss: 0.5946\n",
      "Epoch 191/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9357 - d_loss: 0.6216\n",
      "Epoch 192/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9199 - d_loss: 0.6156\n",
      "Epoch 193/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9515 - d_loss: 0.5936\n",
      "Epoch 194/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9181 - d_loss: 0.6258\n",
      "Epoch 195/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9263 - d_loss: 0.6048\n",
      "Epoch 196/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9075 - d_loss: 0.6104\n",
      "Epoch 197/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9148 - d_loss: 0.6366\n",
      "Epoch 198/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9035 - d_loss: 0.6231\n",
      "Epoch 199/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9423 - d_loss: 0.6071\n",
      "Epoch 200/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9335 - d_loss: 0.6085\n",
      "Epoch 201/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8994 - d_loss: 0.6437\n",
      "Epoch 202/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9081 - d_loss: 0.6146\n",
      "Epoch 203/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8973 - d_loss: 0.6278\n",
      "Epoch 204/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8921 - d_loss: 0.6221\n",
      "Epoch 205/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9076 - d_loss: 0.6171\n",
      "Epoch 206/500\n",
      "146/146 [==============================] - 10s 71ms/step - g_loss: 0.8703 - d_loss: 0.6282\n",
      "Epoch 207/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9452 - d_loss: 0.6070\n",
      "Epoch 208/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8879 - d_loss: 0.6394\n",
      "Epoch 209/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8965 - d_loss: 0.6453\n",
      "Epoch 210/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9120 - d_loss: 0.6102\n",
      "Epoch 211/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9331 - d_loss: 0.6050\n",
      "Epoch 212/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9597 - d_loss: 0.5946\n",
      "Epoch 213/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9216 - d_loss: 0.6069\n",
      "Epoch 214/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8956 - d_loss: 0.6332\n",
      "Epoch 215/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9232 - d_loss: 0.6081\n",
      "Epoch 216/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9090 - d_loss: 0.6325\n",
      "Epoch 217/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9266 - d_loss: 0.5980\n",
      "Epoch 218/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9555 - d_loss: 0.5919\n",
      "Epoch 219/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9325 - d_loss: 0.6202\n",
      "Epoch 220/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9224 - d_loss: 0.6202\n",
      "Epoch 221/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8944 - d_loss: 0.6155\n",
      "Epoch 222/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9212 - d_loss: 0.6319\n",
      "Epoch 223/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9780 - d_loss: 0.5958\n",
      "Epoch 224/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9444 - d_loss: 0.5953\n",
      "Epoch 225/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9294 - d_loss: 0.6121\n",
      "Epoch 226/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9522 - d_loss: 0.6041\n",
      "Epoch 227/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9001 - d_loss: 0.6375\n",
      "Epoch 228/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9407 - d_loss: 0.6098\n",
      "Epoch 229/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.8828 - d_loss: 0.6324\n",
      "Epoch 230/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9612 - d_loss: 0.6018\n",
      "Epoch 231/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9495 - d_loss: 0.5876\n",
      "Epoch 232/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9287 - d_loss: 0.6214\n",
      "Epoch 233/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9843 - d_loss: 0.5917\n",
      "Epoch 234/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9687 - d_loss: 0.6117\n",
      "Epoch 235/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9671 - d_loss: 0.6030\n",
      "Epoch 236/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9507 - d_loss: 0.6353\n",
      "Epoch 237/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9744 - d_loss: 0.5864\n",
      "Epoch 238/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9141 - d_loss: 0.6139\n",
      "Epoch 239/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9506 - d_loss: 0.6186\n",
      "Epoch 240/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9313 - d_loss: 0.6098\n",
      "Epoch 241/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9503 - d_loss: 0.5875\n",
      "Epoch 242/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9578 - d_loss: 0.6117\n",
      "Epoch 243/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9076 - d_loss: 0.6160\n",
      "Epoch 244/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9653 - d_loss: 0.5892\n",
      "Epoch 245/500\n",
      "146/146 [==============================] - 11s 75ms/step - g_loss: 0.9699 - d_loss: 0.5920\n",
      "Epoch 246/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8856 - d_loss: 0.6265\n",
      "Epoch 247/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9515 - d_loss: 0.6012\n",
      "Epoch 248/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9787 - d_loss: 0.5995\n",
      "Epoch 249/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8947 - d_loss: 0.6414\n",
      "Epoch 250/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0047 - d_loss: 0.5712\n",
      "Epoch 251/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9551 - d_loss: 0.6030\n",
      "Epoch 252/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9617 - d_loss: 0.5959\n",
      "Epoch 253/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9732 - d_loss: 0.5894\n",
      "Epoch 254/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0112 - d_loss: 0.5859\n",
      "Epoch 255/500\n",
      "146/146 [==============================] - 10s 71ms/step - g_loss: 0.9989 - d_loss: 0.5819\n",
      "Epoch 256/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9294 - d_loss: 0.6387\n",
      "Epoch 257/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9589 - d_loss: 0.6000\n",
      "Epoch 258/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9376 - d_loss: 0.6052\n",
      "Epoch 259/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9695 - d_loss: 0.5986\n",
      "Epoch 260/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9373 - d_loss: 0.6414\n",
      "Epoch 261/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9892 - d_loss: 0.5860\n",
      "Epoch 262/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9444 - d_loss: 0.5969\n",
      "Epoch 263/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8833 - d_loss: 0.6386\n",
      "Epoch 264/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9905 - d_loss: 0.5900\n",
      "Epoch 265/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9943 - d_loss: 0.5802\n",
      "Epoch 266/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9703 - d_loss: 0.6044\n",
      "Epoch 267/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9423 - d_loss: 0.6102\n",
      "Epoch 268/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9538 - d_loss: 0.6051\n",
      "Epoch 269/500\n",
      "146/146 [==============================] - 10s 71ms/step - g_loss: 0.9763 - d_loss: 0.5907\n",
      "Epoch 270/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0024 - d_loss: 0.5695\n",
      "Epoch 271/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0183 - d_loss: 0.5647\n",
      "Epoch 272/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9966 - d_loss: 0.5808\n",
      "Epoch 273/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0674 - d_loss: 0.5580\n",
      "Epoch 274/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0630 - d_loss: 0.5629\n",
      "Epoch 275/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0600 - d_loss: 0.5556\n",
      "Epoch 276/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0091 - d_loss: 0.5922\n",
      "Epoch 277/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0388 - d_loss: 0.5731\n",
      "Epoch 278/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9288 - d_loss: 0.6338\n",
      "Epoch 279/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0210 - d_loss: 0.5790\n",
      "Epoch 280/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9691 - d_loss: 0.6026\n",
      "Epoch 281/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9232 - d_loss: 0.6077\n",
      "Epoch 282/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9497 - d_loss: 0.6296\n",
      "Epoch 283/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0095 - d_loss: 0.5862\n",
      "Epoch 284/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0336 - d_loss: 0.5755\n",
      "Epoch 285/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0086 - d_loss: 0.5963\n",
      "Epoch 286/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9943 - d_loss: 0.5777\n",
      "Epoch 287/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0105 - d_loss: 0.5797\n",
      "Epoch 288/500\n",
      "146/146 [==============================] - 10s 71ms/step - g_loss: 0.9814 - d_loss: 0.6068\n",
      "Epoch 289/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0284 - d_loss: 0.5620\n",
      "Epoch 290/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 1.0016 - d_loss: 0.5723\n",
      "Epoch 291/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9611 - d_loss: 0.5998\n",
      "Epoch 292/500\n",
      "146/146 [==============================] - 10s 71ms/step - g_loss: 0.9453 - d_loss: 0.6341\n",
      "Epoch 293/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9975 - d_loss: 0.5885\n",
      "Epoch 294/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9751 - d_loss: 0.5962\n",
      "Epoch 295/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9124 - d_loss: 0.6419\n",
      "Epoch 296/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9632 - d_loss: 0.6292\n",
      "Epoch 297/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9664 - d_loss: 0.5897\n",
      "Epoch 298/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9226 - d_loss: 0.6282\n",
      "Epoch 299/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9588 - d_loss: 0.5966\n",
      "Epoch 300/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9985 - d_loss: 0.5860\n",
      "Epoch 301/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0004 - d_loss: 0.5869\n",
      "Epoch 302/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9835 - d_loss: 0.5973\n",
      "Epoch 303/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9674 - d_loss: 0.5890\n",
      "Epoch 304/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0041 - d_loss: 0.5854\n",
      "Epoch 305/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9230 - d_loss: 0.6224\n",
      "Epoch 306/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9720 - d_loss: 0.6106\n",
      "Epoch 307/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9890 - d_loss: 0.5794\n",
      "Epoch 308/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9974 - d_loss: 0.6000\n",
      "Epoch 309/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9965 - d_loss: 0.5926\n",
      "Epoch 310/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0020 - d_loss: 0.5812\n",
      "Epoch 311/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9844 - d_loss: 0.6083\n",
      "Epoch 312/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9882 - d_loss: 0.5710\n",
      "Epoch 313/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9727 - d_loss: 0.5829\n",
      "Epoch 314/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9427 - d_loss: 0.6539\n",
      "Epoch 315/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0174 - d_loss: 0.5650\n",
      "Epoch 316/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9957 - d_loss: 0.5912\n",
      "Epoch 317/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9878 - d_loss: 0.5820\n",
      "Epoch 318/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9846 - d_loss: 0.5792\n",
      "Epoch 319/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9835 - d_loss: 0.5719\n",
      "Epoch 320/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9832 - d_loss: 0.6116\n",
      "Epoch 321/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9499 - d_loss: 0.6042\n",
      "Epoch 322/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9886 - d_loss: 0.5799\n",
      "Epoch 323/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9371 - d_loss: 0.6076\n",
      "Epoch 324/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.8955 - d_loss: 0.6645\n",
      "Epoch 325/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9764 - d_loss: 0.5914\n",
      "Epoch 326/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9930 - d_loss: 0.5852\n",
      "Epoch 327/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9764 - d_loss: 0.5996\n",
      "Epoch 328/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9767 - d_loss: 0.5947\n",
      "Epoch 329/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9704 - d_loss: 0.6125\n",
      "Epoch 330/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9362 - d_loss: 0.6090\n",
      "Epoch 331/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9336 - d_loss: 0.6320\n",
      "Epoch 332/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0309 - d_loss: 0.5746\n",
      "Epoch 333/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9201 - d_loss: 0.6308\n",
      "Epoch 334/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0013 - d_loss: 0.5847\n",
      "Epoch 335/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9865 - d_loss: 0.5992\n",
      "Epoch 336/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9629 - d_loss: 0.6362\n",
      "Epoch 337/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9690 - d_loss: 0.6016\n",
      "Epoch 338/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.8813 - d_loss: 0.6627\n",
      "Epoch 339/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9757 - d_loss: 0.5894\n",
      "Epoch 340/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9692 - d_loss: 0.5904\n",
      "Epoch 341/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0026 - d_loss: 0.5803\n",
      "Epoch 342/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9299 - d_loss: 0.6290\n",
      "Epoch 343/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0283 - d_loss: 0.5923\n",
      "Epoch 344/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9311 - d_loss: 0.6458\n",
      "Epoch 345/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0015 - d_loss: 0.5909\n",
      "Epoch 346/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9906 - d_loss: 0.5886\n",
      "Epoch 347/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 1.0152 - d_loss: 0.5850\n",
      "Epoch 348/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9914 - d_loss: 0.5708\n",
      "Epoch 349/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0054 - d_loss: 0.5787\n",
      "Epoch 350/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9731 - d_loss: 0.6153\n",
      "Epoch 351/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0401 - d_loss: 0.5751\n",
      "Epoch 352/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9999 - d_loss: 0.5959\n",
      "Epoch 353/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9253 - d_loss: 0.6633\n",
      "Epoch 354/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0008 - d_loss: 0.5856\n",
      "Epoch 355/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9448 - d_loss: 0.6219\n",
      "Epoch 356/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 1.0596 - d_loss: 0.5534\n",
      "Epoch 357/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0238 - d_loss: 0.5838\n",
      "Epoch 358/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9885 - d_loss: 0.5859\n",
      "Epoch 359/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9282 - d_loss: 0.6220\n",
      "Epoch 360/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9451 - d_loss: 0.6227\n",
      "Epoch 361/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9747 - d_loss: 0.5935\n",
      "Epoch 362/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9543 - d_loss: 0.5832\n",
      "Epoch 363/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9797 - d_loss: 0.5890\n",
      "Epoch 364/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9735 - d_loss: 0.5982\n",
      "Epoch 365/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9250 - d_loss: 0.6458\n",
      "Epoch 366/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0376 - d_loss: 0.5627\n",
      "Epoch 367/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9668 - d_loss: 0.6011\n",
      "Epoch 368/500\n",
      "146/146 [==============================] - 11s 75ms/step - g_loss: 1.0296 - d_loss: 0.5737\n",
      "Epoch 369/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9361 - d_loss: 0.6165\n",
      "Epoch 370/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0148 - d_loss: 0.5747\n",
      "Epoch 371/500\n",
      "146/146 [==============================] - 10s 71ms/step - g_loss: 1.0028 - d_loss: 0.5831\n",
      "Epoch 372/500\n",
      "146/146 [==============================] - 10s 71ms/step - g_loss: 0.9798 - d_loss: 0.5991\n",
      "Epoch 373/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9899 - d_loss: 0.6007\n",
      "Epoch 374/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0210 - d_loss: 0.5725\n",
      "Epoch 375/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9972 - d_loss: 0.5854\n",
      "Epoch 376/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0219 - d_loss: 0.5706\n",
      "Epoch 377/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0531 - d_loss: 0.5492\n",
      "Epoch 378/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0448 - d_loss: 0.5667\n",
      "Epoch 379/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0819 - d_loss: 0.5618\n",
      "Epoch 380/500\n",
      "146/146 [==============================] - 10s 71ms/step - g_loss: 0.9699 - d_loss: 0.6122\n",
      "Epoch 381/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0352 - d_loss: 0.5617\n",
      "Epoch 382/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0334 - d_loss: 0.5875\n",
      "Epoch 383/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0442 - d_loss: 0.5654\n",
      "Epoch 384/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.1062 - d_loss: 0.5391\n",
      "Epoch 385/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0821 - d_loss: 0.5645\n",
      "Epoch 386/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 1.0927 - d_loss: 0.5392\n",
      "Epoch 387/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.1185 - d_loss: 0.5418\n",
      "Epoch 388/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.1093 - d_loss: 0.5427\n",
      "Epoch 389/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0876 - d_loss: 0.5498\n",
      "Epoch 390/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0916 - d_loss: 0.5600\n",
      "Epoch 391/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0452 - d_loss: 0.5766\n",
      "Epoch 392/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.1129 - d_loss: 0.5325\n",
      "Epoch 393/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0774 - d_loss: 0.5661\n",
      "Epoch 394/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.1307 - d_loss: 0.5197\n",
      "Epoch 395/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 1.1481 - d_loss: 0.5537\n",
      "Epoch 396/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0962 - d_loss: 0.5472\n",
      "Epoch 397/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0005 - d_loss: 0.6296\n",
      "Epoch 398/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0842 - d_loss: 0.5572\n",
      "Epoch 399/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0175 - d_loss: 0.5942\n",
      "Epoch 400/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0072 - d_loss: 0.5788\n",
      "Epoch 401/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9909 - d_loss: 0.6181\n",
      "Epoch 402/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0178 - d_loss: 0.5938\n",
      "Epoch 403/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0231 - d_loss: 0.5812\n",
      "Epoch 404/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0251 - d_loss: 0.5806\n",
      "Epoch 405/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9503 - d_loss: 0.6164\n",
      "Epoch 406/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0221 - d_loss: 0.5672\n",
      "Epoch 407/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9954 - d_loss: 0.5832\n",
      "Epoch 408/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0307 - d_loss: 0.5656\n",
      "Epoch 409/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0378 - d_loss: 0.5696\n",
      "Epoch 410/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0244 - d_loss: 0.5785\n",
      "Epoch 411/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9788 - d_loss: 0.5848\n",
      "Epoch 412/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0161 - d_loss: 0.5749\n",
      "Epoch 413/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9585 - d_loss: 0.5893\n",
      "Epoch 414/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0244 - d_loss: 0.5820\n",
      "Epoch 415/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0190 - d_loss: 0.5766\n",
      "Epoch 416/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9867 - d_loss: 0.6336\n",
      "Epoch 417/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0796 - d_loss: 0.5789\n",
      "Epoch 418/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0818 - d_loss: 0.5561\n",
      "Epoch 419/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0714 - d_loss: 0.5599\n",
      "Epoch 420/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0032 - d_loss: 0.6086\n",
      "Epoch 421/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0029 - d_loss: 0.5737\n",
      "Epoch 422/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9590 - d_loss: 0.6217\n",
      "Epoch 423/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0490 - d_loss: 0.5631\n",
      "Epoch 424/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9690 - d_loss: 0.6250\n",
      "Epoch 425/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0014 - d_loss: 0.6147\n",
      "Epoch 426/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0040 - d_loss: 0.5795\n",
      "Epoch 427/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0329 - d_loss: 0.5647\n",
      "Epoch 428/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0434 - d_loss: 0.5618\n",
      "Epoch 429/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0312 - d_loss: 0.5779\n",
      "Epoch 430/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0028 - d_loss: 0.5834\n",
      "Epoch 431/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9969 - d_loss: 0.6144\n",
      "Epoch 432/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9985 - d_loss: 0.6004\n",
      "Epoch 433/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9879 - d_loss: 0.6072\n",
      "Epoch 434/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9313 - d_loss: 0.6294\n",
      "Epoch 435/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0524 - d_loss: 0.5613\n",
      "Epoch 436/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9792 - d_loss: 0.5905\n",
      "Epoch 437/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.1137 - d_loss: 0.5269\n",
      "Epoch 438/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.1204 - d_loss: 0.5364\n",
      "Epoch 439/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 1.0508 - d_loss: 0.5997\n",
      "Epoch 440/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0778 - d_loss: 0.5593\n",
      "Epoch 441/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0632 - d_loss: 0.5574\n",
      "Epoch 442/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0660 - d_loss: 0.5687\n",
      "Epoch 443/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0337 - d_loss: 0.5738\n",
      "Epoch 444/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0615 - d_loss: 0.5530\n",
      "Epoch 445/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0497 - d_loss: 0.5583\n",
      "Epoch 446/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0318 - d_loss: 0.5770\n",
      "Epoch 447/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0889 - d_loss: 0.5461\n",
      "Epoch 448/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9774 - d_loss: 0.6173\n",
      "Epoch 449/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0228 - d_loss: 0.5859\n",
      "Epoch 450/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9926 - d_loss: 0.6017\n",
      "Epoch 451/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9388 - d_loss: 0.6299\n",
      "Epoch 452/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0169 - d_loss: 0.5642\n",
      "Epoch 453/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0133 - d_loss: 0.5651\n",
      "Epoch 454/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0724 - d_loss: 0.5597\n",
      "Epoch 455/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9786 - d_loss: 0.6140\n",
      "Epoch 456/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0306 - d_loss: 0.5709\n",
      "Epoch 457/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9882 - d_loss: 0.6043\n",
      "Epoch 458/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 0.9976 - d_loss: 0.5866\n",
      "Epoch 459/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 1.0623 - d_loss: 0.5736\n",
      "Epoch 460/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9803 - d_loss: 0.5991\n",
      "Epoch 461/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0588 - d_loss: 0.5912\n",
      "Epoch 462/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0166 - d_loss: 0.5786\n",
      "Epoch 463/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0404 - d_loss: 0.5764\n",
      "Epoch 464/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9896 - d_loss: 0.6048\n",
      "Epoch 465/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 0.9676 - d_loss: 0.6110\n",
      "Epoch 466/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0613 - d_loss: 0.5749\n",
      "Epoch 467/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0580 - d_loss: 0.5571\n",
      "Epoch 468/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0646 - d_loss: 0.5479\n",
      "Epoch 469/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0735 - d_loss: 0.5514\n",
      "Epoch 470/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0184 - d_loss: 0.5878\n",
      "Epoch 471/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0503 - d_loss: 0.5667\n",
      "Epoch 472/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0821 - d_loss: 0.5652\n",
      "Epoch 473/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0539 - d_loss: 0.5727\n",
      "Epoch 474/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0454 - d_loss: 0.5641\n",
      "Epoch 475/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0267 - d_loss: 0.5546\n",
      "Epoch 476/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.1050 - d_loss: 0.5703\n",
      "Epoch 477/500\n",
      "146/146 [==============================] - 11s 75ms/step - g_loss: 1.0261 - d_loss: 0.5790\n",
      "Epoch 478/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0110 - d_loss: 0.6052\n",
      "Epoch 479/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0813 - d_loss: 0.5802\n",
      "Epoch 480/500\n",
      "146/146 [==============================] - 11s 73ms/step - g_loss: 1.0386 - d_loss: 0.6042\n",
      "Epoch 481/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9440 - d_loss: 0.6341\n",
      "Epoch 482/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0114 - d_loss: 0.5953\n",
      "Epoch 483/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0422 - d_loss: 0.5469\n",
      "Epoch 484/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0571 - d_loss: 0.5695\n",
      "Epoch 485/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0417 - d_loss: 0.5751\n",
      "Epoch 486/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0301 - d_loss: 0.5746\n",
      "Epoch 487/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0082 - d_loss: 0.5855\n",
      "Epoch 488/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0306 - d_loss: 0.5859\n",
      "Epoch 489/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9762 - d_loss: 0.5899\n",
      "Epoch 490/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0170 - d_loss: 0.5534\n",
      "Epoch 491/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0365 - d_loss: 0.5642\n",
      "Epoch 492/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0224 - d_loss: 0.5846\n",
      "Epoch 493/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 0.9685 - d_loss: 0.6193\n",
      "Epoch 494/500\n",
      "146/146 [==============================] - 11s 74ms/step - g_loss: 1.0239 - d_loss: 0.5794\n",
      "Epoch 495/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 0.9737 - d_loss: 0.5973\n",
      "Epoch 496/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0152 - d_loss: 0.5626\n",
      "Epoch 497/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0379 - d_loss: 0.5674\n",
      "Epoch 498/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0707 - d_loss: 0.5789\n",
      "Epoch 499/500\n",
      "146/146 [==============================] - 10s 72ms/step - g_loss: 1.0201 - d_loss: 0.5607\n",
      "Epoch 500/500\n",
      "146/146 [==============================] - 11s 72ms/step - g_loss: 1.0686 - d_loss: 0.5456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f00c0bb5490>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan.fit(dataset, epochs=epoch_t, \n",
    "        callbacks=GANMonitor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb007955",
   "metadata": {
    "papermill": {
     "duration": 24.14407,
     "end_time": "2022-04-10T22:01:40.040031",
     "exception": false,
     "start_time": "2022-04-10T22:01:15.895961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Interpolating between classes with the trained GEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "affa6229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T22:02:29.159815Z",
     "iopub.status.busy": "2022-04-10T22:02:29.158969Z",
     "iopub.status.idle": "2022-04-10T22:02:29.167503Z",
     "shell.execute_reply": "2022-04-10T22:02:29.167059Z"
    },
    "papermill": {
     "duration": 24.810807,
     "end_time": "2022-04-10T22:02:29.167621",
     "exception": false,
     "start_time": "2022-04-10T22:02:04.356814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We first extract the trained generator from our Conditiona GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 2000  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = tf.cast(first_label, tf.float32)\n",
    "    second_label = tf.cast(second_label, tf.float32)\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f5e28d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T22:03:17.144894Z",
     "iopub.status.busy": "2022-04-10T22:03:17.144050Z",
     "iopub.status.idle": "2022-04-10T22:03:17.146409Z",
     "shell.execute_reply": "2022-04-10T22:03:17.145862Z"
    },
    "papermill": {
     "duration": 24.256108,
     "end_time": "2022-04-10T22:03:17.146521",
     "exception": false,
     "start_time": "2022-04-10T22:02:52.890413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create new directory for saving folder\n",
    "os.makedirs(path_save_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "851011e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T22:04:05.062913Z",
     "iopub.status.busy": "2022-04-10T22:04:05.061284Z",
     "iopub.status.idle": "2022-04-10T22:04:05.063474Z",
     "shell.execute_reply": "2022-04-10T22:04:05.063916Z"
    },
    "papermill": {
     "duration": 23.529268,
     "end_time": "2022-04-10T22:04:05.064068",
     "exception": false,
     "start_time": "2022-04-10T22:03:41.534800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve class name based on number\n",
    "classes_list = list(prelim_dataset.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae400cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T22:04:53.891747Z",
     "iopub.status.busy": "2022-04-10T22:04:53.891075Z",
     "iopub.status.idle": "2022-04-10T22:05:27.210240Z",
     "shell.execute_reply": "2022-04-10T22:05:27.209735Z"
    },
    "papermill": {
     "duration": 57.740472,
     "end_time": "2022-04-10T22:05:27.210376",
     "exception": false,
     "start_time": "2022-04-10T22:04:29.469904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(num_classes):\n",
    "    class_name = classes_list[i]\n",
    "    class_dir = f\"{path_save_imgs}/{class_name}\"\n",
    "    os.makedirs(class_dir)\n",
    "    start_class = i\n",
    "    end_class = i\n",
    "    fake_images = interpolate_class(start_class, end_class)\n",
    "    fake_images *= 255\n",
    "    converted_images = fake_images.astype(np.uint8)\n",
    "    converted_images = tf.image.resize(converted_images, (64, 64)).numpy().astype(np.uint8)\n",
    "    for j in range(num_interpolation):\n",
    "        np_array = np.squeeze(converted_images[j], axis=2)\n",
    "        im = Image.fromarray((np_array))\n",
    "        im.save(f\"{class_dir}/gen_imgs_{class_name}_{j}.png\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8246.37575,
   "end_time": "2022-04-10T22:05:54.970809",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-10T19:48:28.595059",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
