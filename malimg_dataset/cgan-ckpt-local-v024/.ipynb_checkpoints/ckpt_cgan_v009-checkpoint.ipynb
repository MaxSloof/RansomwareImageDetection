{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de546011",
   "metadata": {},
   "source": [
    "# Conditional GAN\n",
    "\n",
    "Used to generate new training data for the ransomware families to overcome the skewed distribution of training data towards the benign samples\n",
    "\n",
    "Ran for over 1500 epochs (1000 Kaggle & 500 local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "176d8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d338ac",
   "metadata": {},
   "source": [
    "**Change parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b44d3f",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d37ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Color mode\n",
    "ch = 'grayscale'\n",
    "\n",
    "# Image size\n",
    "iw, ih = 64,64\n",
    "im_size = (iw,ih)\n",
    "\n",
    "# Latent dim size\n",
    "latent_dim = 128\n",
    "\n",
    "# Number of Epochs\n",
    "epoch_t = 500\n",
    "\n",
    "# Computation environment: Kaggle (0) or Local (1)\n",
    "cenv = 1\n",
    "\n",
    "# If weights are used: Weight factor\n",
    "wf = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd651cb4",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd315bc2",
   "metadata": {},
   "source": [
    "Automatic notebook preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50855d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(ch == 'rgb'):\n",
    "    chnum = 3\n",
    "elif(ch == 'grayscale'):\n",
    "    chnum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "193e04b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 matches(es) found\n",
      "--------------\n",
      "New folder name: cgan-local-v130\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "if cenv == 1:\n",
    "    file_exists = []\n",
    "    vnum = 1\n",
    "    dir = \"C:/Users/Max/Documents/GitHub/malimg_dataset/\"\n",
    "    for files in os.listdir(dir):\n",
    "        if \"cgan\" in files:\n",
    "            try:\n",
    "                vnum = max(vnum, int(files[-3:]))\n",
    "            except: \n",
    "                continue\n",
    "            new_vnum = vnum + 1\n",
    "            file_exists.append(True)\n",
    "        else: \n",
    "            file_exists.append(False)\n",
    "    # If this is the first notebook you want to save, a new folder will be created with version #001\n",
    "    if sum(file_exists) == 0:\n",
    "        new_vnum = 1\n",
    "        print(\"No matches found\")\n",
    "\n",
    "    else: \n",
    "        print(f\"{sum(file_exists)} matches(es) found\")\n",
    "        print(\"--------------\")\n",
    "\n",
    "    # Print new folder name\n",
    "    print(f\"New folder name: cgan-local-v{new_vnum:03}\")\n",
    "    print(\"--------------\")\n",
    "    \n",
    "    # Create new folder with the name of the notebook and the version number\n",
    "    new_dir = f\"C://Users/Max/Documents/GitHub/malimg_dataset/cgan_checkpoint-local-v{new_vnum:03}\"\n",
    "    os.makedirs(new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30853b",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06d54d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cenv == 0:\n",
    "    path_root = \"/kaggle/input/data-wo-benign\"\n",
    "    path_save_imgs = \"/kaggle/working/numpy_arrays/\"\n",
    "if cenv == 1:\n",
    "    path_root = \"C:/Users/Max/Documents/image_data/malimg_paper_dataset_imgs\"\n",
    "    path_save_imgs = f\"C:/Users/Max/Documents/image_data/malimg_cgan_ckpt_v025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6642f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1/255 # Pixel values need to be scaled between 0 and 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e800a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4549c79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9339 images belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "prelim_dataset = datagen.flow_from_directory(\n",
    "    directory = path_root,\n",
    "    color_mode = ch,\n",
    "    target_size = im_size,\n",
    "    interpolation = 'bicubic',\n",
    "    batch_size = 40000,\n",
    "    shuffle=False\n",
    ")\n",
    "imgs, labels = next(prelim_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e987c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = prelim_dataset.samples\n",
    "num_classes = max(prelim_dataset.labels) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba425506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adialer.C': 0,\n",
       " 'Agent.FYI': 1,\n",
       " 'Allaple.A': 2,\n",
       " 'Allaple.L': 3,\n",
       " 'Alueron.gen!J': 4,\n",
       " 'Autorun.K': 5,\n",
       " 'C2LOP.P': 6,\n",
       " 'C2LOP.gen!g': 7,\n",
       " 'Dialplatform.B': 8,\n",
       " 'Dontovo.A': 9,\n",
       " 'Fakerean': 10,\n",
       " 'Instantaccess': 11,\n",
       " 'Lolyda.AA1': 12,\n",
       " 'Lolyda.AA2': 13,\n",
       " 'Lolyda.AA3': 14,\n",
       " 'Lolyda.AT': 15,\n",
       " 'Malex.gen!J': 16,\n",
       " 'Obfuscator.AD': 17,\n",
       " 'Rbot!gen': 18,\n",
       " 'Skintrim.N': 19,\n",
       " 'Swizzor.gen!E': 20,\n",
       " 'Swizzor.gen!I': 21,\n",
       " 'VB.AT': 22,\n",
       " 'Wintrim.BX': 23,\n",
       " 'Yuner.A': 24}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prelim_dataset.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b0729",
   "metadata": {},
   "source": [
    "Create tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c29159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((imgs, labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250f6a3",
   "metadata": {},
   "source": [
    "Calculate number of input channel for Gen and Disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c8c4b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 26\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = chnum + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5518b3",
   "metadata": {},
   "source": [
    "# Creating discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5807858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((iw, ih, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73d69a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        layers.Dense(8 * 8 * generator_in_channels),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((8, 8, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f2b6070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        15040     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 236,609\n",
      "Trainable params: 236,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8019d328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 9792)              1507968   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 9792)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 153)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 16, 16, 128)       313472    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 32, 32, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 64, 64, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 1)         6273      \n",
      "=================================================================\n",
      "Total params: 2,352,257\n",
      "Trainable params: 2,352,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16291bdf",
   "metadata": {},
   "source": [
    "**Create Conditional GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1fa8cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[ih * iw]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, iw, ih, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e70546",
   "metadata": {},
   "source": [
    "**Optimizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf8cba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers\n",
    "d_optimizer=keras.optimizers.Adam(learning_rate=0.0003)\n",
    "g_optimizer=keras.optimizers.Adam(learning_rate=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa94c67",
   "metadata": {},
   "source": [
    "**Checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af608a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        # Save the model every 5 epochs \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "          checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b649da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cenv == 0:\n",
    "    checkpoint_dir = '/kaggle/working/checkpoints'\n",
    "if cenv == 1:\n",
    "    checkpoint_dir = f'C:/Users/Max/Documents/GitHub/malimg_dataset/cgan-kaggle-v023/checkpoints'\n",
    "    \n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=g_optimizer,\n",
    "                                 discriminator_optimizer=d_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c715c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2563d897ca0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db7c93",
   "metadata": {},
   "source": [
    "# Training C-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2338e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "146/146 [==============================] - 19s 122ms/step - g_loss: 1.1275 - d_loss: 0.5246\n",
      "Epoch 2/500\n",
      "146/146 [==============================] - 17s 114ms/step - g_loss: 1.0545 - d_loss: 0.5717\n",
      "Epoch 3/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0310 - d_loss: 0.6126\n",
      "Epoch 4/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1506 - d_loss: 0.5458\n",
      "Epoch 5/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2069 - d_loss: 0.4594\n",
      "Epoch 6/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2166 - d_loss: 0.4955\n",
      "Epoch 7/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1096 - d_loss: 0.5737\n",
      "Epoch 8/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1214 - d_loss: 0.5797\n",
      "Epoch 9/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1249 - d_loss: 0.5193\n",
      "Epoch 10/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0777 - d_loss: 0.5829\n",
      "Epoch 11/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1312 - d_loss: 0.5357\n",
      "Epoch 12/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1540 - d_loss: 0.4930\n",
      "Epoch 13/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2240 - d_loss: 0.5081\n",
      "Epoch 14/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1369 - d_loss: 0.5379\n",
      "Epoch 15/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0490 - d_loss: 0.6152\n",
      "Epoch 16/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1444 - d_loss: 0.4980\n",
      "Epoch 17/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1630 - d_loss: 0.5038\n",
      "Epoch 18/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.3061 - d_loss: 0.4719\n",
      "Epoch 19/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1631 - d_loss: 0.5322\n",
      "Epoch 20/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1517 - d_loss: 0.5488\n",
      "Epoch 21/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2734 - d_loss: 0.4526\n",
      "Epoch 22/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2535 - d_loss: 0.5702\n",
      "Epoch 23/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1139 - d_loss: 0.5700\n",
      "Epoch 24/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.0323 - d_loss: 0.6552\n",
      "Epoch 25/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.2152 - d_loss: 0.4936\n",
      "Epoch 26/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1594 - d_loss: 0.5386\n",
      "Epoch 27/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1856 - d_loss: 0.5113\n",
      "Epoch 28/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1634 - d_loss: 0.5280\n",
      "Epoch 29/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0445 - d_loss: 0.5982\n",
      "Epoch 30/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1086 - d_loss: 0.5217\n",
      "Epoch 31/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1790 - d_loss: 0.5047\n",
      "Epoch 32/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1493 - d_loss: 0.5719\n",
      "Epoch 33/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2090 - d_loss: 0.5628\n",
      "Epoch 34/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1182 - d_loss: 0.5388\n",
      "Epoch 35/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1671 - d_loss: 0.5055\n",
      "Epoch 36/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0892 - d_loss: 0.5542\n",
      "Epoch 37/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1872 - d_loss: 0.5117\n",
      "Epoch 38/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2951 - d_loss: 0.4733\n",
      "Epoch 39/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0920 - d_loss: 0.5899\n",
      "Epoch 40/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 0.9913 - d_loss: 0.6462\n",
      "Epoch 41/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1732 - d_loss: 0.5000\n",
      "Epoch 42/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1701 - d_loss: 0.5758\n",
      "Epoch 43/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2107 - d_loss: 0.4909\n",
      "Epoch 44/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0547 - d_loss: 0.6096\n",
      "Epoch 45/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0371 - d_loss: 0.5714\n",
      "Epoch 46/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1707 - d_loss: 0.5105\n",
      "Epoch 47/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2393 - d_loss: 0.5314\n",
      "Epoch 48/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1151 - d_loss: 0.6439\n",
      "Epoch 49/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1124 - d_loss: 0.5245\n",
      "Epoch 50/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1320 - d_loss: 0.5032\n",
      "Epoch 51/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2394 - d_loss: 0.4968\n",
      "Epoch 52/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2881 - d_loss: 0.5037\n",
      "Epoch 53/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1288 - d_loss: 0.5892\n",
      "Epoch 54/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0539 - d_loss: 0.5920\n",
      "Epoch 55/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1359 - d_loss: 0.5306\n",
      "Epoch 56/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1638 - d_loss: 0.5134\n",
      "Epoch 57/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0958 - d_loss: 0.5424\n",
      "Epoch 58/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 0.9782 - d_loss: 0.6363\n",
      "Epoch 59/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1010 - d_loss: 0.5304\n",
      "Epoch 60/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2048 - d_loss: 0.5182\n",
      "Epoch 61/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 0.9491 - d_loss: 0.6496\n",
      "Epoch 62/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 0.9963 - d_loss: 0.5909\n",
      "Epoch 63/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1653 - d_loss: 0.4941\n",
      "Epoch 64/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1130 - d_loss: 0.5287\n",
      "Epoch 65/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1887 - d_loss: 0.5280\n",
      "Epoch 66/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1808 - d_loss: 0.5558\n",
      "Epoch 67/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1088 - d_loss: 0.5621\n",
      "Epoch 68/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1559 - d_loss: 0.5181\n",
      "Epoch 69/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1771 - d_loss: 0.4837\n",
      "Epoch 70/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1700 - d_loss: 0.5221\n",
      "Epoch 71/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1608 - d_loss: 0.5197\n",
      "Epoch 72/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.0531 - d_loss: 0.5708\n",
      "Epoch 73/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.0162 - d_loss: 0.5769\n",
      "Epoch 74/500\n",
      "146/146 [==============================] - 18s 121ms/step - g_loss: 1.1433 - d_loss: 0.4878\n",
      "Epoch 75/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.2077 - d_loss: 0.4912\n",
      "Epoch 76/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.0967 - d_loss: 0.6128\n",
      "Epoch 77/500\n",
      "146/146 [==============================] - 18s 120ms/step - g_loss: 1.1225 - d_loss: 0.5963\n",
      "Epoch 78/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.2894 - d_loss: 0.5179\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.2314 - d_loss: 0.5101\n",
      "Epoch 80/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.2368 - d_loss: 0.5259\n",
      "Epoch 81/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1712 - d_loss: 0.5597\n",
      "Epoch 82/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1524 - d_loss: 0.4915\n",
      "Epoch 83/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.2337 - d_loss: 0.5260\n",
      "Epoch 84/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1509 - d_loss: 0.6173\n",
      "Epoch 85/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 0.9863 - d_loss: 0.6556\n",
      "Epoch 86/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1311 - d_loss: 0.5142\n",
      "Epoch 87/500\n",
      "146/146 [==============================] - 18s 120ms/step - g_loss: 1.2561 - d_loss: 0.4998\n",
      "Epoch 88/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1111 - d_loss: 0.5362\n",
      "Epoch 89/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.0636 - d_loss: 0.6104\n",
      "Epoch 90/500\n",
      "146/146 [==============================] - 18s 122ms/step - g_loss: 1.1404 - d_loss: 0.5303\n",
      "Epoch 91/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.3186 - d_loss: 0.4638\n",
      "Epoch 92/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1621 - d_loss: 0.5729\n",
      "Epoch 93/500\n",
      "146/146 [==============================] - 17s 120ms/step - g_loss: 1.2069 - d_loss: 0.5160\n",
      "Epoch 94/500\n",
      "146/146 [==============================] - 18s 124ms/step - g_loss: 1.1941 - d_loss: 0.5166\n",
      "Epoch 95/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.2448 - d_loss: 0.5049\n",
      "Epoch 96/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.3234 - d_loss: 0.4776\n",
      "Epoch 97/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.2430 - d_loss: 0.5286\n",
      "Epoch 98/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1087 - d_loss: 0.5441\n",
      "Epoch 99/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1763 - d_loss: 0.5324\n",
      "Epoch 100/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.1089 - d_loss: 0.5369\n",
      "Epoch 101/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.2333 - d_loss: 0.5137\n",
      "Epoch 102/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2327 - d_loss: 0.4880\n",
      "Epoch 103/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.0675 - d_loss: 0.5803\n",
      "Epoch 104/500\n",
      "146/146 [==============================] - 18s 122ms/step - g_loss: 1.1330 - d_loss: 0.6213\n",
      "Epoch 105/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1870 - d_loss: 0.5057\n",
      "Epoch 106/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2934 - d_loss: 0.4682\n",
      "Epoch 107/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1865 - d_loss: 0.5589\n",
      "Epoch 108/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1488 - d_loss: 0.5391\n",
      "Epoch 109/500\n",
      "146/146 [==============================] - 18s 122ms/step - g_loss: 1.0996 - d_loss: 0.5675\n",
      "Epoch 110/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1729 - d_loss: 0.5118\n",
      "Epoch 111/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1204 - d_loss: 0.5811\n",
      "Epoch 112/500\n",
      "146/146 [==============================] - 17s 120ms/step - g_loss: 1.1341 - d_loss: 0.5534\n",
      "Epoch 113/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1908 - d_loss: 0.5813\n",
      "Epoch 114/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1981 - d_loss: 0.4764\n",
      "Epoch 115/500\n",
      "146/146 [==============================] - 17s 120ms/step - g_loss: 1.2545 - d_loss: 0.4818\n",
      "Epoch 116/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 0.9717 - d_loss: 0.7219\n",
      "Epoch 117/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.0339 - d_loss: 0.5900\n",
      "Epoch 118/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.2052 - d_loss: 0.4933\n",
      "Epoch 119/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.2471 - d_loss: 0.5333\n",
      "Epoch 120/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0590 - d_loss: 0.5819\n",
      "Epoch 121/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 0.9698 - d_loss: 0.6313\n",
      "Epoch 122/500\n",
      "146/146 [==============================] - 18s 122ms/step - g_loss: 1.2016 - d_loss: 0.4909\n",
      "Epoch 123/500\n",
      "146/146 [==============================] - 18s 121ms/step - g_loss: 1.0855 - d_loss: 0.5640\n",
      "Epoch 124/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1292 - d_loss: 0.5424\n",
      "Epoch 125/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1684 - d_loss: 0.5598\n",
      "Epoch 126/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0610 - d_loss: 0.5933\n",
      "Epoch 127/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.0527 - d_loss: 0.5707\n",
      "Epoch 128/500\n",
      "146/146 [==============================] - 18s 121ms/step - g_loss: 1.1542 - d_loss: 0.5342\n",
      "Epoch 129/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1401 - d_loss: 0.5858\n",
      "Epoch 130/500\n",
      "146/146 [==============================] - 18s 123ms/step - g_loss: 1.1293 - d_loss: 0.5590\n",
      "Epoch 131/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.1596 - d_loss: 0.4991\n",
      "Epoch 132/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1454 - d_loss: 0.5938\n",
      "Epoch 133/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1248 - d_loss: 0.5760\n",
      "Epoch 134/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1287 - d_loss: 0.5185\n",
      "Epoch 135/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0613 - d_loss: 0.6050\n",
      "Epoch 136/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1009 - d_loss: 0.5280\n",
      "Epoch 137/500\n",
      "146/146 [==============================] - 19s 130ms/step - g_loss: 1.1362 - d_loss: 0.5185\n",
      "Epoch 138/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1310 - d_loss: 0.5227\n",
      "Epoch 139/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.2498 - d_loss: 0.5045\n",
      "Epoch 140/500\n",
      "146/146 [==============================] - 18s 123ms/step - g_loss: 1.2039 - d_loss: 0.5827\n",
      "Epoch 141/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0527 - d_loss: 0.5818\n",
      "Epoch 142/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.2007 - d_loss: 0.5201\n",
      "Epoch 143/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.1881 - d_loss: 0.4997\n",
      "Epoch 144/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.0262 - d_loss: 0.6571\n",
      "Epoch 145/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.0554 - d_loss: 0.5591\n",
      "Epoch 146/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1474 - d_loss: 0.5261\n",
      "Epoch 147/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1779 - d_loss: 0.4913\n",
      "Epoch 148/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 0.9559 - d_loss: 0.7375\n",
      "Epoch 149/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.0545 - d_loss: 0.5595\n",
      "Epoch 150/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1085 - d_loss: 0.5215\n",
      "Epoch 151/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1023 - d_loss: 0.5230\n",
      "Epoch 152/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1034 - d_loss: 0.5562\n",
      "Epoch 153/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.1529 - d_loss: 0.5156\n",
      "Epoch 154/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.1189 - d_loss: 0.5422\n",
      "Epoch 155/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1061 - d_loss: 0.5933\n",
      "Epoch 156/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.1604 - d_loss: 0.5220\n",
      "Epoch 157/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.2583 - d_loss: 0.4666\n",
      "Epoch 158/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 0.9898 - d_loss: 0.7440\n",
      "Epoch 159/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.0096 - d_loss: 0.5884\n",
      "Epoch 160/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1263 - d_loss: 0.5046\n",
      "Epoch 161/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1859 - d_loss: 0.5204\n",
      "Epoch 162/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0810 - d_loss: 0.5800\n",
      "Epoch 163/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 0.9353 - d_loss: 0.6716\n",
      "Epoch 164/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.1015 - d_loss: 0.5098\n",
      "Epoch 165/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2749 - d_loss: 0.5130\n",
      "Epoch 166/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1312 - d_loss: 0.5799\n",
      "Epoch 167/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0907 - d_loss: 0.5338\n",
      "Epoch 168/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1183 - d_loss: 0.5602\n",
      "Epoch 169/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2184 - d_loss: 0.4837\n",
      "Epoch 170/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1501 - d_loss: 0.5420\n",
      "Epoch 171/500\n",
      "146/146 [==============================] - 18s 120ms/step - g_loss: 1.1905 - d_loss: 0.4859\n",
      "Epoch 172/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1728 - d_loss: 0.5269\n",
      "Epoch 173/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2375 - d_loss: 0.4630\n",
      "Epoch 174/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1105 - d_loss: 0.6211\n",
      "Epoch 175/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1465 - d_loss: 0.6006\n",
      "Epoch 176/500\n",
      "146/146 [==============================] - 18s 120ms/step - g_loss: 1.1305 - d_loss: 0.5686\n",
      "Epoch 177/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 0.9572 - d_loss: 0.7294\n",
      "Epoch 178/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 1.0167 - d_loss: 0.5763\n",
      "Epoch 179/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.2036 - d_loss: 0.4900\n",
      "Epoch 180/500\n",
      "146/146 [==============================] - 17s 120ms/step - g_loss: 1.2018 - d_loss: 0.4907\n",
      "Epoch 181/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0833 - d_loss: 0.5839\n",
      "Epoch 182/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 0.9160 - d_loss: 0.7023\n",
      "Epoch 183/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1759 - d_loss: 0.5334\n",
      "Epoch 184/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1614 - d_loss: 0.5720\n",
      "Epoch 185/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2409 - d_loss: 0.5563\n",
      "Epoch 186/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1194 - d_loss: 0.5331\n",
      "Epoch 187/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1863 - d_loss: 0.5457\n",
      "Epoch 188/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1106 - d_loss: 0.5338\n",
      "Epoch 189/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1217 - d_loss: 0.5163\n",
      "Epoch 190/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2994 - d_loss: 0.4993\n",
      "Epoch 191/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1855 - d_loss: 0.5494\n",
      "Epoch 192/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1282 - d_loss: 0.5653\n",
      "Epoch 193/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1265 - d_loss: 0.5582\n",
      "Epoch 194/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1024 - d_loss: 0.5205\n",
      "Epoch 195/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1411 - d_loss: 0.5260\n",
      "Epoch 196/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2754 - d_loss: 0.4880\n",
      "Epoch 197/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 0.8961 - d_loss: 0.7711\n",
      "Epoch 198/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1003 - d_loss: 0.5218\n",
      "Epoch 199/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1081 - d_loss: 0.5779\n",
      "Epoch 200/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0999 - d_loss: 0.5404\n",
      "Epoch 201/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.1327 - d_loss: 0.5333\n",
      "Epoch 202/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 0.8906 - d_loss: 0.7315\n",
      "Epoch 203/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 0.9931 - d_loss: 0.5688\n",
      "Epoch 204/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1374 - d_loss: 0.5448\n",
      "Epoch 205/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1106 - d_loss: 0.5645\n",
      "Epoch 206/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1676 - d_loss: 0.5173\n",
      "Epoch 207/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1081 - d_loss: 0.5423\n",
      "Epoch 208/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2405 - d_loss: 0.5180\n",
      "Epoch 209/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2280 - d_loss: 0.5007\n",
      "Epoch 210/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1488 - d_loss: 0.5950\n",
      "Epoch 211/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0023 - d_loss: 0.6303\n",
      "Epoch 212/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2141 - d_loss: 0.4662\n",
      "Epoch 213/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2989 - d_loss: 0.4807\n",
      "Epoch 214/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1467 - d_loss: 0.5553\n",
      "Epoch 215/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3374 - d_loss: 0.4810\n",
      "Epoch 216/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2295 - d_loss: 0.4901\n",
      "Epoch 217/500\n",
      "146/146 [==============================] - 18s 126ms/step - g_loss: 1.2440 - d_loss: 0.5410\n",
      "Epoch 218/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0916 - d_loss: 0.6315\n",
      "Epoch 219/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1601 - d_loss: 0.5101\n",
      "Epoch 220/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0998 - d_loss: 0.5607\n",
      "Epoch 221/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0400 - d_loss: 0.5985\n",
      "Epoch 222/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0640 - d_loss: 0.5733\n",
      "Epoch 223/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2260 - d_loss: 0.5229\n",
      "Epoch 224/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2000 - d_loss: 0.5207\n",
      "Epoch 225/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1599 - d_loss: 0.5262\n",
      "Epoch 226/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1225 - d_loss: 0.5602\n",
      "Epoch 227/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1395 - d_loss: 0.5419\n",
      "Epoch 228/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2830 - d_loss: 0.4957\n",
      "Epoch 229/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2387 - d_loss: 0.6211\n",
      "Epoch 230/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1144 - d_loss: 0.5470\n",
      "Epoch 231/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1203 - d_loss: 0.6070\n",
      "Epoch 232/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1839 - d_loss: 0.4930\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1802 - d_loss: 0.5377\n",
      "Epoch 234/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0503 - d_loss: 0.6296\n",
      "Epoch 235/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1411 - d_loss: 0.5662\n",
      "Epoch 236/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2421 - d_loss: 0.4996\n",
      "Epoch 237/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2563 - d_loss: 0.5077\n",
      "Epoch 238/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1284 - d_loss: 0.5703\n",
      "Epoch 239/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1648 - d_loss: 0.4897\n",
      "Epoch 240/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2459 - d_loss: 0.5198\n",
      "Epoch 241/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0945 - d_loss: 0.5735\n",
      "Epoch 242/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2014 - d_loss: 0.5097\n",
      "Epoch 243/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1454 - d_loss: 0.5998\n",
      "Epoch 244/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0961 - d_loss: 0.5321\n",
      "Epoch 245/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1295 - d_loss: 0.5467\n",
      "Epoch 246/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0855 - d_loss: 0.5682\n",
      "Epoch 247/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0227 - d_loss: 0.6420\n",
      "Epoch 248/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0502 - d_loss: 0.5704\n",
      "Epoch 249/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2749 - d_loss: 0.4703\n",
      "Epoch 250/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2838 - d_loss: 0.5146\n",
      "Epoch 251/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0782 - d_loss: 0.5816\n",
      "Epoch 252/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 0.9766 - d_loss: 0.6085\n",
      "Epoch 253/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0713 - d_loss: 0.5647\n",
      "Epoch 254/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2365 - d_loss: 0.5029\n",
      "Epoch 255/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1987 - d_loss: 0.5583\n",
      "Epoch 256/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 0.9613 - d_loss: 0.6852\n",
      "Epoch 257/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0577 - d_loss: 0.5675\n",
      "Epoch 258/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0846 - d_loss: 0.5399\n",
      "Epoch 259/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0662 - d_loss: 0.5715\n",
      "Epoch 260/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1873 - d_loss: 0.5211\n",
      "Epoch 261/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2227 - d_loss: 0.4972\n",
      "Epoch 262/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2088 - d_loss: 0.5090\n",
      "Epoch 263/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1836 - d_loss: 0.5162\n",
      "Epoch 264/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2158 - d_loss: 0.4827\n",
      "Epoch 265/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3499 - d_loss: 0.4676\n",
      "Epoch 266/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1790 - d_loss: 0.5431\n",
      "Epoch 267/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.0342 - d_loss: 0.5991\n",
      "Epoch 268/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1599 - d_loss: 0.4947\n",
      "Epoch 269/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2623 - d_loss: 0.4979\n",
      "Epoch 270/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.4000 - d_loss: 0.5258\n",
      "Epoch 271/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2023 - d_loss: 0.5735\n",
      "Epoch 272/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1432 - d_loss: 0.5947\n",
      "Epoch 273/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2728 - d_loss: 0.4695\n",
      "Epoch 274/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3410 - d_loss: 0.4781\n",
      "Epoch 275/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3048 - d_loss: 0.5257\n",
      "Epoch 276/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3113 - d_loss: 0.4651\n",
      "Epoch 277/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2205 - d_loss: 0.5185\n",
      "Epoch 278/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1857 - d_loss: 0.5466\n",
      "Epoch 279/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1742 - d_loss: 0.5317\n",
      "Epoch 280/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2015 - d_loss: 0.5147\n",
      "Epoch 281/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2517 - d_loss: 0.4627\n",
      "Epoch 282/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3709 - d_loss: 0.4352\n",
      "Epoch 283/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3117 - d_loss: 0.5554\n",
      "Epoch 284/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0669 - d_loss: 0.6373\n",
      "Epoch 285/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0392 - d_loss: 0.5908\n",
      "Epoch 286/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1727 - d_loss: 0.5018\n",
      "Epoch 287/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2642 - d_loss: 0.4762\n",
      "Epoch 288/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2465 - d_loss: 0.4920\n",
      "Epoch 289/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1868 - d_loss: 0.5272\n",
      "Epoch 290/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1138 - d_loss: 0.5556\n",
      "Epoch 291/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 0.8721 - d_loss: 0.7697\n",
      "Epoch 292/500\n",
      "146/146 [==============================] - 17s 120ms/step - g_loss: 1.1390 - d_loss: 0.5282\n",
      "Epoch 293/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2116 - d_loss: 0.5694\n",
      "Epoch 294/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1205 - d_loss: 0.5607\n",
      "Epoch 295/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1110 - d_loss: 0.5208\n",
      "Epoch 296/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1857 - d_loss: 0.5482\n",
      "Epoch 297/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0660 - d_loss: 0.6623\n",
      "Epoch 298/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2591 - d_loss: 0.5149\n",
      "Epoch 299/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2555 - d_loss: 0.5644\n",
      "Epoch 300/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0616 - d_loss: 0.5820\n",
      "Epoch 301/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0122 - d_loss: 0.6242\n",
      "Epoch 302/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1831 - d_loss: 0.5151\n",
      "Epoch 303/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2044 - d_loss: 0.4899\n",
      "Epoch 304/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2051 - d_loss: 0.4985\n",
      "Epoch 305/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1549 - d_loss: 0.5272\n",
      "Epoch 306/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2058 - d_loss: 0.4804\n",
      "Epoch 307/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2900 - d_loss: 0.4553\n",
      "Epoch 308/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2525 - d_loss: 0.4959\n",
      "Epoch 309/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1952 - d_loss: 0.5432\n",
      "Epoch 310/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.1591 - d_loss: 0.5460\n",
      "Epoch 311/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2503 - d_loss: 0.4701\n",
      "Epoch 312/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2564 - d_loss: 0.5254\n",
      "Epoch 313/500\n",
      "146/146 [==============================] - 17s 118ms/step - g_loss: 0.9761 - d_loss: 0.6493\n",
      "Epoch 314/500\n",
      "146/146 [==============================] - 17s 119ms/step - g_loss: 1.0659 - d_loss: 0.5836\n",
      "Epoch 315/500\n",
      "146/146 [==============================] - 18s 122ms/step - g_loss: 1.1540 - d_loss: 0.5247\n",
      "Epoch 316/500\n",
      "146/146 [==============================] - 17s 117ms/step - g_loss: 1.2575 - d_loss: 0.5073\n",
      "Epoch 317/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2852 - d_loss: 0.5478\n",
      "Epoch 318/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2189 - d_loss: 0.5027\n",
      "Epoch 319/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1675 - d_loss: 0.5278\n",
      "Epoch 320/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1206 - d_loss: 0.6204\n",
      "Epoch 321/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0854 - d_loss: 0.5657\n",
      "Epoch 322/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1571 - d_loss: 0.5527\n",
      "Epoch 323/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2088 - d_loss: 0.5177\n",
      "Epoch 324/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2390 - d_loss: 0.5334\n",
      "Epoch 325/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2283 - d_loss: 0.5394\n",
      "Epoch 326/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1578 - d_loss: 0.5411\n",
      "Epoch 327/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0684 - d_loss: 0.6157\n",
      "Epoch 328/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1257 - d_loss: 0.5045\n",
      "Epoch 329/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2365 - d_loss: 0.4922\n",
      "Epoch 330/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2787 - d_loss: 0.5074\n",
      "Epoch 331/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2182 - d_loss: 0.5036\n",
      "Epoch 332/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0485 - d_loss: 0.6480\n",
      "Epoch 333/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2076 - d_loss: 0.4685\n",
      "Epoch 334/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1570 - d_loss: 0.5556\n",
      "Epoch 335/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1162 - d_loss: 0.5186\n",
      "Epoch 336/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0692 - d_loss: 0.5516\n",
      "Epoch 337/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1143 - d_loss: 0.5338\n",
      "Epoch 338/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1881 - d_loss: 0.5507\n",
      "Epoch 339/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2324 - d_loss: 0.4968\n",
      "Epoch 340/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2269 - d_loss: 0.6002\n",
      "Epoch 341/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1107 - d_loss: 0.6400\n",
      "Epoch 342/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1124 - d_loss: 0.5235\n",
      "Epoch 343/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2561 - d_loss: 0.5008\n",
      "Epoch 344/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1508 - d_loss: 0.5230\n",
      "Epoch 345/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0491 - d_loss: 0.6110\n",
      "Epoch 346/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1530 - d_loss: 0.5595\n",
      "Epoch 347/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1970 - d_loss: 0.5110\n",
      "Epoch 348/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0983 - d_loss: 0.5672\n",
      "Epoch 349/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1330 - d_loss: 0.5227\n",
      "Epoch 350/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1895 - d_loss: 0.5315\n",
      "Epoch 351/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1977 - d_loss: 0.5521\n",
      "Epoch 352/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0628 - d_loss: 0.5650\n",
      "Epoch 353/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2103 - d_loss: 0.5026\n",
      "Epoch 354/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.1721 - d_loss: 0.5529\n",
      "Epoch 355/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0743 - d_loss: 0.5720\n",
      "Epoch 356/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1853 - d_loss: 0.5066\n",
      "Epoch 357/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1810 - d_loss: 0.5111\n",
      "Epoch 358/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0881 - d_loss: 0.6060\n",
      "Epoch 359/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1427 - d_loss: 0.5924\n",
      "Epoch 360/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 0.8811 - d_loss: 0.8307\n",
      "Epoch 361/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0122 - d_loss: 0.5740\n",
      "Epoch 362/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2282 - d_loss: 0.5426\n",
      "Epoch 363/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1918 - d_loss: 0.5168\n",
      "Epoch 364/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1333 - d_loss: 0.5096\n",
      "Epoch 365/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1982 - d_loss: 0.4849\n",
      "Epoch 366/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2929 - d_loss: 0.4615\n",
      "Epoch 367/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0878 - d_loss: 0.5805\n",
      "Epoch 368/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1151 - d_loss: 0.5540\n",
      "Epoch 369/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1157 - d_loss: 0.5587\n",
      "Epoch 370/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2686 - d_loss: 0.5178\n",
      "Epoch 371/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3022 - d_loss: 0.5170\n",
      "Epoch 372/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1407 - d_loss: 0.5433\n",
      "Epoch 373/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1716 - d_loss: 0.5322\n",
      "Epoch 374/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2557 - d_loss: 0.4601\n",
      "Epoch 375/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2287 - d_loss: 0.5371\n",
      "Epoch 376/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3097 - d_loss: 0.5001\n",
      "Epoch 377/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2714 - d_loss: 0.5242\n",
      "Epoch 378/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2672 - d_loss: 0.5236\n",
      "Epoch 379/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2959 - d_loss: 0.5361\n",
      "Epoch 380/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1847 - d_loss: 0.5066\n",
      "Epoch 381/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2489 - d_loss: 0.4694\n",
      "Epoch 382/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3159 - d_loss: 0.4679\n",
      "Epoch 383/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1684 - d_loss: 0.5521\n",
      "Epoch 384/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2516 - d_loss: 0.5052\n",
      "Epoch 385/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3285 - d_loss: 0.4671\n",
      "Epoch 386/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2479 - d_loss: 0.5554\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1563 - d_loss: 0.5887\n",
      "Epoch 388/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0029 - d_loss: 0.6850\n",
      "Epoch 389/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0983 - d_loss: 0.5716\n",
      "Epoch 390/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1927 - d_loss: 0.5076\n",
      "Epoch 391/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1961 - d_loss: 0.5114\n",
      "Epoch 392/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2566 - d_loss: 0.5065\n",
      "Epoch 393/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1651 - d_loss: 0.5148\n",
      "Epoch 394/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2854 - d_loss: 0.4943\n",
      "Epoch 395/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1885 - d_loss: 0.5157\n",
      "Epoch 396/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0527 - d_loss: 0.5714\n",
      "Epoch 397/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0994 - d_loss: 0.5604\n",
      "Epoch 398/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0547 - d_loss: 0.5821\n",
      "Epoch 399/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1067 - d_loss: 0.5294\n",
      "Epoch 400/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2052 - d_loss: 0.5276\n",
      "Epoch 401/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1130 - d_loss: 0.6177\n",
      "Epoch 402/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0655 - d_loss: 0.5690\n",
      "Epoch 403/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1553 - d_loss: 0.5235\n",
      "Epoch 404/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2523 - d_loss: 0.5036\n",
      "Epoch 405/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2430 - d_loss: 0.5011\n",
      "Epoch 406/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1143 - d_loss: 0.5676\n",
      "Epoch 407/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2444 - d_loss: 0.4816\n",
      "Epoch 408/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2977 - d_loss: 0.4880\n",
      "Epoch 409/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3492 - d_loss: 0.4686\n",
      "Epoch 410/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2663 - d_loss: 0.4980\n",
      "Epoch 411/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1293 - d_loss: 0.5498\n",
      "Epoch 412/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1576 - d_loss: 0.5243\n",
      "Epoch 413/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2082 - d_loss: 0.5177\n",
      "Epoch 414/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0930 - d_loss: 0.6138\n",
      "Epoch 415/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1860 - d_loss: 0.5556\n",
      "Epoch 416/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2455 - d_loss: 0.4990\n",
      "Epoch 417/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1492 - d_loss: 0.5521\n",
      "Epoch 418/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1998 - d_loss: 0.5127\n",
      "Epoch 419/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2436 - d_loss: 0.5576\n",
      "Epoch 420/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1841 - d_loss: 0.6019\n",
      "Epoch 421/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2284 - d_loss: 0.5071\n",
      "Epoch 422/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0910 - d_loss: 0.6711\n",
      "Epoch 423/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0346 - d_loss: 0.5629\n",
      "Epoch 424/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1035 - d_loss: 0.5764\n",
      "Epoch 425/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0984 - d_loss: 0.5249\n",
      "Epoch 426/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2132 - d_loss: 0.4823\n",
      "Epoch 427/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1954 - d_loss: 0.5288\n",
      "Epoch 428/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0462 - d_loss: 0.6025\n",
      "Epoch 429/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1682 - d_loss: 0.5172\n",
      "Epoch 430/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2606 - d_loss: 0.4857\n",
      "Epoch 431/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2817 - d_loss: 0.6226\n",
      "Epoch 432/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1063 - d_loss: 0.5442\n",
      "Epoch 433/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1376 - d_loss: 0.5470\n",
      "Epoch 434/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2184 - d_loss: 0.5262\n",
      "Epoch 435/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2646 - d_loss: 0.4605\n",
      "Epoch 436/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3282 - d_loss: 0.4790\n",
      "Epoch 437/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1121 - d_loss: 0.6312\n",
      "Epoch 438/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0759 - d_loss: 0.5706\n",
      "Epoch 439/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1608 - d_loss: 0.5485\n",
      "Epoch 440/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2334 - d_loss: 0.5487\n",
      "Epoch 441/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1081 - d_loss: 0.7356\n",
      "Epoch 442/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1232 - d_loss: 0.5715\n",
      "Epoch 443/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1431 - d_loss: 0.5936\n",
      "Epoch 444/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 0.9133 - d_loss: 0.7892\n",
      "Epoch 445/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0875 - d_loss: 0.5889\n",
      "Epoch 446/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2062 - d_loss: 0.5158\n",
      "Epoch 447/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2162 - d_loss: 0.5223\n",
      "Epoch 448/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2562 - d_loss: 0.5086\n",
      "Epoch 449/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2549 - d_loss: 0.5067\n",
      "Epoch 450/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1452 - d_loss: 0.6461\n",
      "Epoch 451/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1304 - d_loss: 0.5818\n",
      "Epoch 452/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1416 - d_loss: 0.5220\n",
      "Epoch 453/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2589 - d_loss: 0.4888\n",
      "Epoch 454/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2299 - d_loss: 0.4935\n",
      "Epoch 455/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3683 - d_loss: 0.4326\n",
      "Epoch 456/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3623 - d_loss: 0.5225\n",
      "Epoch 457/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.0542 - d_loss: 0.7055\n",
      "Epoch 458/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1645 - d_loss: 0.5408\n",
      "Epoch 459/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3118 - d_loss: 0.4907\n",
      "Epoch 460/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1082 - d_loss: 0.6197\n",
      "Epoch 461/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2927 - d_loss: 0.4788\n",
      "Epoch 462/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2845 - d_loss: 0.5194\n",
      "Epoch 463/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2453 - d_loss: 0.5021\n",
      "Epoch 464/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1040 - d_loss: 0.5773\n",
      "Epoch 465/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1715 - d_loss: 0.5311\n",
      "Epoch 466/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2688 - d_loss: 0.5218\n",
      "Epoch 467/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1449 - d_loss: 0.5459\n",
      "Epoch 468/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2091 - d_loss: 0.5533\n",
      "Epoch 469/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2228 - d_loss: 0.4878\n",
      "Epoch 470/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2618 - d_loss: 0.5492\n",
      "Epoch 471/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3587 - d_loss: 0.4957\n",
      "Epoch 472/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2317 - d_loss: 0.5201\n",
      "Epoch 473/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3140 - d_loss: 0.5067\n",
      "Epoch 474/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2972 - d_loss: 0.4914\n",
      "Epoch 475/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2456 - d_loss: 0.5641\n",
      "Epoch 476/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1441 - d_loss: 0.5652\n",
      "Epoch 477/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2519 - d_loss: 0.5091\n",
      "Epoch 478/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3140 - d_loss: 0.4603\n",
      "Epoch 479/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3076 - d_loss: 0.5142\n",
      "Epoch 480/500\n",
      "146/146 [==============================] - 17s 116ms/step - g_loss: 1.2710 - d_loss: 0.5542\n",
      "Epoch 481/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3366 - d_loss: 0.4375\n",
      "Epoch 482/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.4165 - d_loss: 0.4343\n",
      "Epoch 483/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3089 - d_loss: 0.4604\n",
      "Epoch 484/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.4317 - d_loss: 0.4322\n",
      "Epoch 485/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3647 - d_loss: 0.4843\n",
      "Epoch 486/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2705 - d_loss: 0.5571\n",
      "Epoch 487/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3892 - d_loss: 0.4453\n",
      "Epoch 488/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.2347 - d_loss: 0.5161\n",
      "Epoch 489/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3758 - d_loss: 0.4522\n",
      "Epoch 490/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3478 - d_loss: 0.5120\n",
      "Epoch 491/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.4830 - d_loss: 0.4827\n",
      "Epoch 492/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.4880 - d_loss: 0.4475\n",
      "Epoch 493/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.4471 - d_loss: 0.4376\n",
      "Epoch 494/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3596 - d_loss: 0.4930\n",
      "Epoch 495/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3239 - d_loss: 0.5316\n",
      "Epoch 496/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.4743 - d_loss: 0.3849\n",
      "Epoch 497/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.6497 - d_loss: 0.4356\n",
      "Epoch 498/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.1670 - d_loss: 0.7473\n",
      "Epoch 499/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.3630 - d_loss: 0.4504\n",
      "Epoch 500/500\n",
      "146/146 [==============================] - 17s 115ms/step - g_loss: 1.4626 - d_loss: 0.4609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2563d9fbee0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=checkpoint.discriminator, generator=checkpoint.generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=checkpoint.discriminator_optimizer,\n",
    "    g_optimizer=checkpoint.generator_optimizer,\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan.fit(dataset, epochs=epoch_t, \n",
    "        callbacks=GANMonitor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6263e9",
   "metadata": {},
   "source": [
    "# Create new training images using the Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a0397cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first extract the trained generator from our Conditiona GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 2500  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = tf.cast(first_label, tf.float32)\n",
    "    second_label = tf.cast(second_label, tf.float32)\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "780b224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new directory for saving folder\n",
    "os.makedirs(path_save_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0de5e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve class name based on number\n",
    "classes_list = list(prelim_dataset.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79dfad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images for class: Adialer.C\n",
      "Generating images for class: Agent.FYI\n",
      "Generating images for class: Allaple.A\n",
      "Generating images for class: Allaple.L\n",
      "Generating images for class: Alueron.gen!J\n",
      "Generating images for class: Autorun.K\n",
      "Generating images for class: C2LOP.P\n",
      "Generating images for class: C2LOP.gen!g\n",
      "Generating images for class: Dialplatform.B\n",
      "Generating images for class: Dontovo.A\n",
      "Generating images for class: Fakerean\n",
      "Generating images for class: Instantaccess\n",
      "Generating images for class: Lolyda.AA1\n",
      "Generating images for class: Lolyda.AA2\n",
      "Generating images for class: Lolyda.AA3\n",
      "Generating images for class: Lolyda.AT\n",
      "Generating images for class: Malex.gen!J\n",
      "Generating images for class: Obfuscator.AD\n",
      "Generating images for class: Rbot!gen\n",
      "Generating images for class: Skintrim.N\n",
      "Generating images for class: Swizzor.gen!E\n",
      "Generating images for class: Swizzor.gen!I\n",
      "Generating images for class: VB.AT\n",
      "Generating images for class: Wintrim.BX\n",
      "Generating images for class: Yuner.A\n"
     ]
    }
   ],
   "source": [
    "# Create images for every class and store in seperate folder\n",
    "for i in range(num_classes):\n",
    "    class_name = classes_list[i]\n",
    "    class_dir = f\"{path_save_imgs}/{class_name}\"\n",
    "    os.makedirs(class_dir)\n",
    "    start_class = i\n",
    "    end_class = i\n",
    "    fake_images = interpolate_class(start_class, end_class)\n",
    "    fake_images *= 255\n",
    "    converted_images = fake_images.astype(np.uint8)\n",
    "    converted_images = tf.image.resize(converted_images, (64, 64)).numpy().astype(np.uint8)\n",
    "    print(\"Generating images for class: {name}\".format(name=class_name))\n",
    "    for j in range(num_interpolation):\n",
    "        np_array = np.squeeze(converted_images[j], axis=2)\n",
    "        im = Image.fromarray((np_array))\n",
    "        im.save(f\"{class_dir}/gen_imgs_{class_name}_{j}.png\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e830ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
