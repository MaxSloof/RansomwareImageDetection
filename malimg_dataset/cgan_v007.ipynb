{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de546011",
   "metadata": {},
   "source": [
    "# Conditional GAN\n",
    "\n",
    "Used to generate new training data for the ransomware families to overcome the skewed distribution of training data towards the benign samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "176d8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d338ac",
   "metadata": {},
   "source": [
    "**Change parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b44d3f",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d37ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Color mode\n",
    "ch = 'grayscale'\n",
    "\n",
    "# Image size\n",
    "iw, ih = 64,64\n",
    "im_size = (iw,ih)\n",
    "\n",
    "# Latent dim size\n",
    "latent_dim = 256\n",
    "\n",
    "# Number of Epochs\n",
    "epoch_t = 20\n",
    "\n",
    "# Computation environment: Kaggle (0) or Local (1)\n",
    "cenv = 1\n",
    "\n",
    "# If weights are used: Weight factor\n",
    "wf = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd651cb4",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd315bc2",
   "metadata": {},
   "source": [
    "Automatic notebook preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50855d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(ch == 'rgb'):\n",
    "    chnum = 3\n",
    "elif(ch == 'grayscale'):\n",
    "    chnum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "193e04b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 matches(es) found\n",
      "--------------\n",
      "New folder name: cgan-local-v010\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "if cenv == 1:\n",
    "    file_exists = []\n",
    "    vnum = 1\n",
    "    dir = \"C:/Users/Max/Documents/GitHub/malimg_dataset\"\n",
    "    for files in os.listdir(dir):\n",
    "        if \"cgan\" in files:\n",
    "            try:\n",
    "                vnum = max(vnum, int(files[-3:]))\n",
    "            except: \n",
    "                continue\n",
    "            new_vnum = vnum + 1\n",
    "            file_exists.append(True)\n",
    "        else: \n",
    "            file_exists.append(False)\n",
    "    # If this is the first notebook you want to save, a new folder will be created with version #001\n",
    "    if sum(file_exists) == 0:\n",
    "        new_vnum = 1\n",
    "        print(\"No matches found\")\n",
    "\n",
    "    else: \n",
    "        print(f\"{sum(file_exists)} matches(es) found\")\n",
    "        print(\"--------------\")\n",
    "\n",
    "    # Print new folder name\n",
    "    print(f\"New folder name: cgan-local-v{new_vnum:03}\")\n",
    "    print(\"--------------\")\n",
    "    \n",
    "    # Create new folder with the name of the notebook and the version number\n",
    "    new_dir = f\"C://Users/Max/Documents/GitHub/malimg_dataset/cgan-local-v{new_vnum:03}\"\n",
    "    os.makedirs(new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30853b",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06d54d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cenv == 0:\n",
    "    path_root = \"/kaggle/input/data-wo-benign\"\n",
    "    path_save_imgs = \"/kaggle/working/numpy_arrays/\"\n",
    "if cenv == 1:\n",
    "    path_root = \"C:/Users/Max/Documents/image_data/fixed_malimg_dataset\"\n",
    "    path_save_imgs = f\"C:/Users/Max/Documents/image_data/malimg-cgan-local-v{new_vnum:03}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6642f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4549c79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9339 images belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "prelim_dataset = datagen.flow_from_directory(\n",
    "    directory = path_root,\n",
    "    color_mode = ch,\n",
    "    target_size = im_size,\n",
    "    interpolation = 'bicubic',\n",
    "    batch_size = 40000,\n",
    "    shuffle=False\n",
    ")\n",
    "imgs, labels = next(prelim_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dda172b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ransomware family:  Lolyda.AT\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = 7099+10\n",
    "plt.imshow(np.array(imgs[z]*255).astype(np.uint8), cmap=\"gray\")\n",
    "print(\"Ransomware family: \",list(prelim_dataset.class_indices)[np.argmax(labels[z])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e987c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = prelim_dataset.samples\n",
    "num_classes = max(prelim_dataset.labels) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba425506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adialer.C': 0,\n",
       " 'Agent.FYI': 1,\n",
       " 'Allaple.A': 2,\n",
       " 'Allaple.L': 3,\n",
       " 'Alueron.gen!J': 4,\n",
       " 'Autorun.K': 5,\n",
       " 'C2LOP.P': 6,\n",
       " 'C2LOP.gen!g': 7,\n",
       " 'Dialplatform.B': 8,\n",
       " 'Dontovo.A': 9,\n",
       " 'Fakerean': 10,\n",
       " 'Instantaccess': 11,\n",
       " 'Lolyda.AA1': 12,\n",
       " 'Lolyda.AA2': 13,\n",
       " 'Lolyda.AA3': 14,\n",
       " 'Lolyda.AT': 15,\n",
       " 'Malex.gen!J': 16,\n",
       " 'Obfuscator.AD': 17,\n",
       " 'Rbot!gen': 18,\n",
       " 'Skintrim.N': 19,\n",
       " 'Swizzor.gen!E': 20,\n",
       " 'Swizzor.gen!I': 21,\n",
       " 'VB.AT': 22,\n",
       " 'Wintrim.BX': 23,\n",
       " 'Yuner.A': 24}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prelim_dataset.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b0729",
   "metadata": {},
   "source": [
    "Create tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c29159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((imgs, labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250f6a3",
   "metadata": {},
   "source": [
    "Calculate number of input channel for Gen and Disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c8c4b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 26\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = chnum + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5518b3",
   "metadata": {},
   "source": [
    "# Creating discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5807858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((iw, ih, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73d69a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        layers.Dense(8 * 8 * generator_in_channels),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((8, 8, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f2b6070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        15040     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 384,321\n",
      "Trainable params: 384,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8019d328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 17984)             5071488   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 17984)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 281)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 16, 16, 128)       575616    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 32, 32, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 64, 64, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 1)         6273      \n",
      "=================================================================\n",
      "Total params: 6,177,921\n",
      "Trainable params: 6,177,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16291bdf",
   "metadata": {},
   "source": [
    "**Create Conditional GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1fa8cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[ih * iw]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, iw, ih, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e70546",
   "metadata": {},
   "source": [
    "**Optimizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cf8cba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers\n",
    "d_optimizer=keras.optimizers.Adam(learning_rate=0.0003)\n",
    "g_optimizer=keras.optimizers.Adam(learning_rate=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa94c67",
   "metadata": {},
   "source": [
    "**Checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "af608a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        # Save the model every 5 epochs \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "          checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b649da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cenv == 0:\n",
    "    checkpoint_dir = '/kaggle/working/checkpoints'\n",
    "if cenv == 1:\n",
    "    checkpoint_dir = f'{new_dir}'\n",
    "    \n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=g_optimizer,\n",
    "                                 discriminator_optimizer=d_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db7c93",
   "metadata": {},
   "source": [
    "# Training C-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a2338e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "146/146 [==============================] - 22s 144ms/step - g_loss: 1.5739 - d_loss: 0.6622\n",
      "Epoch 2/20\n",
      "146/146 [==============================] - 21s 142ms/step - g_loss: 1.6294 - d_loss: 0.5966\n",
      "Epoch 3/20\n",
      "146/146 [==============================] - 22s 148ms/step - g_loss: 1.1542 - d_loss: 0.6704\n",
      "Epoch 4/20\n",
      "146/146 [==============================] - 21s 147ms/step - g_loss: 2.3941 - d_loss: 0.4523\n",
      "Epoch 5/20\n",
      "146/146 [==============================] - 22s 148ms/step - g_loss: 4.1994 - d_loss: 0.4368\n",
      "Epoch 6/20\n",
      "146/146 [==============================] - 22s 149ms/step - g_loss: 3.1842 - d_loss: 0.4153\n",
      "Epoch 7/20\n",
      "146/146 [==============================] - 22s 151ms/step - g_loss: 4.9417 - d_loss: 0.0719\n",
      "Epoch 8/20\n",
      "146/146 [==============================] - 23s 157ms/step - g_loss: 3.9047 - d_loss: 0.0806\n",
      "Epoch 9/20\n",
      "146/146 [==============================] - 22s 153ms/step - g_loss: 4.9714 - d_loss: 0.0367\n",
      "Epoch 10/20\n",
      "146/146 [==============================] - 22s 151ms/step - g_loss: 2.0568 - d_loss: 0.4865\n",
      "Epoch 11/20\n",
      "146/146 [==============================] - 23s 155ms/step - g_loss: 0.8099 - d_loss: 0.6301\n",
      "Epoch 12/20\n",
      "146/146 [==============================] - 22s 149ms/step - g_loss: 0.9304 - d_loss: 0.5922\n",
      "Epoch 13/20\n",
      "146/146 [==============================] - 22s 147ms/step - g_loss: 0.9542 - d_loss: 0.6552\n",
      "Epoch 14/20\n",
      "146/146 [==============================] - 22s 147ms/step - g_loss: 0.9605 - d_loss: 0.6068\n",
      "Epoch 15/20\n",
      "146/146 [==============================] - 21s 147ms/step - g_loss: 1.0628 - d_loss: 0.6106\n",
      "Epoch 16/20\n",
      "146/146 [==============================] - 22s 148ms/step - g_loss: 0.9153 - d_loss: 0.7173\n",
      "Epoch 17/20\n",
      "146/146 [==============================] - 22s 148ms/step - g_loss: 0.8156 - d_loss: 0.7218\n",
      "Epoch 18/20\n",
      "146/146 [==============================] - 22s 147ms/step - g_loss: 1.2038 - d_loss: 0.6499\n",
      "Epoch 19/20\n",
      "146/146 [==============================] - 22s 149ms/step - g_loss: 0.9288 - d_loss: 0.6353\n",
      "Epoch 20/20\n",
      "146/146 [==============================] - 21s 146ms/step - g_loss: 0.7957 - d_loss: 0.6906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a77fa7a4c0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan.fit(dataset, epochs=epoch_t, \n",
    "        callbacks=GANMonitor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6263e9",
   "metadata": {},
   "source": [
    "# Interpolating between classes with the trained GEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a0397cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first extract the trained generator from our Conditiona GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 2000  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = tf.cast(first_label, tf.float32)\n",
    "    second_label = tf.cast(second_label, tf.float32)\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "780b224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new directory for saving folder\n",
    "os.makedirs(path_save_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0de5e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve class name based on number\n",
    "classes_list = list(prelim_dataset.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "79dfad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_classes):\n",
    "    class_name = classes_list[i]\n",
    "    class_dir = f\"{path_save_imgs}/{class_name}\"\n",
    "    os.makedirs(class_dir)\n",
    "    start_class = i\n",
    "    end_class = i\n",
    "    fake_images = interpolate_class(start_class, end_class)\n",
    "    fake_images *= 255\n",
    "    converted_images = fake_images.astype(np.uint8)\n",
    "    converted_images = tf.image.resize(converted_images, (64, 64)).numpy().astype(np.uint8)\n",
    "    for j in range(num_interpolation):\n",
    "        np_array = np.squeeze(converted_images[j], axis=2)\n",
    "        im = Image.fromarray((np_array))\n",
    "        im.save(f\"{class_dir}/gen_imgs_{class_name}_{j}.png\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
