{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Conditional GAN\n\nUsed to generate new training data for the ransomware families to overcome the skewed distribution of training data towards the benign samples. \n\nDim Size 128","metadata":{"papermill":{"duration":0.039629,"end_time":"2022-04-10T19:09:38.693894","exception":false,"start_time":"2022-04-10T19:09:38.654265","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Packages\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\n\nimport matplotlib.pyplot as plt \nimport tensorflow as tf\nimport numpy as np\nimport os\nfrom PIL import Image\nimport shutil","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:09:38.765616Z","iopub.status.busy":"2022-04-10T19:09:38.763422Z","iopub.status.idle":"2022-04-10T19:09:44.192544Z","shell.execute_reply":"2022-04-10T19:09:44.191668Z"},"papermill":{"duration":5.461966,"end_time":"2022-04-10T19:09:44.192736","exception":false,"start_time":"2022-04-10T19:09:38.73077","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Change parameters**","metadata":{"papermill":{"duration":0.023758,"end_time":"2022-04-10T19:09:44.241442","exception":false,"start_time":"2022-04-10T19:09:44.217684","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"-----","metadata":{"papermill":{"duration":0.023965,"end_time":"2022-04-10T19:09:44.289545","exception":false,"start_time":"2022-04-10T19:09:44.26558","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Batch size\nbatch_size = 64\n\n# Color mode\nch = 'grayscale'\n\n# Image size\niw, ih = 64,64\nim_size = (iw,ih)\n\n# Latent dim size\nlatent_dim = 128\n\n# Number of Epochs\nepoch_t = 500\n\n# Computation environment: Kaggle (0) or Local (1)\ncenv = 0\n\n# If weights are used: Weight factor\nwf = 0.5","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:09:44.343827Z","iopub.status.busy":"2022-04-10T19:09:44.342897Z","iopub.status.idle":"2022-04-10T19:09:44.344746Z","shell.execute_reply":"2022-04-10T19:09:44.345218Z"},"papermill":{"duration":0.031518,"end_time":"2022-04-10T19:09:44.345349","exception":false,"start_time":"2022-04-10T19:09:44.313831","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-----------","metadata":{"papermill":{"duration":0.02472,"end_time":"2022-04-10T19:09:44.394219","exception":false,"start_time":"2022-04-10T19:09:44.369499","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Automatic notebook preparation","metadata":{"papermill":{"duration":0.025554,"end_time":"2022-04-10T19:09:44.444044","exception":false,"start_time":"2022-04-10T19:09:44.41849","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if(ch == 'rgb'):\n    chnum = 3\nelif(ch == 'grayscale'):\n    chnum = 1","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:09:44.494878Z","iopub.status.busy":"2022-04-10T19:09:44.494071Z","iopub.status.idle":"2022-04-10T19:09:44.498462Z","shell.execute_reply":"2022-04-10T19:09:44.498044Z"},"papermill":{"duration":0.030532,"end_time":"2022-04-10T19:09:44.498568","exception":false,"start_time":"2022-04-10T19:09:44.468036","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cenv == 1:\n    file_exists = []\n    vnum = 1\n    dir = \"C:/Users/Max/Documents/GitHub/malimg_dataset\"\n    for files in os.listdir(dir):\n        if \"cgan\" in files:\n            try:\n                vnum = max(vnum, int(files[-3:]))\n            except: \n                continue\n            new_vnum = vnum + 1\n            file_exists.append(True)\n        else: \n            file_exists.append(False)\n    # If this is the first notebook you want to save, a new folder will be created with version #001\n    if sum(file_exists) == 0:\n        new_vnum = 1\n        print(\"No matches found\")\n\n    else: \n        print(f\"{sum(file_exists)} matches(es) found\")\n        print(\"--------------\")\n\n    # Print new folder name\n    print(f\"New folder name: cgan-local-v{new_vnum:03}\")\n    print(\"--------------\")\n    \n    # Create new folder with the name of the notebook and the version number\n    new_dir = f\"C://Users/Max/Documents/GitHub/malimg_dataset/cgan-local-v{new_vnum:03}\"\n    os.makedirs(new_dir)","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:09:44.555324Z","iopub.status.busy":"2022-04-10T19:09:44.554603Z","iopub.status.idle":"2022-04-10T19:09:44.556521Z","shell.execute_reply":"2022-04-10T19:09:44.556914Z"},"papermill":{"duration":0.032849,"end_time":"2022-04-10T19:09:44.557045","exception":false,"start_time":"2022-04-10T19:09:44.524196","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data preprocessing**","metadata":{"papermill":{"duration":0.024303,"end_time":"2022-04-10T19:09:44.605559","exception":false,"start_time":"2022-04-10T19:09:44.581256","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if cenv == 0:\n    path_root = \"/kaggle/input/malimgdataset\"\n    path_save_imgs = \"/kaggle/working/gen_images\"\nif cenv == 1:\n    path_root = \"C:/Users/Max/Documents/image_data/malimg_paper_dataset_imgs\"\n    path_save_imgs = f\"C:/Users/Max/Documents/image_data/malimg-cgan-local-v{new_vnum:03}\"","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:09:44.65872Z","iopub.status.busy":"2022-04-10T19:09:44.657968Z","iopub.status.idle":"2022-04-10T19:09:44.659883Z","shell.execute_reply":"2022-04-10T19:09:44.660268Z"},"papermill":{"duration":0.030577,"end_time":"2022-04-10T19:09:44.660385","exception":false,"start_time":"2022-04-10T19:09:44.629808","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rescale = 1/255)","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:09:44.712119Z","iopub.status.busy":"2022-04-10T19:09:44.711332Z","iopub.status.idle":"2022-04-10T19:09:44.715532Z","shell.execute_reply":"2022-04-10T19:09:44.715112Z"},"papermill":{"duration":0.030957,"end_time":"2022-04-10T19:09:44.715635","exception":false,"start_time":"2022-04-10T19:09:44.684678","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prelim_dataset = datagen.flow_from_directory(\n    directory = path_root,\n    color_mode = ch,\n    target_size = im_size,\n    interpolation = 'bicubic',\n    batch_size = 40000,\n    shuffle=False\n)\nimgs, labels = next(prelim_dataset)","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:09:44.769677Z","iopub.status.busy":"2022-04-10T19:09:44.769173Z","iopub.status.idle":"2022-04-10T19:10:50.352208Z","shell.execute_reply":"2022-04-10T19:10:50.351655Z"},"papermill":{"duration":65.61195,"end_time":"2022-04-10T19:10:50.352355","exception":false,"start_time":"2022-04-10T19:09:44.740405","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z = 7099+10\nplt.imshow(np.array(imgs[z]*255).astype(np.uint8), cmap=\"gray\")\nprint(\"Ransomware family: \",list(prelim_dataset.class_indices)[np.argmax(labels[z])])","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:50.414479Z","iopub.status.busy":"2022-04-10T19:10:50.413707Z","iopub.status.idle":"2022-04-10T19:10:50.61524Z","shell.execute_reply":"2022-04-10T19:10:50.615965Z"},"papermill":{"duration":0.236708,"end_time":"2022-04-10T19:10:50.61615","exception":false,"start_time":"2022-04-10T19:10:50.379442","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_samples = prelim_dataset.samples\nnum_classes = max(prelim_dataset.labels) + 1","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:50.677105Z","iopub.status.busy":"2022-04-10T19:10:50.67638Z","iopub.status.idle":"2022-04-10T19:10:50.678333Z","shell.execute_reply":"2022-04-10T19:10:50.678855Z"},"papermill":{"duration":0.034824,"end_time":"2022-04-10T19:10:50.679027","exception":false,"start_time":"2022-04-10T19:10:50.644203","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prelim_dataset.class_indices","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:50.740378Z","iopub.status.busy":"2022-04-10T19:10:50.738989Z","iopub.status.idle":"2022-04-10T19:10:50.742561Z","shell.execute_reply":"2022-04-10T19:10:50.742141Z"},"papermill":{"duration":0.036638,"end_time":"2022-04-10T19:10:50.74266","exception":false,"start_time":"2022-04-10T19:10:50.706022","status":"completed"},"scrolled":true,"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create tf.data.Dataset","metadata":{"papermill":{"duration":0.027163,"end_time":"2022-04-10T19:10:50.797753","exception":false,"start_time":"2022-04-10T19:10:50.77059","status":"completed"},"tags":[]}},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((imgs, labels))\ndataset = dataset.shuffle(buffer_size=1024).batch(batch_size)","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:53.292572Z","iopub.status.busy":"2022-04-10T19:10:53.291483Z","iopub.status.idle":"2022-04-10T19:10:53.416993Z","shell.execute_reply":"2022-04-10T19:10:53.41738Z"},"papermill":{"duration":2.592254,"end_time":"2022-04-10T19:10:53.41754","exception":false,"start_time":"2022-04-10T19:10:50.825286","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculate number of input channel for Gen and Disc","metadata":{"papermill":{"duration":0.028269,"end_time":"2022-04-10T19:10:53.474223","exception":false,"start_time":"2022-04-10T19:10:53.445954","status":"completed"},"tags":[]}},{"cell_type":"code","source":"generator_in_channels = latent_dim + num_classes\ndiscriminator_in_channels = chnum + num_classes\nprint(generator_in_channels, discriminator_in_channels)","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:53.53599Z","iopub.status.busy":"2022-04-10T19:10:53.533302Z","iopub.status.idle":"2022-04-10T19:10:53.538656Z","shell.execute_reply":"2022-04-10T19:10:53.539168Z"},"papermill":{"duration":0.036685,"end_time":"2022-04-10T19:10:53.539314","exception":false,"start_time":"2022-04-10T19:10:53.502629","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating discriminator and generator","metadata":{"papermill":{"duration":0.02806,"end_time":"2022-04-10T19:10:53.595699","exception":false,"start_time":"2022-04-10T19:10:53.567639","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Create the discriminator.\ndiscriminator = keras.Sequential(\n    [\n        keras.layers.InputLayer((iw, ih, discriminator_in_channels)),\n        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.GlobalMaxPooling2D(),\n        layers.Dense(1),\n    ],\n    name=\"discriminator\",\n)\n","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:53.658493Z","iopub.status.busy":"2022-04-10T19:10:53.657908Z","iopub.status.idle":"2022-04-10T19:10:53.744606Z","shell.execute_reply":"2022-04-10T19:10:53.743698Z"},"papermill":{"duration":0.120491,"end_time":"2022-04-10T19:10:53.744718","exception":false,"start_time":"2022-04-10T19:10:53.624227","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the generator.\ngenerator = keras.Sequential(\n    [\n        keras.layers.InputLayer((generator_in_channels,)),\n        # We want to generate 128 + num_classes coefficients to reshape into a\n        # 7x7x(128 + num_classes) map.\n        layers.Dense(8 * 8 * generator_in_channels),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Reshape((8, 8, generator_in_channels)),\n        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n    ],\n    name=\"generator\",\n)","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:53.808467Z","iopub.status.busy":"2022-04-10T19:10:53.807696Z","iopub.status.idle":"2022-04-10T19:10:53.877046Z","shell.execute_reply":"2022-04-10T19:10:53.876588Z"},"papermill":{"duration":0.103948,"end_time":"2022-04-10T19:10:53.877159","exception":false,"start_time":"2022-04-10T19:10:53.773211","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator.summary()","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:53.946034Z","iopub.status.busy":"2022-04-10T19:10:53.944346Z","iopub.status.idle":"2022-04-10T19:10:53.948833Z","shell.execute_reply":"2022-04-10T19:10:53.948245Z"},"papermill":{"duration":0.04165,"end_time":"2022-04-10T19:10:53.948958","exception":false,"start_time":"2022-04-10T19:10:53.907308","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.summary()","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:54.012841Z","iopub.status.busy":"2022-04-10T19:10:54.012343Z","iopub.status.idle":"2022-04-10T19:10:54.020508Z","shell.execute_reply":"2022-04-10T19:10:54.021585Z"},"papermill":{"duration":0.043091,"end_time":"2022-04-10T19:10:54.021742","exception":false,"start_time":"2022-04-10T19:10:53.978651","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create Conditional GAN**","metadata":{"papermill":{"duration":0.029558,"end_time":"2022-04-10T19:10:54.081369","exception":false,"start_time":"2022-04-10T19:10:54.051811","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ConditionalGAN(keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(ConditionalGAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n\n    @property\n    def metrics(self):\n        return [self.gen_loss_tracker, self.disc_loss_tracker]\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(ConditionalGAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n\n    def train_step(self, data):\n        # Unpack the data.\n        real_images, one_hot_labels = data\n\n        # Add dummy dimensions to the labels so that they can be concatenated with\n        # the images. This is for the discriminator.\n        image_one_hot_labels = one_hot_labels[:, :, None, None]\n        image_one_hot_labels = tf.repeat(\n            image_one_hot_labels, repeats=[ih * iw]\n        )\n        image_one_hot_labels = tf.reshape(\n            image_one_hot_labels, (-1, iw, ih, num_classes)\n        )\n\n        # Sample random points in the latent space and concatenate the labels.\n        # This is for the generator.\n        batch_size = tf.shape(real_images)[0]\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n        random_vector_labels = tf.concat(\n            [random_latent_vectors, one_hot_labels], axis=1\n        )\n\n        # Decode the noise (guided by labels) to fake images.\n        generated_images = self.generator(random_vector_labels)\n\n        # Combine them with real images. Note that we are concatenating the labels\n        # with these images here.\n        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n        combined_images = tf.concat(\n            [fake_image_and_labels, real_image_and_labels], axis=0\n        )\n\n        # Assemble labels discriminating real from fake images.\n        labels = tf.concat(\n            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n        )\n\n        # Train the discriminator.\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(\n            zip(grads, self.discriminator.trainable_weights)\n        )\n\n        # Sample random points in the latent space.\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n        random_vector_labels = tf.concat(\n            [random_latent_vectors, one_hot_labels], axis=1\n        )\n\n        # Assemble labels that say \"all real images\".\n        misleading_labels = tf.zeros((batch_size, 1))\n\n        # Train the generator (note that we should *not* update the weights\n        # of the discriminator)!\n        with tf.GradientTape() as tape:\n            fake_images = self.generator(random_vector_labels)\n            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n            predictions = self.discriminator(fake_image_and_labels)\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        # Monitor loss.\n        self.gen_loss_tracker.update_state(g_loss)\n        self.disc_loss_tracker.update_state(d_loss)\n        return {\n            \"g_loss\": self.gen_loss_tracker.result(),\n            \"d_loss\": self.disc_loss_tracker.result(),\n        }","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:54.149522Z","iopub.status.busy":"2022-04-10T19:10:54.148714Z","iopub.status.idle":"2022-04-10T19:10:54.161407Z","shell.execute_reply":"2022-04-10T19:10:54.16184Z"},"papermill":{"duration":0.050626,"end_time":"2022-04-10T19:10:54.161978","exception":false,"start_time":"2022-04-10T19:10:54.111352","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Optimizers**","metadata":{"papermill":{"duration":0.029823,"end_time":"2022-04-10T19:10:54.221232","exception":false,"start_time":"2022-04-10T19:10:54.191409","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define optimizers\nd_optimizer=keras.optimizers.Adam(learning_rate=0.0003)\ng_optimizer=keras.optimizers.Adam(learning_rate=0.0003)","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:54.284241Z","iopub.status.busy":"2022-04-10T19:10:54.283283Z","iopub.status.idle":"2022-04-10T19:10:54.288064Z","shell.execute_reply":"2022-04-10T19:10:54.287616Z"},"papermill":{"duration":0.037247,"end_time":"2022-04-10T19:10:54.288169","exception":false,"start_time":"2022-04-10T19:10:54.250922","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Checkpoints**","metadata":{"papermill":{"duration":0.029472,"end_time":"2022-04-10T19:10:54.348241","exception":false,"start_time":"2022-04-10T19:10:54.318769","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class GANMonitor(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        \n        # Save the model every 5 epochs \n        if (epoch + 1) % 10 == 0:\n          checkpoint.save(file_prefix = checkpoint_prefix)","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:54.41314Z","iopub.status.busy":"2022-04-10T19:10:54.412616Z","iopub.status.idle":"2022-04-10T19:10:54.415765Z","shell.execute_reply":"2022-04-10T19:10:54.416207Z"},"papermill":{"duration":0.038054,"end_time":"2022-04-10T19:10:54.416327","exception":false,"start_time":"2022-04-10T19:10:54.378273","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cenv == 0:\n    inp_dir = '../input/malimgcganoutput2/checkpoints'\n    outp_dir = 'checkpoints'\n    \n    try:\n        os.makedirs(outp_dir)\n    except:\n        pass\n    \n    \n    for item in os.listdir(inp_dir):\n        inp_file = os.path.join(inp_dir, item)\n        outp_file = os.path.join(outp_dir, item)\n        \n        shutil.copy(inp_file, outp_file)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T15:31:15.510337Z","iopub.execute_input":"2022-04-18T15:31:15.510629Z","iopub.status.idle":"2022-04-18T15:31:17.038902Z","shell.execute_reply.started":"2022-04-18T15:31:15.510596Z","shell.execute_reply":"2022-04-18T15:31:17.038084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cenv == 0:\n    checkpoint_dir = outp_dir\nif cenv == 1:\n    checkpoint_dir = f'C:/Users/Max/Documents/GitHub/malimg_dataset/malimg-cgan-output2/checkpoints'\n    \ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=g_optimizer,\n                                 discriminator_optimizer=d_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:54.483549Z","iopub.status.busy":"2022-04-10T19:10:54.482018Z","iopub.status.idle":"2022-04-10T19:10:54.48421Z","shell.execute_reply":"2022-04-10T19:10:54.484612Z"},"papermill":{"duration":0.038108,"end_time":"2022-04-10T19:10:54.484727","exception":false,"start_time":"2022-04-10T19:10:54.446619","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training C-GAN","metadata":{"papermill":{"duration":0.030074,"end_time":"2022-04-10T19:10:54.544817","exception":false,"start_time":"2022-04-10T19:10:54.514743","status":"completed"},"tags":[]}},{"cell_type":"code","source":"cond_gan = ConditionalGAN(\n    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n)\ncond_gan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n)\n\ncond_gan.fit(dataset, epochs=epoch_t, \n        callbacks=GANMonitor()\n)\n","metadata":{"execution":{"iopub.execute_input":"2022-04-10T19:10:54.611489Z","iopub.status.busy":"2022-04-10T19:10:54.610731Z","iopub.status.idle":"2022-04-10T21:21:28.487278Z","shell.execute_reply":"2022-04-10T21:21:28.486779Z"},"papermill":{"duration":7833.912816,"end_time":"2022-04-10T21:21:28.487417","exception":false,"start_time":"2022-04-10T19:10:54.574601","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Interpolating between classes with the trained GEN","metadata":{"papermill":{"duration":22.887202,"end_time":"2022-04-10T21:22:15.216797","exception":false,"start_time":"2022-04-10T21:21:52.329595","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# We first extract the trained generator from our Conditiona GAN.\ntrained_gen = cond_gan.generator\n\n# Choose the number of intermediate images that would be generated in\n# between the interpolation + 2 (start and last images).\nnum_interpolation = 2000  # @param {type:\"integer\"}\n\n# Sample noise for the interpolation.\ninterpolation_noise = tf.random.normal(shape=(1, latent_dim))\ninterpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\ninterpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n\n\ndef interpolate_class(first_number, second_number):\n    # Convert the start and end labels to one-hot encoded vectors.\n    first_label = keras.utils.to_categorical([first_number], num_classes)\n    second_label = keras.utils.to_categorical([second_number], num_classes)\n    first_label = tf.cast(first_label, tf.float32)\n    second_label = tf.cast(second_label, tf.float32)\n\n    # Calculate the interpolation vector between the two labels.\n    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n    percent_second_label = tf.cast(percent_second_label, tf.float32)\n    interpolation_labels = (\n        first_label * (1 - percent_second_label) + second_label * percent_second_label\n    )\n\n    # Combine the noise and the labels and run inference with the generator.\n    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n    fake = trained_gen.predict(noise_and_labels)\n    return fake\n\n","metadata":{"execution":{"iopub.execute_input":"2022-04-10T21:23:02.575171Z","iopub.status.busy":"2022-04-10T21:23:02.574518Z","iopub.status.idle":"2022-04-10T21:23:02.583025Z","shell.execute_reply":"2022-04-10T21:23:02.582582Z"},"papermill":{"duration":23.736107,"end_time":"2022-04-10T21:23:02.583138","exception":false,"start_time":"2022-04-10T21:22:38.847031","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create new directory for saving folder\nos.makedirs(path_save_imgs)","metadata":{"execution":{"iopub.execute_input":"2022-04-10T21:23:49.25081Z","iopub.status.busy":"2022-04-10T21:23:49.249888Z","iopub.status.idle":"2022-04-10T21:23:49.252218Z","shell.execute_reply":"2022-04-10T21:23:49.251661Z"},"papermill":{"duration":23.45063,"end_time":"2022-04-10T21:23:49.252335","exception":false,"start_time":"2022-04-10T21:23:25.801705","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve class name based on number\nclasses_list = list(prelim_dataset.class_indices)","metadata":{"execution":{"iopub.execute_input":"2022-04-10T21:24:36.69952Z","iopub.status.busy":"2022-04-10T21:24:36.698679Z","iopub.status.idle":"2022-04-10T21:24:36.7006Z","shell.execute_reply":"2022-04-10T21:24:36.701328Z"},"papermill":{"duration":23.688963,"end_time":"2022-04-10T21:24:36.701525","exception":false,"start_time":"2022-04-10T21:24:13.012562","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(num_classes):\n    class_name = classes_list[i]\n    class_dir = f\"{path_save_imgs}/{class_name}\"\n    os.makedirs(class_dir)\n    start_class = i\n    end_class = i\n    fake_images = interpolate_class(start_class, end_class)\n    fake_images *= 255\n    converted_images = fake_images.astype(np.uint8)\n    converted_images = tf.image.resize(converted_images, (64, 64)).numpy().astype(np.uint8)\n    for j in range(num_interpolation):\n        np_array = np.squeeze(converted_images[j], axis=2)\n        im = Image.fromarray((np_array))\n        im.save(f\"{class_dir}/gen_imgs_{class_name}_{j}.png\")    ","metadata":{"execution":{"iopub.execute_input":"2022-04-10T21:25:23.294433Z","iopub.status.busy":"2022-04-10T21:25:23.293824Z","iopub.status.idle":"2022-04-10T21:25:56.574143Z","shell.execute_reply":"2022-04-10T21:25:56.573612Z"},"papermill":{"duration":56.759675,"end_time":"2022-04-10T21:25:56.574285","exception":false,"start_time":"2022-04-10T21:24:59.81461","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}