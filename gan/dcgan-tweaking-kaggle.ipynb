{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n```\n# Dit is opgemaakt als code\n```\n\n# DCGAN to generate grayscale images\n","metadata":{"id":"Yqp2aX78LtH0"}},{"cell_type":"markdown","source":"## Setup","metadata":{"id":"MQ6hXbgPLtH2"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nimport cv2\nimport random as rd\nimport PIL","metadata":{"id":"waMV_df_LtH3","execution":{"iopub.status.busy":"2022-03-18T14:44:04.600836Z","iopub.execute_input":"2022-03-18T14:44:04.601132Z","iopub.status.idle":"2022-03-18T14:44:04.605763Z","shell.execute_reply.started":"2022-03-18T14:44:04.601084Z","shell.execute_reply":"2022-03-18T14:44:04.604975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CHANGE","metadata":{}},{"cell_type":"markdown","source":"_____________________________________________________________________","metadata":{}},{"cell_type":"code","source":"# Image size (height x width)\nih = 128\niw = 128\n\n# Grayscale or RGB\nch = 'rgb'\n\n# Layer adapt\nksize = 4 # Kernel size : was '4' for 64x64 image\nssize = 2 # Stride size : was '2' for 64x64 image\n\n# Batch size\nbatch_size = 32\n\n# TPU\nprint('Are you going to use TPU?')\nuse_tpu = input(\"y/n\")","metadata":{"id":"nXzDemd6yFMN","execution":{"iopub.status.busy":"2022-03-18T14:44:04.607389Z","iopub.execute_input":"2022-03-18T14:44:04.607699Z","iopub.status.idle":"2022-03-18T14:44:06.528128Z","shell.execute_reply.started":"2022-03-18T14:44:04.607663Z","shell.execute_reply":"2022-03-18T14:44:06.52742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_____________________________________________________________________","metadata":{}},{"cell_type":"markdown","source":"**TPU Setup (Optional & Automatic)**","metadata":{}},{"cell_type":"code","source":"if(use_tpu == 'y' or use_tpu == 'Y'):\n    # Detect and init. TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n    # Initialize distributed TPU strategy\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T14:44:06.529725Z","iopub.execute_input":"2022-03-18T14:44:06.531521Z","iopub.status.idle":"2022-03-18T14:44:06.537913Z","shell.execute_reply.started":"2022-03-18T14:44:06.531479Z","shell.execute_reply":"2022-03-18T14:44:06.536922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Tensorflow version \" + tf.__version__)","metadata":{"id":"DW2D1egMb3z7","outputId":"ba862c51-f373-4976-95cb-7dbeca8bae8e","execution":{"iopub.status.busy":"2022-03-18T14:44:06.5426Z","iopub.execute_input":"2022-03-18T14:44:06.544152Z","iopub.status.idle":"2022-03-18T14:44:06.554613Z","shell.execute_reply.started":"2022-03-18T14:44:06.544105Z","shell.execute_reply":"2022-03-18T14:44:06.552811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try: \n    os.mkdir(\"/kaggle/working/checkpoints\")\n    print(\"Path for checkpoints has been created!\")\nexcept:\n    print(\"Path already exists\")","metadata":{"execution":{"iopub.status.busy":"2022-03-18T14:44:06.557685Z","iopub.execute_input":"2022-03-18T14:44:06.559194Z","iopub.status.idle":"2022-03-18T14:44:06.568732Z","shell.execute_reply.started":"2022-03-18T14:44:06.559156Z","shell.execute_reply":"2022-03-18T14:44:06.568108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    os.mkdir(\"/kaggle/working/generated_images\")\n    print(\"Path for generated images has been created!\")\nexcept:\n    print(\"Path already exists\")","metadata":{"execution":{"iopub.status.busy":"2022-03-18T14:44:06.570206Z","iopub.execute_input":"2022-03-18T14:44:06.570748Z","iopub.status.idle":"2022-03-18T14:44:06.583399Z","shell.execute_reply.started":"2022-03-18T14:44:06.570698Z","shell.execute_reply":"2022-03-18T14:44:06.580722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare CelebA data\n\nWe'll use face images from the CelebA dataset, resized to 64x64.","metadata":{"id":"uOZNby3TLtH4"}},{"cell_type":"code","source":"# Overwrite if TPU is used\nif use_tpu == 'y' or use_tpu == 'Y':\n    batch_size = 16 * tpu_strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.status.busy":"2022-03-18T14:44:06.584175Z","iopub.execute_input":"2022-03-18T14:44:06.58452Z","iopub.status.idle":"2022-03-18T14:44:06.591136Z","shell.execute_reply.started":"2022-03-18T14:44:06.584482Z","shell.execute_reply":"2022-03-18T14:44:06.590433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_tpu == 'y' or use_tpu == 'Y':\n    # Step 1: Get the credentail from the Cloud SDK\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    user_credential = user_secrets.get_gcloud_credential()\n    \n    # Step 2: Set the credentials\n    user_secrets.set_tensorflow_credential(user_credential)\n    \n    # Step 3: Use a familiar call to get the GCS path of the dataset\n    !gcloud config set project 'solid-topic-344315'\n    \n    GCS_DS_PATH = 'gs://thesis_data_max/classified_data'\n\n    \nelse: path_root = '/kaggle/input/thesis-data'","metadata":{"id":"4H4AwAFpLtH4","execution":{"iopub.status.busy":"2022-03-18T14:44:06.592354Z","iopub.execute_input":"2022-03-18T14:44:06.592662Z","iopub.status.idle":"2022-03-18T14:44:06.602193Z","shell.execute_reply.started":"2022-03-18T14:44:06.592627Z","shell.execute_reply":"2022-03-18T14:44:06.601475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a dataset from our folder, and rescale the images to the [0-1] range:","metadata":{"id":"JP_TdOVnLtH5"}},{"cell_type":"code","source":"im_si = (ih, iw)\n\nif(ch == 'rgb'):\n    chnum = 3\nelif(ch == 'grayscale'):\n    chnum = 1\n","metadata":{"execution":{"iopub.status.busy":"2022-03-18T14:44:06.603309Z","iopub.execute_input":"2022-03-18T14:44:06.603849Z","iopub.status.idle":"2022-03-18T14:44:06.616963Z","shell.execute_reply.started":"2022-03-18T14:44:06.603806Z","shell.execute_reply":"2022-03-18T14:44:06.609337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    path_root, \n    label_mode = None,\n    color_mode = ch,\n    image_size = im_si,\n    interpolation='bicubic',\n    batch_size = batch_size\n)\n\ndataset = dataset.map(lambda x : x / 255.0)","metadata":{"id":"WH5fIdgBnZE5","outputId":"2957b61c-4951-407c-a889-77ed834b57a8","execution":{"iopub.status.busy":"2022-03-18T14:44:06.621505Z","iopub.execute_input":"2022-03-18T14:44:06.62502Z","iopub.status.idle":"2022-03-18T14:44:11.17791Z","shell.execute_reply.started":"2022-03-18T14:44:06.62498Z","shell.execute_reply":"2022-03-18T14:44:11.177224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's display a sample image:","metadata":{"id":"bk2Y9PcvLtH6"}},{"cell_type":"markdown","source":"## Create the discriminator\n\nIt maps a 64x64 image to a binary classification score.","metadata":{"id":"219PDLAMLtH7"}},{"cell_type":"code","source":"def create_discriminator():\n  return keras.Sequential(\n      [\n        \n          layers.Conv2D(ih, kernel_size=ksize, strides=ssize, padding=\"same\",\n                        input_shape=(ih, iw, chnum)),\n          layers.LeakyReLU(alpha=0.2),\n          layers.Conv2D(2*ih, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.LeakyReLU(alpha=0.2),\n          layers.Conv2D(2*ih, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.LeakyReLU(alpha=0.2),\n          layers.Flatten(),\n          layers.Dropout(0.2),\n          layers.Dense(1, activation=\"sigmoid\"),\n      ],\n      name=\"discriminator\",\n  )\n","metadata":{"id":"xUEQGyFpLtH8","execution":{"iopub.status.busy":"2022-03-18T14:44:11.179218Z","iopub.execute_input":"2022-03-18T14:44:11.179464Z","iopub.status.idle":"2022-03-18T14:44:11.185902Z","shell.execute_reply.started":"2022-03-18T14:44:11.179433Z","shell.execute_reply":"2022-03-18T14:44:11.185104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create the generator\n\nIt mirrors the discriminator, replacing `Conv2D` layers with `Conv2DTranspose` layers.","metadata":{"id":"OoTIdSsDLtH8"}},{"cell_type":"code","source":"latent_dim = 2*ih\nsih = ih//8\nsiw = iw//8\n\ndef create_generator():\n  return keras.Sequential(\n      [\n          keras.layers.InputLayer(input_shape=(latent_dim)),\n          \n          layers.Dense(sih * siw * latent_dim),\n          layers.Reshape((sih, siw, latent_dim)),\n          layers.Conv2DTranspose(latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.LeakyReLU(alpha=0.2),\n          layers.Conv2DTranspose(2*latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.LeakyReLU(alpha=0.2),\n          layers.Conv2DTranspose(4*latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.LeakyReLU(alpha=0.2),\n          layers.Conv2D(chnum, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n      ],\n      name=\"generator\",\n  )\n","metadata":{"scrolled":true,"id":"oJWFNzjjLtH8","execution":{"iopub.status.busy":"2022-03-18T14:44:11.187436Z","iopub.execute_input":"2022-03-18T14:44:11.187936Z","iopub.status.idle":"2022-03-18T14:44:11.197775Z","shell.execute_reply.started":"2022-03-18T14:44:11.187857Z","shell.execute_reply":"2022-03-18T14:44:11.197003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_tpu == 'y' or use_tpu == 'Y':\n    with tpu_strategy.scope():\n        generator = create_generator()\n        discriminator = create_discriminator()\nelse:  \n    generator = create_generator()\n    discriminator = create_discriminator()","metadata":{"id":"eAzWstRrJTnV","execution":{"iopub.status.busy":"2022-03-18T14:44:11.198983Z","iopub.execute_input":"2022-03-18T14:44:11.199447Z","iopub.status.idle":"2022-03-18T14:44:11.308281Z","shell.execute_reply.started":"2022-03-18T14:44:11.19941Z","shell.execute_reply":"2022-03-18T14:44:11.307401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Override `train_step`","metadata":{"id":"35QhQ42WLtH9"}},{"cell_type":"code","source":"class GAN(keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(GAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(GAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n\n    @property\n    def metrics(self):\n        return [self.d_loss_metric, self.g_loss_metric]\n\n    def train_step(self, real_images):\n        # Sample random points in the latent space\n        \n        batch_size = tf.shape(real_images)[0]\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Decode them to fake images\n        generated_images = self.generator(random_latent_vectors)\n\n        # Combine them with real images\n        combined_images = tf.concat([generated_images, real_images], axis=0)\n\n        # Assemble labels discriminating real from fake images\n        labels = tf.concat(\n            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n        )\n        # Add random noise to the labels - important trick!\n        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n\n        # Train the discriminator\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(\n            zip(grads, self.discriminator.trainable_weights)\n        )\n\n        # Sample random points in the latent space\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Assemble labels that say \"all real images\"\n        misleading_labels = tf.zeros((batch_size, 1))\n\n        # Train the generator (note that we should *not* update the weights\n        # of the discriminator)!\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(self.generator(random_latent_vectors))\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        # Update metrics\n        self.d_loss_metric.update_state(d_loss)\n        self.g_loss_metric.update_state(g_loss)\n        return {\n            \"d_loss\": self.d_loss_metric.result(),\n            \"g_loss\": self.g_loss_metric.result(),\n        }\n  \n","metadata":{"id":"y8nmAfrtLtH9","execution":{"iopub.status.busy":"2022-03-18T14:44:11.309668Z","iopub.execute_input":"2022-03-18T14:44:11.309899Z","iopub.status.idle":"2022-03-18T14:44:11.324842Z","shell.execute_reply.started":"2022-03-18T14:44:11.309866Z","shell.execute_reply":"2022-03-18T14:44:11.324179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Other GAN Script**","metadata":{"id":"xQUSDLa9LtH-"}},{"cell_type":"code","source":"# This method returns a helper function to compute cross entropy loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","metadata":{"id":"bnGLeB0_LtH-","execution":{"iopub.status.busy":"2022-03-18T14:44:11.325729Z","iopub.execute_input":"2022-03-18T14:44:11.325938Z","iopub.status.idle":"2022-03-18T14:44:11.33723Z","shell.execute_reply.started":"2022-03-18T14:44:11.325914Z","shell.execute_reply":"2022-03-18T14:44:11.336537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(real_output, fake_output, d_loss):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    d_loss.append(total_loss)\n    return total_loss","metadata":{"id":"GnZ9x59bLtH-","execution":{"iopub.status.busy":"2022-03-18T14:44:11.34019Z","iopub.execute_input":"2022-03-18T14:44:11.340946Z","iopub.status.idle":"2022-03-18T14:44:11.347256Z","shell.execute_reply.started":"2022-03-18T14:44:11.34091Z","shell.execute_reply":"2022-03-18T14:44:11.346446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator_loss(fake_output, g_loss):\n    fake_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n    g_loss.append(fake_loss)\n    return fake_loss","metadata":{"id":"pvt697zkLtH_","execution":{"iopub.status.busy":"2022-03-18T14:44:11.3488Z","iopub.execute_input":"2022-03-18T14:44:11.349249Z","iopub.status.idle":"2022-03-18T14:44:11.355896Z","shell.execute_reply.started":"2022-03-18T14:44:11.34921Z","shell.execute_reply":"2022-03-18T14:44:11.355268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","metadata":{"id":"58LhymTSLtH_","execution":{"iopub.status.busy":"2022-03-18T14:44:11.357808Z","iopub.execute_input":"2022-03-18T14:44:11.358577Z","iopub.status.idle":"2022-03-18T14:44:11.365908Z","shell.execute_reply.started":"2022-03-18T14:44:11.35854Z","shell.execute_reply":"2022-03-18T14:44:11.365258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator.summary()","metadata":{"id":"ixCCxiGLHgmV","execution":{"iopub.status.busy":"2022-03-18T14:44:11.367283Z","iopub.execute_input":"2022-03-18T14:44:11.367832Z","iopub.status.idle":"2022-03-18T14:44:11.37963Z","shell.execute_reply.started":"2022-03-18T14:44:11.367793Z","shell.execute_reply":"2022-03-18T14:44:11.378801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.summary()","metadata":{"id":"qF-AyFSjHzoY","execution":{"iopub.status.busy":"2022-03-18T14:44:11.381922Z","iopub.execute_input":"2022-03-18T14:44:11.38233Z","iopub.status.idle":"2022-03-18T14:44:11.391565Z","shell.execute_reply.started":"2022-03-18T14:44:11.382293Z","shell.execute_reply":"2022-03-18T14:44:11.390655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_dir = '/kaggle/working/checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=create_generator(),\n                                 discriminator=create_discriminator())","metadata":{"id":"QwKJcZWrLtH_","execution":{"iopub.status.busy":"2022-03-18T14:44:11.392639Z","iopub.execute_input":"2022-03-18T14:44:11.393059Z","iopub.status.idle":"2022-03-18T14:44:11.519219Z","shell.execute_reply.started":"2022-03-18T14:44:11.39302Z","shell.execute_reply":"2022-03-18T14:44:11.518427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a callback that periodically saves generated images","metadata":{"id":"puaQCbHtLtH_"}},{"cell_type":"code","source":"class GANMonitor(keras.callbacks.Callback):\n    def __init__(self, num_img=3, latent_dim=latent_dim):\n        self.num_img = num_img\n        self.latent_dim = latent_dim\n\n    def on_epoch_end(self, epoch, logs=None):\n        start = time.time()\n        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n        generated_images = self.model.generator(random_latent_vectors)\n        generated_images *= 255\n        generated_images.numpy()\n        for i in range(self.num_img):\n            img = keras.preprocessing.image.array_to_img(generated_images[i])\n            img.save(\"/kaggle/working/generated_images/generated_img_%03d_%d.png\" % (epoch, i))\n    \n        # Save the model every 15 epochs (WAS 15)\n        if (epoch + 1) % 15 == 0:\n          checkpoint.save(file_prefix = checkpoint_prefix)\n\n","metadata":{"id":"8jTG8X3xLtH_","execution":{"iopub.status.busy":"2022-03-18T14:44:11.52046Z","iopub.execute_input":"2022-03-18T14:44:11.521289Z","iopub.status.idle":"2022-03-18T14:44:11.529504Z","shell.execute_reply.started":"2022-03-18T14:44:11.521257Z","shell.execute_reply":"2022-03-18T14:44:11.528273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the end-to-end model","metadata":{"id":"_Bn3n_AaLtIA"}},{"cell_type":"code","source":"epochs = 90  # In practice, use ~100 epochs\n\nif use_tpu == 'y' or use_tpu == 'Y':\n    with tpu_strategy.scope():\n        gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n\n        gan.compile(\n        d_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n        g_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n        loss_fn=keras.losses.BinaryCrossentropy(),\n        )\n        \nelse: \n    gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n\n    gan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n    loss_fn=keras.losses.BinaryCrossentropy(),\n    )\n\n#steps_per_epoch = 2500 // batch_size\ngan.fit(\n  dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n)","metadata":{"scrolled":true,"id":"7atjQsdbLtIA","outputId":"201f7c7d-f6ef-487d-9843-51ef8f267c67","execution":{"iopub.status.busy":"2022-03-18T14:44:11.53128Z","iopub.execute_input":"2022-03-18T14:44:11.531701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in dataset:\n  i = rd.randint(0,2512)\n  plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n  break","metadata":{"id":"IWm3DeULK_BH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some of the last generated images around epoch 30\n(results keep improving after that):\n","metadata":{"id":"s-gZ4WSgLtIA"}},{"cell_type":"markdown","source":"# Checkpoint Restore","metadata":{"id":"LBGlaWncLtIA"}},{"cell_type":"code","source":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","metadata":{"id":"gE-OlXC2LtIA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"f66OR5_-LtIA"},"execution_count":null,"outputs":[]}]}