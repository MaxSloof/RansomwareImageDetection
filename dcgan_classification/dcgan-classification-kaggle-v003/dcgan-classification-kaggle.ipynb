{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Deep Convolutional Generative Adversarial Network - Classification (2of2)"]},{"cell_type":"markdown","metadata":{},"source":["**Notes about this specific notebook**\n","\n","Uses grayscale, 64x64 images, with ReLU activation.\n","\n","Uses 10 and 15 epochs instead of initial 7 and 8. Performance seems worse due to overfitting.\n","\n","Should use exact same layers as DCGAN model. \n","\n","Based on dcgan_v002\n"]},{"cell_type":"markdown","metadata":{},"source":["# Change\n","\n","Image height, image width, color channel, ksize and ssize should align with GAN.\n","\n","Just like the generator and discriminator should be identical to the one in GAN"]},{"cell_type":"markdown","metadata":{},"source":["----------------------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Image size (height x width)\n","ih = 64\n","iw = 64\n","\n","# Grayscale or RGB\n","ch = 'grayscale'\n","\n","# Batch size \n","batch_size = 40000\n","\n","# Layer adapt\n","ksize = 4 # Kernel size : was '4' for 64x64 image\n","ssize = 2 # Stride size : was '2' for 64x64 image\n","\n","# Size of test set (in %)\n","testsize = 0.3\n","\n","# Number of epochs in untrainable model\n","epoch_unt = 10\n","\n","# Number of epochs in trainable model\n","epoch_t = 15\n","\n","# Where computation is performed: Kaggle (0) or Local (1)\n","cenv = 0"]},{"cell_type":"markdown","metadata":{},"source":["-----"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if cenv == 0:\n","    print(\"Computation environment: Kaggle\")\n","if cenv == 1:\n","    print(\"Computation environment: Local\")"]},{"cell_type":"markdown","metadata":{},"source":["**Import required packages**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import Sequential, layers\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from tensorflow.keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import glob\n","import os\n","import PIL\n","import time\n","from IPython import display"]},{"cell_type":"markdown","metadata":{},"source":["Automatic parameter changes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["im_si = (ih, iw)\n","\n","if(ch == 'rgb'):\n","    chnum = 3\n","elif(ch == 'grayscale'):\n","    chnum = 1"]},{"cell_type":"markdown","metadata":{},"source":["Create new directory for saving output files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if cenv == 1:\n","    file_exists = []\n","    vnum = 1\n","    dir = \"C:/Users/Max/Documents/GitHub/dcgan_classification\"\n","    for files in os.listdir(dir):\n","        if \"dcgan-classification\" in files: \n","            try:\n","                vnum = max(vnum, int(files[-3:]))\n","            except: \n","                continue\n","            new_vnum = vnum + 1\n","            file_exists.append(True)\n","        else: \n","            file_exists.append(False)\n","    # If this is the first notebook you want to save, a new folder will be created with version #001\n","    if sum(file_exists) == 0:\n","        new_vnum = 1\n","        print(\"No matches found\")\n","\n","    else: \n","        print(f\"{sum(file_exists)} matches(es) found\")\n","        print(\"--------------\")\n","\n","    # Print new folder name\n","    print(f\"New folder name: dcgan-classification-local-v{new_vnum:03}\")\n","    print(\"--------------\")\n","    \n","    # Create new folder with the name of the notebook and the version number\n","    new_dir = f\"/Users/Max/Documents/GitHub/dcgan_classification/dcgan-classification-local-v{new_vnum:03}\"\n","    os.makedirs(new_dir)"]},{"cell_type":"markdown","metadata":{},"source":["# Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if cenv == 0:\n","    path_root = \"/kaggle/input/thesis-data\"\n","    \n","    # Directory where checkpoints of DCGAN are stored\n","    checkpoint_dir = \"/kaggle/input/checkpoints\" \n","\n","if cenv == 1:\n","    path_root = \"C:/Users/Max/Documents/thesis_data\"\n","    \n","    # Directory where checkpoints of DCGAN are stored\n","    checkpoint_dir = 'C:/Users/Max/Documents/GitHub/dcgan_kaggle_output/dcgan-kaggle-v002/checkpoints'\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["batches = ImageDataGenerator().flow_from_directory(\n","    directory  = path_root, \n","    color_mode = ch, \n","    target_size= (ih,iw), \n","    class_mode= \"sparse\", \n","    interpolation=\"bicubic\", \n","    batch_size=batch_size\n",")\n","imgs, labels = next(batches)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["imgs.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batches.class_indices"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_classes = len(batches.class_indices)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(imgs, labels, test_size=testsize)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classes = batches.class_indices.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["multi_distribution = np.unique(labels, return_counts=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["perc = (multi_distribution[1]/labels.shape[0])*100\n","plt.xticks(rotation='vertical')\n","plt.bar(classes,perc)\n","if cenv == 0:\n","    plt.savefig(\"multi_data_dist.png\", bbox_inches = 'tight')\n","if cenv == 1:\n","    plt.savefig(f\"{new_dir}/multi_data_dist.png\", bbox_inches = 'tight')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainsize = len(X_train)\n","testsize = len(X_test)\n","\n","print(f\"Size of training data: {trainsize} | Shape of training data {X_train.shape}\")\n","print(f\"Size of training data: {testsize}  | Shape of training data {X_test.shape}\")\n","print(f\"Shape of training labels {y_train.shape}\")\n","print(f\"Shape of training labels {y_test.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def my_fmt(x):\n","    return '{:.1f}%\\n({:.0f})'.format(x, total*x/100)\n","total = trainsize + testsize"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.pie(\n","    [trainsize, testsize], \n","    labels = [\"Training\", \"Validation\"], \n","    startangle=90, \n","    counterclock=False, \n","    autopct=my_fmt,\n","    colors = ['gray', 'silver']\n",")\n","\n","plt.title(\"Training and validation data distribution\")\n","\n","if cenv == 0:\n","    plt.savefig(\"train_test_dist.png\", bbox_inches = 'tight')\n","if cenv == 1:\n","    plt.savefig(f\"{new_dir}/train_test_dist.png\", bbox_inches = 'tight')"]},{"cell_type":"markdown","metadata":{},"source":["# Preparing models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["latent_dim = ih\n","sih = ih//8\n","siw = iw//8\n","\n","generator = keras.Sequential(\n","    [\n","          keras.layers.InputLayer(input_shape=(latent_dim)),\n","          \n","          layers.Dense(sih * siw * latent_dim),\n","          layers.Reshape((sih, siw, latent_dim)),\n","          layers.Conv2DTranspose(latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n","          layers.ReLU(),\n","          layers.Conv2DTranspose(2*latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n","          layers.ReLU(),\n","          layers.Conv2DTranspose(4*latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n","          layers.ReLU(),\n","          layers.Conv2D(chnum, kernel_size=ksize+1, padding=\"same\", activation=\"sigmoid\"),\n","      ],\n","    name=\"generator\",\n",")\n","generator.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["discriminator = keras.Sequential(\n","       [\n","        \n","          layers.Conv2D(ih, kernel_size=ksize, strides=ssize, padding=\"same\",\n","                        input_shape=(ih, iw, chnum)),\n","          layers.ReLU(),\n","          layers.Conv2D(2*ih, kernel_size=ksize, strides=ssize, padding=\"same\"),\n","          layers.ReLU(),\n","          layers.Conv2D(2*ih, kernel_size=ksize, strides=ssize, padding=\"same\"),\n","          layers.ReLU(),\n","          layers.Flatten(),\n","          layers.Dropout(0.2),\n","          layers.Dense(1, activation=\"sigmoid\"),\n","      ],\n","    name=\"discriminator\",\n",")\n","discriminator.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n","                                 discriminator_optimizer=discriminator_optimizer,\n","                                 generator=generator,\n","                                 discriminator=discriminator)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"]},{"cell_type":"markdown","metadata":{},"source":["Now, we transfer the weights of discriminator except the last layer to a new model, add a dense layer with 128 units, and add another dense layer with 10 units and softmax activation."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["disc = checkpoint.discriminator\n","    \n","classification_model = Sequential()\n","for i in range(len(disc.layers) - 1):\n","    classification_model.add(disc.layers[i])\n","\n","for layer in classification_model.layers:\n","    layers.trainable = False\n","\n","classification_model.add(Dense(128, activation = \"relu\"))\n","classification_model.add(Dense(num_classes, activation = \"softmax\"))\n","classification_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# view the initialized weights and bias of the second last dense layer; weights are uniformly randomly generated \n","# and biases are all zeroes by default\n","classification_model.layers[-2].weights"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_images = X_train.reshape((trainsize, ih,iw,chnum))\n","train_images = train_images.astype('float32') / 255 # Was *255\n","train_images.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_images = X_test.reshape((testsize, ih,iw,chnum))\n","test_images = test_images.astype('float32') / 255 # Was *255"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_labels = to_categorical(y_train)\n","test_labels = to_categorical(y_test)\n","\n","print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classification_model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","history1 = classification_model.fit(train_images, train_labels, batch_size=100, epochs=epoch_unt,\n","                        validation_data=(test_images, test_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# unfreeze all layers \n","for layer in classification_model.layers:\n","    layer.trainable = True\n","\n","#optimizer=classification_model.optimizer\n","#optimizer.learning_rate=0.005\n","    \n","classification_model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","history2 = classification_model.fit(train_images, train_labels, batch_size=100, epochs=epoch_t,\n","                        validation_data=(test_images, test_labels)) \n"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluating performance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score\n","from prettytable import PrettyTable, MSWORD_FRIENDLY"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy = history1.history['accuracy'] + history2.history['accuracy']\n","val_accuracy = history1.history['val_accuracy'] + history2.history['val_accuracy']\n","\n","loss = history1.history['loss'] + history2.history['loss']\n","val_loss = history1.history['val_loss'] + history2.history['val_loss']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate total number of epochs (the arrays above are the accuracies for every epoch, so you need the latest one)\n","total_epochs = epoch_t + epoch_unt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scores = [val_loss, val_accuracy]\n","print(f\"Overall CNN Accuracy: {scores[1][total_epochs-1]}\\n(The number of correct predictions divided by the number of total predictions)\")\n","# Total epochs - 1, because array starts at 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t = PrettyTable(['Metric', 'Performance'])\n","t.add_row(['Valididation accuracy', round(scores[1][total_epochs-1],4)])\n","t.add_row(['Validation loss', round(scores[0][total_epochs-1],4)])\n","t.header = True\n","t.align = \"l\"\n","t.title = \"Performance of multi-class classification - CNN\"\n","print(t)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Saving PrettyTable\n","table = t.get_string()\n","\n","if cenv == 0:\n","    with open('multi_performance_table.txt', 'w') as f:\n","        f.write(table)\n","if cenv == 1:\n","    with open(f'{new_dir}/multi_performance_table.txt', 'w') as f:\n","        f.write(table)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure()\n","plt.plot(accuracy, label='accuracy')\n","plt.plot(val_accuracy, label = 'val_accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.ylim([0.3, 1])\n","plt.legend(loc='lower right')\n","if cenv == 0:\n","    plt.savefig(\"dcgan_class_model_acc.png\", bbox_inches = 'tight')\n","if cenv == 1:\n","    plt.savefig(f\"{new_dir}/dcgan_class_model_acc.png\", bbox_inches = 'tight')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure()\n","plt.plot(loss, label='loss')\n","plt.plot(val_loss, label = 'val_loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.ylim([0, 0.5])\n","plt.legend(loc='lower right')\n","if cenv == 0:\n","    plt.savefig(\"dcgan_class_model_loss.png\", bbox_inches = 'tight')\n","if cenv == 1:\n","    plt.savefig(f\"{new_dir}/dcgan_class_model_loss.png\", bbox_inches = 'tight')"]},{"cell_type":"markdown","metadata":{},"source":["We can see that, using the tuned discriminator model, both training accuracy and testing are approximately 0.94 after 15 epochs."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# demonstration: predict the ith test digit\n","i = np.random.randint(0, testsize)\n","\n","# show the actual ith digit\n","print('actual label:', np.argmax(test_labels[i]))\n","plt.figure()\n","plt.imshow(test_images[i,:,:,0], cmap='gray')\n","plt.show()\n","\n","# predict\n","prediction = classification_model.predict(test_images[i].reshape(1,ih,iw,chnum))\n","\n","# get probability distribution and classification of the test digit\n","print(prediction)\n","print(\"-----------------------------------------------------------------------\")\n","print('prediction:', np.argmax(prediction))\n","\n","# draw the barplot\n","plt.figure()\n","plt.bar(np.arange(0,11).astype('str'), prediction[0,:])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Analyse performance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn import metrics\n","import pandas as pd\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = np.argmax(classification_model.predict(test_images), axis=-1)\n","true_labels = test_labels.argmax(axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_test2 = np.argmax(test_labels, axis=1)\n","y_test2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["c_matrix = metrics.confusion_matrix(y_test2, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n","   \n","    df_cm = pd.DataFrame(\n","        confusion_matrix, index=class_names, columns=class_names, \n","    )\n","    fig = plt.figure(figsize=figsize)\n","    try:\n","        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n","    except ValueError:\n","        raise ValueError(\"Confusion matrix values must be integers.\")\n","    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n","    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.tight_layout()\n","    if cenv == 0:\n","        plt.savefig(\"multi_class_cmatrix.png\")\n","    if cenv == 1:\n","        plt.savefig(f\"{new_dir}/multi_class_cmatrix.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class_names= batches.class_indices.keys()\n","confusion_matrix(c_matrix, class_names, figsize = (20,7), fontsize=14)"]},{"cell_type":"markdown","metadata":{},"source":["# Binary classification"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score\n","from prettytable import PrettyTable, MSWORD_FRIENDLY"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_predbin = [] \n","y_truebin = []\n","for count, value in enumerate(y_test2):\n","    if y_test2[count] in range(10): # range(10) is 0 to 9\n","        y_truebin.append(0)\n","    else: y_truebin.append(1)\n","    \n","    if y_pred[count] in range(10):\n","        y_predbin.append(0)\n","    else: y_predbin.append(1)\n","    \n","    continue\n","if len(y_truebin) == len(y_predbin):\n","    print(f\"Length of the observations in test set: {len(y_truebin)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rw_count = 0\n","bn_count = 0\n","for count, value in enumerate(multi_distribution[1]):\n","    if count in range(10):\n","        rw_count = rw_count + multi_distribution[1][count]\n","    else: \n","        bn_count = bn_count + multi_distribution[1][count]\n","print(f\"Ransomware Occurences: {rw_count}, Benign Occurences: {bn_count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure()\n","ax = fig.add_axes([0,0,1,1])\n","x_lab = ['Ransomware', 'Benign']\n","y_lab = [rw_count, bn_count]\n","ax.bar(x_lab, y_lab)\n","if cenv == 0:\n","    plt.savefig(\"data_dist.png.png\", bbox_inches = 'tight')\n","if cenv == 1:\n","    plt.savefig(f\"{new_dir}/bin_data_dist.png\", bbox_inches = 'tight')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["c_matrix_bin = metrics.confusion_matrix(y_truebin, y_predbin)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def confusion_matrix_bin(confusion_matrix, class_names_bin, figsize = (5,2), fontsize=7):\n","   \n","    df_cm = pd.DataFrame(\n","        confusion_matrix, index=class_names_bin, columns=class_names_bin, \n","    )\n","    fig = plt.figure(figsize=figsize)\n","    try:\n","        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n","    except ValueError:\n","        raise ValueError(\"Confusion matrix values must be integers.\")\n","    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n","    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    if cenv == 0:\n","        plt.savefig(\"bin_class_cmatrix.png\", bbox_inches = 'tight')\n","    if cenv == 1:\n","        plt.savefig(f\"{new_dir}/bin_class_cmatrix.png\", bbox_inches = 'tight')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class_names_bin= (\"ransomware\", \"benign\")\n","confusion_matrix_bin(c_matrix_bin, class_names_bin, figsize = (5,2), fontsize=10)"]},{"cell_type":"markdown","metadata":{},"source":["**True Positive Rate**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["TPR = c_matrix_bin[0,0]/(c_matrix_bin[0,0] + c_matrix_bin[0,1]) #True Positive Rate"]},{"cell_type":"markdown","metadata":{},"source":["**Accuracy**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ACC = accuracy_score(y_truebin, y_predbin) # Accuracy"]},{"cell_type":"markdown","metadata":{},"source":["**F1 Score**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["F1 = f1_score(y_truebin, y_predbin, labels=0) # F1 Score"]},{"cell_type":"markdown","metadata":{},"source":["**Matthews Correlation Coefficient**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MCC = matthews_corrcoef(y_truebin, y_predbin) # Matthews Correlation Coefficient"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["t = PrettyTable(['Metric', 'Performance'])\n","t.add_row(['True Positive Rate', round(TPR,4)])\n","t.add_row(['Accuracy', round(ACC,4)])\n","t.add_row(['F1 Score', round(F1,4)])\n","t.add_row(['Matthews Correlation Coefficient', round(MCC,4)])\n","t.header = True\n","t.align = \"l\"\n","t.title = \"Performance of GAN\"\n","print(t)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Saving PrettyTable\n","table = t.get_string()\n","\n","if cenv == 0:\n","    with open('bin_performance_table.txt', 'w') as f:\n","        f.write(table)\n","if cenv == 1:\n","    with open(f'{new_dir}/bin_performance_table.txt', 'w') as f:\n","        f.write(table)"]},{"cell_type":"markdown","metadata":{},"source":["**Generate new digits and perform classification on them using our model**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["noi = tf.random.normal([1, 64])\n","sample = checkpoint.generator(noi, training=False)\n","fig = plt.figure()\n","plt.imshow(sample[0, :, :, 0], cmap='gray')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_sample = sample[0, :, :, 0].numpy().reshape(1,ih,iw,chnum)\n","new_prediction = classification_model.predict(new_sample)\n","\n","# get probability distribution and classification of the test digit\n","print(new_prediction)\n","print('prediction:', np.argmax(new_prediction))\n","\n","# draw the barplot\n","plt.figure()\n","plt.bar(np.arange(0,11).astype('str'), new_prediction[0,:])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# we can save the numpy array of appropriately generated digits as .npy file,\n","# which could be used for further training\n","if cenv == 0:\n","    np.save('generated_numpy.npy', sample[0, :, :, 0].numpy())\n","if cenv == 1:\n","    np.save(f'{new_dir}/generated_numpy.npy', sample[0, :, :, 0].numpy())\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
