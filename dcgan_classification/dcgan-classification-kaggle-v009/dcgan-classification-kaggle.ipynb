{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Deep Convolutional Generative Adversarial Network - Classification (2of2)","metadata":{}},{"cell_type":"markdown","source":"**Notes about this specific notebook**\n\nUses grayscale, 64x64 images, with LeakyReLU activation (excl. LeakyReLU in the classification_model dense layer)\n\nShould use exact same layers as DCGAN model. \n\nBased on dcgan_v001","metadata":{}},{"cell_type":"markdown","source":"# Change\n\nImage height, image width, color channel, ksize and ssize should align with GAN.\n\nJust like the generator and discriminator should be identical to the one in GAN","metadata":{}},{"cell_type":"markdown","source":"----------------------------------------------------------------------","metadata":{}},{"cell_type":"code","source":"# Image size (height x width)\nih = 64\niw = 64\n\n# Grayscale or RGB\nch = 'grayscale'\n\n# Batch size \nbatch_size = 40000\n\n# Layer adapt\nksize = 4 # Kernel size : was '4' for 64x64 image\nssize = 2 # Stride size : was '2' for 64x64 image\n\n# Size of test set (in %)\ntestsize = 0.3\n\n# Number of epochs in untrainable model\nepoch_unt = 7\n\n# Number of epochs in trainable model\nepoch_t = 8\n\n# Where computation is performed: Kaggle (0) or Local (1)\ncenv = 0","metadata":{"execution":{"iopub.status.busy":"2022-03-25T08:57:38.134413Z","iopub.execute_input":"2022-03-25T08:57:38.134744Z","iopub.status.idle":"2022-03-25T08:57:38.160849Z","shell.execute_reply.started":"2022-03-25T08:57:38.134659Z","shell.execute_reply":"2022-03-25T08:57:38.160101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-----","metadata":{}},{"cell_type":"code","source":"if cenv == 0:\n    print(\"Computation environment: Kaggle\")\nif cenv == 1:\n    print(\"Computation environment: Local\")","metadata":{"execution":{"iopub.status.busy":"2022-03-25T08:57:38.162661Z","iopub.execute_input":"2022-03-25T08:57:38.162954Z","iopub.status.idle":"2022-03-25T08:57:38.167597Z","shell.execute_reply.started":"2022-03-25T08:57:38.162916Z","shell.execute_reply":"2022-03-25T08:57:38.166715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Import required packages**","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential, layers\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LeakyReLU\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-03-25T08:57:38.16919Z","iopub.execute_input":"2022-03-25T08:57:38.169466Z","iopub.status.idle":"2022-03-25T08:57:44.013135Z","shell.execute_reply.started":"2022-03-25T08:57:38.169433Z","shell.execute_reply":"2022-03-25T08:57:44.012342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport os\nimport PIL\nimport time\nfrom IPython import display","metadata":{"execution":{"iopub.status.busy":"2022-03-25T08:57:44.017081Z","iopub.execute_input":"2022-03-25T08:57:44.017283Z","iopub.status.idle":"2022-03-25T08:57:44.020702Z","shell.execute_reply.started":"2022-03-25T08:57:44.017259Z","shell.execute_reply":"2022-03-25T08:57:44.020025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Automatic parameter changes","metadata":{}},{"cell_type":"code","source":"im_si = (ih, iw)\n\nif(ch == 'rgb'):\n    chnum = 3\nelif(ch == 'grayscale'):\n    chnum = 1","metadata":{"execution":{"iopub.status.busy":"2022-03-25T08:57:44.023028Z","iopub.execute_input":"2022-03-25T08:57:44.023436Z","iopub.status.idle":"2022-03-25T08:57:44.040739Z","shell.execute_reply.started":"2022-03-25T08:57:44.023398Z","shell.execute_reply":"2022-03-25T08:57:44.039984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create new directory for saving output files","metadata":{}},{"cell_type":"code","source":"if cenv == 1:\n    file_exists = []\n    vnum = 1\n    dir = \"C:/Users/Max/Documents/GitHub/dcgan_classification\"\n    for files in os.listdir(dir):\n        if \"dcgan-classification\" in files: \n            try:\n                vnum = max(vnum, int(files[-3:]))\n            except: \n                continue\n            new_vnum = vnum + 1\n            file_exists.append(True)\n        else: \n            file_exists.append(False)\n    # If this is the first notebook you want to save, a new folder will be created with version #001\n    if sum(file_exists) == 0:\n        new_vnum = 1\n        print(\"No matches found\")\n\n    else: \n        print(f\"{sum(file_exists)} matches(es) found\")\n        print(\"--------------\")\n\n    # Print new folder name\n    print(f\"New folder name: dcgan-classification-local-v{new_vnum:03}\")\n    print(\"--------------\")\n    \n    # Create new folder with the name of the notebook and the version number\n    new_dir = f\"/Users/Max/Documents/GitHub/dcgan_classification/dcgan-classification-local-v{new_vnum:03}\"\n    os.makedirs(new_dir)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T08:57:44.042166Z","iopub.execute_input":"2022-03-25T08:57:44.042661Z","iopub.status.idle":"2022-03-25T08:57:44.051637Z","shell.execute_reply.started":"2022-03-25T08:57:44.042607Z","shell.execute_reply":"2022-03-25T08:57:44.05092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"if cenv == 0:\n    path_root = \"/kaggle/input/thesis-data\"\n    \n    # Directory where checkpoints of DCGAN are stored\n    checkpoint_dir = \"/kaggle/input/checkpoints\" \n\nif cenv == 1:\n    path_root = \"C:/Users/Max/Documents/thesis_data\"\n    \n    # Directory where checkpoints of DCGAN are stored\n    checkpoint_dir = 'C:/Users/Max/Documents/GitHub/dcgan_kaggle_output/dcgan-kaggle-v002/checkpoints'\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-25T09:05:56.932806Z","iopub.execute_input":"2022-03-25T09:05:56.933069Z","iopub.status.idle":"2022-03-25T09:05:56.940533Z","shell.execute_reply.started":"2022-03-25T09:05:56.93304Z","shell.execute_reply":"2022-03-25T09:05:56.939803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batches = ImageDataGenerator().flow_from_directory(\n    directory  = path_root, \n    color_mode = ch, \n    target_size= (ih,iw), \n    class_mode= \"sparse\", \n    interpolation=\"bicubic\", \n    batch_size=batch_size\n)\nimgs, labels = next(batches)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-25T09:05:56.942705Z","iopub.execute_input":"2022-03-25T09:05:56.943051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batches.class_indices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = len(batches.class_indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(imgs, labels, test_size=testsize)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = batches.class_indices.keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_distribution = np.unique(labels, return_counts=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perc = (multi_distribution[1]/labels.shape[0])*100\nplt.xticks(rotation='vertical')\nplt.bar(classes,perc)\nif cenv == 0:\n    plt.savefig(\"multi_data_dist.png\", bbox_inches = 'tight')\nif cenv == 1:\n    plt.savefig(f\"{new_dir}/multi_data_dist.png\", bbox_inches = 'tight')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainsize = len(X_train)\ntestsize = len(X_test)\n\nprint(f\"Size of training data: {trainsize} | Shape of training data {X_train.shape}\")\nprint(f\"Size of training data: {testsize}  | Shape of training data {X_test.shape}\")\nprint(f\"Shape of training labels {y_train.shape}\")\nprint(f\"Shape of training labels {y_test.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_fmt(x):\n    return '{:.1f}%\\n({:.0f})'.format(x, total*x/100)\ntotal = trainsize + testsize","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.pie(\n    [trainsize, testsize], \n    labels = [\"Training\", \"Validation\"], \n    startangle=90, \n    counterclock=False, \n    autopct=my_fmt,\n    colors = ['gray', 'silver']\n)\n\nplt.title(\"Training and validation data distribution\")\n\nif cenv == 0:\n    plt.savefig(\"train_test_dist.png\", bbox_inches = 'tight')\nif cenv == 1:\n    plt.savefig(f\"{new_dir}/train_test_dist.png\", bbox_inches = 'tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing models","metadata":{}},{"cell_type":"code","source":"latent_dim = ih\nsih = ih//8\nsiw = iw//8\n\ngenerator = keras.Sequential(\n    [\n          keras.layers.InputLayer(input_shape=(latent_dim)),\n          \n          layers.Dense(sih * siw * latent_dim),\n          layers.Reshape((sih, siw, latent_dim)),\n          layers.Conv2DTranspose(latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.LeakyReLU(),\n          layers.Conv2DTranspose(2*latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.LeakyReLU(),\n          layers.Conv2DTranspose(4*latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.LeakyReLU(),\n          layers.Conv2D(chnum, kernel_size=ksize+1, padding=\"same\", activation=\"sigmoid\"),\n      ],\n    name=\"generator\",\n)\ngenerator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = keras.Sequential(\n       [\n        \n          layers.Conv2D(ih, kernel_size=ksize, strides=ssize, padding=\"same\",\n                        input_shape=(ih, iw, chnum)),\n          layers.LeakyReLU(),\n          layers.Conv2D(2*ih, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.LeakyReLU(),\n          layers.Conv2D(2*ih, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.LeakyReLU(),\n          layers.Flatten(),\n          layers.Dropout(0.2),\n          layers.Dense(1, activation=\"sigmoid\"),\n      ],\n    name=\"discriminator\",\n)\ndiscriminator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(checkpoint_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we transfer the weights of discriminator except the last layer to a new model, add a dense layer with 128 units, and add another dense layer with 10 units and softmax activation.","metadata":{}},{"cell_type":"code","source":"disc = checkpoint.discriminator\n    \nclassification_model = Sequential()\nfor i in range(len(disc.layers) - 1):\n    classification_model.add(disc.layers[i])\n\nfor layer in classification_model.layers:\n    layers.trainable = False\n\nclassification_model.add(Dense(128, activation = \"relu\"))\nclassification_model.add(Dense(num_classes, activation = \"softmax\"))\nclassification_model.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view the initialized weights and bias of the second last dense layer; weights are uniformly randomly generated \n# and biases are all zeroes by default\nclassification_model.layers[-2].weights","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = X_train.reshape((trainsize, ih,iw,chnum))\ntrain_images = train_images.astype('float32') / 255 # Was *255\ntrain_images.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = X_test.reshape((testsize, ih,iw,chnum))\ntest_images = test_images.astype('float32') / 255 # Was *255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = to_categorical(y_train)\ntest_labels = to_categorical(y_test)\n\nprint(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classification_model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\nhistory1 = classification_model.fit(train_images, train_labels, batch_size=100, epochs=epoch_unt,\n                        validation_data=(test_images, test_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unfreeze all layers \nfor layer in classification_model.layers:\n    layer.trainable = True\n\n#optimizer=classification_model.optimizer\n#optimizer.learning_rate=0.005\n    \nclassification_model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\nhistory2 = classification_model.fit(train_images, train_labels, batch_size=100, epochs=epoch_t,\n                        validation_data=(test_images, test_labels)) \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating performance","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score\nfrom prettytable import PrettyTable, MSWORD_FRIENDLY","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = history1.history['accuracy'] + history2.history['accuracy']\nval_accuracy = history1.history['val_accuracy'] + history2.history['val_accuracy']\n\nloss = history1.history['loss'] + history2.history['loss']\nval_loss = history1.history['val_loss'] + history2.history['val_loss']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate total number of epochs (the arrays above are the accuracies for every epoch, so you need the latest one)\ntotal_epochs = epoch_t + epoch_unt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = [val_loss, val_accuracy]\nprint(f\"Overall CNN Accuracy: {scores[1][total_epochs-1]}\\n(The number of correct predictions divided by the number of total predictions)\")\n# Total epochs - 1, because array starts at 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = PrettyTable(['Metric', 'Performance'])\nt.add_row(['Valididation accuracy', round(scores[1][total_epochs-1],4)])\nt.add_row(['Validation loss', round(scores[0][total_epochs-1],4)])\nt.header = True\nt.align = \"l\"\nt.title = \"Performance of multi-class classification - CNN\"\nprint(t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving PrettyTable\ntable = t.get_string()\n\nif cenv == 0:\n    with open('multi_performance_table.txt', 'w') as f:\n        f.write(table)\nif cenv == 1:\n    with open(f'{new_dir}/multi_performance_table.txt', 'w') as f:\n        f.write(table)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.plot(accuracy, label='accuracy')\nplt.plot(val_accuracy, label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.3, 1])\nplt.legend(loc='lower right')\nif cenv == 0:\n    plt.savefig(\"dcgan_class_model_acc.png\", bbox_inches = 'tight')\nif cenv == 1:\n    plt.savefig(f\"{new_dir}/dcgan_class_model_acc.png\", bbox_inches = 'tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.plot(loss, label='loss')\nplt.plot(val_loss, label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim([0, 0.5])\nplt.legend(loc='lower right')\nif cenv == 0:\n    plt.savefig(\"dcgan_class_model_loss.png\", bbox_inches = 'tight')\nif cenv == 1:\n    plt.savefig(f\"{new_dir}/dcgan_class_model_loss.png\", bbox_inches = 'tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that, using the tuned discriminator model, both training accuracy and testing are approximately 0.94 after 15 epochs.","metadata":{}},{"cell_type":"code","source":"# demonstration: predict the ith test digit\ni = np.random.randint(0, testsize)\n\n# show the actual ith digit\nprint('actual label:', np.argmax(test_labels[i]))\nplt.figure()\nplt.imshow(test_images[i,:,:,0], cmap='gray')\nplt.show()\n\n# predict\nprediction = classification_model.predict(test_images[i].reshape(1,ih,iw,chnum))\n\n# get probability distribution and classification of the test digit\nprint(prediction)\nprint(\"-----------------------------------------------------------------------\")\nprint('prediction:', np.argmax(prediction))\n\n# draw the barplot\nplt.figure()\nplt.bar(np.arange(0,11).astype('str'), prediction[0,:])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyse performance","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nimport pandas as pd\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.argmax(classification_model.predict(test_images), axis=-1)\ntrue_labels = test_labels.argmax(axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test2 = np.argmax(test_labels, axis=1)\ny_test2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_matrix = metrics.confusion_matrix(y_test2, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n   \n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    if cenv == 0:\n        plt.savefig(\"multi_class_cmatrix.png\")\n    if cenv == 1:\n        plt.savefig(f\"{new_dir}/multi_class_cmatrix.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names= batches.class_indices.keys()\nconfusion_matrix(c_matrix, class_names, figsize = (20,7), fontsize=14)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Binary classification","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score\nfrom prettytable import PrettyTable, MSWORD_FRIENDLY","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predbin = [] \ny_truebin = []\nfor count, value in enumerate(y_test2):\n    if y_test2[count] in range(10): # range(10) is 0 to 9\n        y_truebin.append(0)\n    else: y_truebin.append(1)\n    \n    if y_pred[count] in range(10):\n        y_predbin.append(0)\n    else: y_predbin.append(1)\n    \n    continue\nif len(y_truebin) == len(y_predbin):\n    print(f\"Length of the observations in test set: {len(y_truebin)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rw_count = 0\nbn_count = 0\nfor count, value in enumerate(multi_distribution[1]):\n    if count in range(10):\n        rw_count = rw_count + multi_distribution[1][count]\n    else: \n        bn_count = bn_count + multi_distribution[1][count]\nprint(f\"Ransomware Occurences: {rw_count}, Benign Occurences: {bn_count}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nx_lab = ['Ransomware', 'Benign']\ny_lab = [rw_count, bn_count]\nax.bar(x_lab, y_lab)\nif cenv == 0:\n    plt.savefig(\"data_dist.png.png\", bbox_inches = 'tight')\nif cenv == 1:\n    plt.savefig(f\"{new_dir}/bin_data_dist.png\", bbox_inches = 'tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_matrix_bin = metrics.confusion_matrix(y_truebin, y_predbin)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def confusion_matrix_bin(confusion_matrix, class_names_bin, figsize = (5,2), fontsize=7):\n   \n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names_bin, columns=class_names_bin, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    if cenv == 0:\n        plt.savefig(\"bin_class_cmatrix.png\", bbox_inches = 'tight')\n    if cenv == 1:\n        plt.savefig(f\"{new_dir}/bin_class_cmatrix.png\", bbox_inches = 'tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names_bin= (\"ransomware\", \"benign\")\nconfusion_matrix_bin(c_matrix_bin, class_names_bin, figsize = (5,2), fontsize=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**True Positive Rate**","metadata":{}},{"cell_type":"code","source":"TPR = c_matrix_bin[0,0]/(c_matrix_bin[0,0] + c_matrix_bin[0,1]) #True Positive Rate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Accuracy**","metadata":{}},{"cell_type":"code","source":"ACC = accuracy_score(y_truebin, y_predbin) # Accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**F1 Score**","metadata":{}},{"cell_type":"code","source":"F1 = f1_score(y_truebin, y_predbin, labels=0) # F1 Score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Matthews Correlation Coefficient**","metadata":{}},{"cell_type":"code","source":"MCC = matthews_corrcoef(y_truebin, y_predbin) # Matthews Correlation Coefficient","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = PrettyTable(['Metric', 'Performance'])\nt.add_row(['True Positive Rate', round(TPR,4)])\nt.add_row(['Accuracy', round(ACC,4)])\nt.add_row(['F1 Score', round(F1,4)])\nt.add_row(['Matthews Correlation Coefficient', round(MCC,4)])\nt.header = True\nt.align = \"l\"\nt.title = \"Performance of GAN\"\nprint(t)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving PrettyTable\ntable = t.get_string()\n\nif cenv == 0:\n    with open('bin_performance_table.txt', 'w') as f:\n        f.write(table)\nif cenv == 1:\n    with open(f'{new_dir}/bin_performance_table.txt', 'w') as f:\n        f.write(table)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Generate new digits and perform classification on them using our model**","metadata":{}},{"cell_type":"code","source":"noi = tf.random.normal([1, 64])\nsample = checkpoint.generator(noi, training=False)\nfig = plt.figure()\nplt.imshow(sample[0, :, :, 0], cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_sample = sample[0, :, :, 0].numpy().reshape(1,ih,iw,chnum)\nnew_prediction = classification_model.predict(new_sample)\n\n# get probability distribution and classification of the test digit\nprint(new_prediction)\nprint('prediction:', np.argmax(new_prediction))\n\n# draw the barplot\nplt.figure()\nplt.bar(np.arange(0,11).astype('str'), new_prediction[0,:])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can save the numpy array of appropriately generated digits as .npy file,\n# which could be used for further training\nif cenv == 0:\n    np.save('generated_numpy.npy', sample[0, :, :, 0].numpy())\nif cenv == 1:\n    np.save(f'{new_dir}/generated_numpy.npy', sample[0, :, :, 0].numpy())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}