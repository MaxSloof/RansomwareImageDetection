{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Network - Classification (2of2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes about this specific notebook**\n",
    "\n",
    "Uses grayscale, 64x64 images, with LeakyReLU activation (even LeakyReLU in the classification_model dense layer)\n",
    "\n",
    "Should use exact same layers as DCGAN model. \n",
    "\n",
    "Based on dcgan_v001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change\n",
    "\n",
    "Image height, image width, color channel, ksize and ssize should align with GAN.\n",
    "\n",
    "Just like the generator and discriminator should be identical to the one in GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size (height x width)\n",
    "ih = 64\n",
    "iw = 64\n",
    "\n",
    "# Grayscale or RGB\n",
    "ch = 'grayscale'\n",
    "\n",
    "# Batch size \n",
    "batch_size = 40000\n",
    "\n",
    "# Layer adapt\n",
    "ksize = 4 # Kernel size : was '4' for 64x64 image\n",
    "ssize = 2 # Stride size : was '2' for 64x64 image\n",
    "\n",
    "# Size of test set (in %)\n",
    "testsize = 0.3\n",
    "\n",
    "# Number of epochs in untrainable model\n",
    "epoch_unt = 7\n",
    "\n",
    "# Number of epochs in trainable model\n",
    "epoch_t = 8\n",
    "\n",
    "# Where computation is performed: Kaggle (0) or Local (1)\n",
    "cenv = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation environment: Local\n"
     ]
    }
   ],
   "source": [
    "if cenv == 0:\n",
    "    print(\"Computation environment: Kaggle\")\n",
    "if cenv == 1:\n",
    "    print(\"Computation environment: Local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import PIL\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic parameter changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_si = (ih, iw)\n",
    "\n",
    "if(ch == 'rgb'):\n",
    "    chnum = 3\n",
    "elif(ch == 'grayscale'):\n",
    "    chnum = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new directory for saving output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 matches(es) found\n",
      "--------------\n",
      "New folder name: dcgan-classification-local-v008\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "if cenv == 1:\n",
    "    file_exists = []\n",
    "    vnum = 1\n",
    "    dir = \"C:/Users/Max/Documents/GitHub/dcgan_classification\"\n",
    "    for files in os.listdir(dir):\n",
    "        if \"dcgan-classification\" in files: \n",
    "            try:\n",
    "                vnum = max(vnum, int(files[-3:]))\n",
    "            except: \n",
    "                continue\n",
    "            new_vnum = vnum + 1\n",
    "            file_exists.append(True)\n",
    "        else: \n",
    "            file_exists.append(False)\n",
    "    # If this is the first notebook you want to save, a new folder will be created with version #001\n",
    "    if sum(file_exists) == 0:\n",
    "        new_vnum = 1\n",
    "        print(\"No matches found\")\n",
    "\n",
    "    else: \n",
    "        print(f\"{sum(file_exists)} matches(es) found\")\n",
    "        print(\"--------------\")\n",
    "\n",
    "    # Print new folder name\n",
    "    print(f\"New folder name: dcgan-classification-local-v{new_vnum:03}\")\n",
    "    print(\"--------------\")\n",
    "    \n",
    "    # Create new folder with the name of the notebook and the version number\n",
    "    new_dir = f\"/Users/Max/Documents/GitHub/dcgan_classification/dcgan-classification-local-v{new_vnum:03}\"\n",
    "    os.makedirs(new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cenv == 0:\n",
    "    path_root = \"/kaggle/input/thesis-data\"\n",
    "    \n",
    "    # Directory where checkpoints of DCGAN are stored\n",
    "    checkpoint_dir = \"/kaggle/input/checkpoints\" \n",
    "\n",
    "if cenv == 1:\n",
    "    path_root = \"C:/Users/Max/Documents/thesis_data\"\n",
    "    \n",
    "    # Directory where checkpoints of DCGAN are stored\n",
    "    checkpoint_dir = 'C:/Users/Max/Documents/GitHub/dcgan_kaggle_output/dcgan-kaggle-v002/checkpoints'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26548 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = ImageDataGenerator().flow_from_directory(\n",
    "    directory  = path_root, \n",
    "    color_mode = ch, \n",
    "    target_size= (ih,iw), \n",
    "    class_mode= \"sparse\", \n",
    "    interpolation=\"bicubic\", \n",
    "    batch_size=batch_size\n",
    ")\n",
    "imgs, labels = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26548, 64, 64, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BetterSurf': 0,\n",
       " 'Eksor.A': 1,\n",
       " 'Obfuscator.AFQ': 2,\n",
       " 'Occamy.C': 3,\n",
       " 'OnLineGames.CTB': 4,\n",
       " 'Reveton.A': 5,\n",
       " 'Sfone': 6,\n",
       " 'VB.IL': 7,\n",
       " 'Zbot': 8,\n",
       " 'Zbot!CI': 9,\n",
       " 'benign': 10}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(imgs, labels, test_size=testsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = batches.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_distribution = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perc = (multi_distribution[1]/labels.shape[0])*100\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.bar(classes,perc)\n",
    "if cenv == 0:\n",
    "    plt.savefig(\"multi_data_dist.png\", bbox_inches = 'tight')\n",
    "if cenv == 1:\n",
    "    plt.savefig(f\"{new_dir}/multi_data_dist.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data: 18583 | Shape of training data (18583, 64, 64, 1)\n",
      "Size of training data: 7965  | Shape of training data (7965, 64, 64, 1)\n",
      "Shape of training labels (18583,)\n",
      "Shape of training labels (7965,)\n"
     ]
    }
   ],
   "source": [
    "trainsize = len(X_train)\n",
    "testsize = len(X_test)\n",
    "\n",
    "print(f\"Size of training data: {trainsize} | Shape of training data {X_train.shape}\")\n",
    "print(f\"Size of training data: {testsize}  | Shape of training data {X_test.shape}\")\n",
    "print(f\"Shape of training labels {y_train.shape}\")\n",
    "print(f\"Shape of training labels {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fmt(x):\n",
    "    return '{:.1f}%\\n({:.0f})'.format(x, total*x/100)\n",
    "total = trainsize + testsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(\n",
    "    [trainsize, testsize], \n",
    "    labels = [\"Training\", \"Validation\"], \n",
    "    startangle=90, \n",
    "    counterclock=False, \n",
    "    autopct=my_fmt,\n",
    "    colors = ['gray', 'silver']\n",
    ")\n",
    "\n",
    "plt.title(\"Training and validation data distribution\")\n",
    "\n",
    "if cenv == 0:\n",
    "    plt.savefig(\"train_test_dist.png\", bbox_inches = 'tight')\n",
    "if cenv == 1:\n",
    "    plt.savefig(f\"{new_dir}/train_test_dist.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4096)              266240    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 16, 16, 64)        65600     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 128)       131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 1)         6401      \n",
      "=================================================================\n",
      "Total params: 993,985\n",
      "Trainable params: 993,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = ih\n",
    "sih = ih//8\n",
    "siw = iw//8\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "          keras.layers.InputLayer(input_shape=(latent_dim)),\n",
    "          \n",
    "          layers.Dense(sih * siw * latent_dim),\n",
    "          layers.Reshape((sih, siw, latent_dim)),\n",
    "          layers.Conv2DTranspose(latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n",
    "          layers.LeakyReLU(),\n",
    "          layers.Conv2DTranspose(2*latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n",
    "          layers.LeakyReLU(),\n",
    "          layers.Conv2DTranspose(4*latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n",
    "          layers.LeakyReLU(),\n",
    "          layers.Conv2D(chnum, kernel_size=ksize+1, padding=\"same\", activation=\"sigmoid\"),\n",
    "      ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1088      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 402,753\n",
      "Trainable params: 402,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "       [\n",
    "        \n",
    "          layers.Conv2D(ih, kernel_size=ksize, strides=ssize, padding=\"same\",\n",
    "                        input_shape=(ih, iw, chnum)),\n",
    "          layers.LeakyReLU(),\n",
    "          layers.Conv2D(2*ih, kernel_size=ksize, strides=ssize, padding=\"same\"),\n",
    "          layers.LeakyReLU(),\n",
    "          layers.Conv2D(2*ih, kernel_size=ksize, strides=ssize, padding=\"same\"),\n",
    "          layers.LeakyReLU(),\n",
    "          layers.Flatten(),\n",
    "          layers.Dropout(0.2),\n",
    "          layers.Dense(1, activation=\"sigmoid\"),\n",
    "      ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x27666f93310>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we transfer the weights of discriminator except the last layer to a new model, add a dense layer with 128 units, and add another dense layer with 10 units and softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1088      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 1,444,683\n",
      "Trainable params: 1,444,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc = checkpoint.discriminator\n",
    "    \n",
    "classification_model = Sequential()\n",
    "for i in range(len(disc.layers) - 1):\n",
    "    classification_model.add(disc.layers[i])\n",
    "\n",
    "for layer in classification_model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "classification_model.add(Dense(128, activation = \"LeakyReLU\"))\n",
    "classification_model.add(Dense(num_classes, activation = \"softmax\"))\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(8192, 128) dtype=float32, numpy=\n",
       " array([[-0.00083547, -0.01755949, -0.00386753, ...,  0.01122919,\n",
       "          0.00299057,  0.0028266 ],\n",
       "        [ 0.01229178,  0.00483669, -0.02301973, ..., -0.01830362,\n",
       "          0.02439567,  0.00271776],\n",
       "        [ 0.00239809,  0.01892054, -0.01271315, ..., -0.00365248,\n",
       "          0.02100273,  0.02081521],\n",
       "        ...,\n",
       "        [-0.01916109, -0.02302619, -0.02445935, ...,  0.01522492,\n",
       "          0.01239372, -0.01855864],\n",
       "        [ 0.00925873, -0.01515567, -0.00258505, ..., -0.02590022,\n",
       "          0.02415059, -0.01385542],\n",
       "        [-0.00264557,  0.00161272, -0.00739397, ...,  0.00841582,\n",
       "          0.01702542,  0.00356407]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the initialized weights and bias of the second last dense layer; weights are uniformly randomly generated \n",
    "# and biases are all zeroes by default\n",
    "classification_model.layers[-2].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18583, 64, 64, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = X_train.reshape((trainsize, ih,iw,chnum))\n",
    "train_images = train_images.astype('float32') / 255 # Was *255\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = X_test.reshape((testsize, ih,iw,chnum))\n",
    "test_images = test_images.astype('float32') / 255 # Was *255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18583, 64, 64, 1) (18583, 11) (7965, 64, 64, 1) (7965, 11)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(y_train)\n",
    "test_labels = to_categorical(y_test)\n",
    "\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "186/186 [==============================] - 11s 22ms/step - loss: 0.4973 - accuracy: 0.8600 - val_loss: 0.2811 - val_accuracy: 0.9207\n",
      "Epoch 2/7\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.2426 - accuracy: 0.9286 - val_loss: 0.2387 - val_accuracy: 0.9296\n",
      "Epoch 3/7\n",
      "186/186 [==============================] - 3s 19ms/step - loss: 0.1956 - accuracy: 0.9401 - val_loss: 0.1961 - val_accuracy: 0.9444\n",
      "Epoch 4/7\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.1557 - accuracy: 0.9526 - val_loss: 0.1931 - val_accuracy: 0.9436\n",
      "Epoch 5/7\n",
      " 53/186 [=======>......................] - ETA: 1s - loss: 0.1273 - accuracy: 0.9555"
     ]
    }
   ],
   "source": [
    "classification_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history1 = classification_model.fit(train_images, train_labels, batch_size=100, epochs=epoch_unt,\n",
    "                        validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze all layers \n",
    "for layer in classification_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "#optimizer=classification_model.optimizer\n",
    "#optimizer.learning_rate=0.005\n",
    "    \n",
    "classification_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history2 = classification_model.fit(train_images, train_labels, batch_size=100, epochs=epoch_t,\n",
    "                        validation_data=(test_images, test_labels)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score\n",
    "from prettytable import PrettyTable, MSWORD_FRIENDLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history1.history['accuracy'] + history2.history['accuracy']\n",
    "val_accuracy = history1.history['val_accuracy'] + history2.history['val_accuracy']\n",
    "\n",
    "loss = history1.history['loss'] + history2.history['loss']\n",
    "val_loss = history1.history['val_loss'] + history2.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of epochs (the arrays above are the accuracies for every epoch, so you need the latest one)\n",
    "total_epochs = epoch_t + epoch_unt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [val_loss, val_accuracy]\n",
    "print(f\"Overall CNN Accuracy: {scores[1][total_epochs-1]}\\n(The number of correct predictions divided by the number of total predictions)\")\n",
    "# Total epochs - 1, because array starts at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = PrettyTable(['Metric', 'Performance'])\n",
    "t.add_row(['Valididation accuracy', round(scores[1][total_epochs-1],4)])\n",
    "t.add_row(['Validation loss', round(scores[0][total_epochs-1],4)])\n",
    "t.header = True\n",
    "t.align = \"l\"\n",
    "t.title = \"Performance of multi-class classification - CNN\"\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving PrettyTable\n",
    "table = t.get_string()\n",
    "\n",
    "if cenv == 0:\n",
    "    with open('multi_performance_table.txt', 'w') as f:\n",
    "        f.write(table)\n",
    "if cenv == 1:\n",
    "    with open(f'{new_dir}/multi_performance_table.txt', 'w') as f:\n",
    "        f.write(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(accuracy, label='accuracy')\n",
    "plt.plot(val_accuracy, label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.3, 1])\n",
    "plt.legend(loc='lower right')\n",
    "if cenv == 0:\n",
    "    plt.savefig(\"dcgan_class_model_acc.png\", bbox_inches = 'tight')\n",
    "if cenv == 1:\n",
    "    plt.savefig(f\"{new_dir}/dcgan_class_model_acc.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.legend(loc='lower right')\n",
    "if cenv == 0:\n",
    "    plt.savefig(\"dcgan_class_model_loss.png\", bbox_inches = 'tight')\n",
    "if cenv == 1:\n",
    "    plt.savefig(f\"{new_dir}/dcgan_class_model_loss.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, using the tuned discriminator model, both training accuracy and testing are approximately 0.94 after 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration: predict the ith test digit\n",
    "i = np.random.randint(0, testsize)\n",
    "\n",
    "# show the actual ith digit\n",
    "print('actual label:', np.argmax(test_labels[i]))\n",
    "plt.figure()\n",
    "plt.imshow(test_images[i,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# predict\n",
    "prediction = classification_model.predict(test_images[i].reshape(1,ih,iw,chnum))\n",
    "\n",
    "# get probability distribution and classification of the test digit\n",
    "print(prediction)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "print('prediction:', np.argmax(prediction))\n",
    "\n",
    "# draw the barplot\n",
    "plt.figure()\n",
    "plt.bar(np.arange(0,11).astype('str'), prediction[0,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(classification_model.predict(test_images), axis=-1)\n",
    "true_labels = test_labels.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = np.argmax(test_labels, axis=1)\n",
    "y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = metrics.confusion_matrix(y_test2, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "   \n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    if cenv == 0:\n",
    "        plt.savefig(\"multi_class_cmatrix.png\")\n",
    "    if cenv == 1:\n",
    "        plt.savefig(f\"{new_dir}/multi_class_cmatrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names= batches.class_indices.keys()\n",
    "confusion_matrix(c_matrix, class_names, figsize = (20,7), fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score\n",
    "from prettytable import PrettyTable, MSWORD_FRIENDLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predbin = [] \n",
    "y_truebin = []\n",
    "for count, value in enumerate(y_test2):\n",
    "    if y_test2[count] in range(10): # range(10) is 0 to 9\n",
    "        y_truebin.append(0)\n",
    "    else: y_truebin.append(1)\n",
    "    \n",
    "    if y_pred[count] in range(10):\n",
    "        y_predbin.append(0)\n",
    "    else: y_predbin.append(1)\n",
    "    \n",
    "    continue\n",
    "if len(y_truebin) == len(y_predbin):\n",
    "    print(f\"Length of the observations in test set: {len(y_truebin)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_count = 0\n",
    "bn_count = 0\n",
    "for count, value in enumerate(multi_distribution[1]):\n",
    "    if count in range(10):\n",
    "        rw_count = rw_count + multi_distribution[1][count]\n",
    "    else: \n",
    "        bn_count = bn_count + multi_distribution[1][count]\n",
    "print(f\"Ransomware Occurences: {rw_count}, Benign Occurences: {bn_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "x_lab = ['Ransomware', 'Benign']\n",
    "y_lab = [rw_count, bn_count]\n",
    "ax.bar(x_lab, y_lab)\n",
    "if cenv == 0:\n",
    "    plt.savefig(\"data_dist.png.png\", bbox_inches = 'tight')\n",
    "if cenv == 1:\n",
    "    plt.savefig(f\"{new_dir}/bin_data_dist.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix_bin = metrics.confusion_matrix(y_truebin, y_predbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_bin(confusion_matrix, class_names_bin, figsize = (5,2), fontsize=7):\n",
    "   \n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names_bin, columns=class_names_bin, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if cenv == 0:\n",
    "        plt.savefig(\"bin_class_cmatrix.png\", bbox_inches = 'tight')\n",
    "    if cenv == 1:\n",
    "        plt.savefig(f\"{new_dir}/bin_class_cmatrix.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_bin= (\"ransomware\", \"benign\")\n",
    "confusion_matrix_bin(c_matrix_bin, class_names_bin, figsize = (5,2), fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**True Positive Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR = c_matrix_bin[0,0]/(c_matrix_bin[0,0] + c_matrix_bin[0,1]) #True Positive Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC = accuracy_score(y_truebin, y_predbin) # Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = f1_score(y_truebin, y_predbin, labels=0) # F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matthews Correlation Coefficient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCC = matthews_corrcoef(y_truebin, y_predbin) # Matthews Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = PrettyTable(['Metric', 'Performance'])\n",
    "t.add_row(['True Positive Rate', round(TPR,4)])\n",
    "t.add_row(['Accuracy', round(ACC,4)])\n",
    "t.add_row(['F1 Score', round(F1,4)])\n",
    "t.add_row(['Matthews Correlation Coefficient', round(MCC,4)])\n",
    "t.header = True\n",
    "t.align = \"l\"\n",
    "t.title = \"Performance of GAN\"\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving PrettyTable\n",
    "table = t.get_string()\n",
    "\n",
    "if cenv == 0:\n",
    "    with open('bin_performance_table.txt', 'w') as f:\n",
    "        f.write(table)\n",
    "if cenv == 1:\n",
    "    with open(f'{new_dir}/bin_performance_table.txt', 'w') as f:\n",
    "        f.write(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate new digits and perform classification on them using our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noi = tf.random.normal([1, 64])\n",
    "sample = checkpoint.generator(noi, training=False)\n",
    "fig = plt.figure()\n",
    "plt.imshow(sample[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample = sample[0, :, :, 0].numpy().reshape(1,ih,iw,chnum)\n",
    "new_prediction = classification_model.predict(new_sample)\n",
    "\n",
    "# get probability distribution and classification of the test digit\n",
    "print(new_prediction)\n",
    "print('prediction:', np.argmax(new_prediction))\n",
    "\n",
    "# draw the barplot\n",
    "plt.figure()\n",
    "plt.bar(np.arange(0,11).astype('str'), new_prediction[0,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save the numpy array of appropriately generated digits as .npy file,\n",
    "# which could be used for further training\n",
    "if cenv == 0:\n",
    "    np.save('generated_numpy.npy', sample[0, :, :, 0].numpy())\n",
    "if cenv == 1:\n",
    "    np.save(f'{new_dir}/generated_numpy.npy', sample[0, :, :, 0].numpy())\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw-celnotatie",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
