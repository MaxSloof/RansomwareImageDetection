{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Conditional GAN\n\nUsed to generate new training data for the ransomware families to overcome the skewed distribution of training data towards the benign samples","metadata":{}},{"cell_type":"code","source":"# Packages\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\n\nimport matplotlib.pyplot as plt \nimport tensorflow as tf\nimport numpy as np\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:53.581852Z","iopub.execute_input":"2022-03-31T13:33:53.584565Z","iopub.status.idle":"2022-03-31T13:33:53.598245Z","shell.execute_reply.started":"2022-03-31T13:33:53.584425Z","shell.execute_reply":"2022-03-31T13:33:53.59742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Change parameters**","metadata":{}},{"cell_type":"markdown","source":"-----","metadata":{}},{"cell_type":"code","source":"# Batch size\nbatch_size = 64\n\n# Color mode\nch = 'grayscale'\n\n# Image size\niw, ih = 64,64\nim_size = (iw,ih)\n\n# Latent dim size\nlatent_dim = 128\n\n# Number of Epochs\nepoch_t = 20\n\n# Computation environment: Kaggle (0) or Local (1)\ncenv = 0\n\n# If weights are used: Weight factor\nwf = 0.5","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:53.600653Z","iopub.execute_input":"2022-03-31T13:33:53.60172Z","iopub.status.idle":"2022-03-31T13:33:53.612717Z","shell.execute_reply.started":"2022-03-31T13:33:53.601673Z","shell.execute_reply":"2022-03-31T13:33:53.611984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-----------","metadata":{}},{"cell_type":"markdown","source":"Automatic notebook preparation","metadata":{}},{"cell_type":"code","source":"if(ch == 'rgb'):\n    chnum = 3\nelif(ch == 'grayscale'):\n    chnum = 1","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:53.61399Z","iopub.execute_input":"2022-03-31T13:33:53.614579Z","iopub.status.idle":"2022-03-31T13:33:53.625365Z","shell.execute_reply.started":"2022-03-31T13:33:53.614533Z","shell.execute_reply":"2022-03-31T13:33:53.624699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cenv == 1:\n    file_exists = []\n    vnum = 1\n    dir = \"C:/Users/Max/Documents/GitHub/conditional_gan\"\n    for files in os.listdir(dir):\n        if \"cgan\" in files:\n            try:\n                vnum = max(vnum, int(files[-3:]))\n            except: \n                continue\n            new_vnum = vnum + 1\n            file_exists.append(True)\n        else: \n            file_exists.append(False)\n    # If this is the first notebook you want to save, a new folder will be created with version #001\n    if sum(file_exists) == 0:\n        new_vnum = 1\n        print(\"No matches found\")\n\n    else: \n        print(f\"{sum(file_exists)} matches(es) found\")\n        print(\"--------------\")\n\n    # Print new folder name\n    print(f\"New folder name: cgan-local-v{new_vnum:03}\")\n    print(\"--------------\")\n    \n    # Create new folder with the name of the notebook and the version number\n    new_dir = f\"C://Users/Max/Documents/GitHub/conditional_gan/cgan-local-v{new_vnum:03}\"\n    os.makedirs(new_dir)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:53.627028Z","iopub.execute_input":"2022-03-31T13:33:53.627466Z","iopub.status.idle":"2022-03-31T13:33:53.641594Z","shell.execute_reply.started":"2022-03-31T13:33:53.627425Z","shell.execute_reply":"2022-03-31T13:33:53.640665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data preprocessing**","metadata":{}},{"cell_type":"code","source":"if cenv == 0:\n    path_root = \"/kaggle/input/data-wo-benign/data_wo_benign\"\n    path_save_imgs = \"/kaggle/working/cgan-images/\"\nif cenv == 1:\n    path_root = \"C:/Users/Max/Documents/image_data/data_wo_benign\"\n    path_save_imgs = f\"C:/Users/Max/Documents/image_data/cgan-local-v{new_vnum:03}\"","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:53.64344Z","iopub.execute_input":"2022-03-31T13:33:53.644092Z","iopub.status.idle":"2022-03-31T13:33:53.656955Z","shell.execute_reply.started":"2022-03-31T13:33:53.644046Z","shell.execute_reply":"2022-03-31T13:33:53.655917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rescale = 1/255)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:53.658806Z","iopub.execute_input":"2022-03-31T13:33:53.659366Z","iopub.status.idle":"2022-03-31T13:33:53.67063Z","shell.execute_reply.started":"2022-03-31T13:33:53.659322Z","shell.execute_reply":"2022-03-31T13:33:53.670003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prelim_dataset = datagen.flow_from_directory(\n    directory = path_root,\n    color_mode = ch,\n    target_size = im_size,\n    interpolation = 'bicubic',\n    batch_size = 40000,\n    shuffle=False\n)\nimgs, labels = next(prelim_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:34:01.806889Z","iopub.execute_input":"2022-03-31T13:34:01.807203Z","iopub.status.idle":"2022-03-31T13:34:36.741942Z","shell.execute_reply.started":"2022-03-31T13:34:01.807175Z","shell.execute_reply":"2022-03-31T13:34:36.741109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_samples = prelim_dataset.samples\nnum_classes = max(prelim_dataset.labels) + 1","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:34:36.744094Z","iopub.execute_input":"2022-03-31T13:34:36.744401Z","iopub.status.idle":"2022-03-31T13:34:36.75117Z","shell.execute_reply.started":"2022-03-31T13:34:36.744362Z","shell.execute_reply":"2022-03-31T13:34:36.750207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prelim_dataset.class_indices","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-31T13:34:36.752546Z","iopub.execute_input":"2022-03-31T13:34:36.753397Z","iopub.status.idle":"2022-03-31T13:34:36.768349Z","shell.execute_reply.started":"2022-03-31T13:34:36.753353Z","shell.execute_reply":"2022-03-31T13:34:36.767494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create tf.data.Dataset","metadata":{}},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((imgs, labels))\ndataset = dataset.shuffle(buffer_size=1024).batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:34:59.520007Z","iopub.execute_input":"2022-03-31T13:34:59.520563Z","iopub.status.idle":"2022-03-31T13:34:59.752838Z","shell.execute_reply.started":"2022-03-31T13:34:59.520527Z","shell.execute_reply":"2022-03-31T13:34:59.752124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculate number of input channel for Gen and Disc","metadata":{}},{"cell_type":"code","source":"generator_in_channels = latent_dim + num_classes\ndiscriminator_in_channels = chnum + num_classes\nprint(generator_in_channels, discriminator_in_channels)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.113945Z","iopub.status.idle":"2022-03-31T13:33:56.114275Z","shell.execute_reply.started":"2022-03-31T13:33:56.114102Z","shell.execute_reply":"2022-03-31T13:33:56.114124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating discriminator and generator","metadata":{}},{"cell_type":"code","source":"# Create the discriminator.\ndiscriminator = keras.Sequential(\n    [\n        keras.layers.InputLayer((iw, ih, discriminator_in_channels)),\n        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.GlobalMaxPooling2D(),\n        layers.Dense(1),\n    ],\n    name=\"discriminator\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.115438Z","iopub.status.idle":"2022-03-31T13:33:56.115756Z","shell.execute_reply.started":"2022-03-31T13:33:56.115585Z","shell.execute_reply":"2022-03-31T13:33:56.115607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the generator.\ngenerator = keras.Sequential(\n    [\n        keras.layers.InputLayer((generator_in_channels,)),\n        # We want to generate 128 + num_classes coefficients to reshape into a\n        # 7x7x(128 + num_classes) map.\n        layers.Dense(8 * 8 * generator_in_channels),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Reshape((8, 8, generator_in_channels)),\n        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n    ],\n    name=\"generator\",\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.117582Z","iopub.status.idle":"2022-03-31T13:33:56.117908Z","shell.execute_reply.started":"2022-03-31T13:33:56.11774Z","shell.execute_reply":"2022-03-31T13:33:56.117756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.119138Z","iopub.status.idle":"2022-03-31T13:33:56.119438Z","shell.execute_reply.started":"2022-03-31T13:33:56.11928Z","shell.execute_reply":"2022-03-31T13:33:56.119296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.120955Z","iopub.status.idle":"2022-03-31T13:33:56.12125Z","shell.execute_reply.started":"2022-03-31T13:33:56.121096Z","shell.execute_reply":"2022-03-31T13:33:56.121112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create Conditional GAN**","metadata":{}},{"cell_type":"code","source":"class ConditionalGAN(keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(ConditionalGAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n\n    @property\n    def metrics(self):\n        return [self.gen_loss_tracker, self.disc_loss_tracker]\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(ConditionalGAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n\n    def train_step(self, data):\n        # Unpack the data.\n        real_images, one_hot_labels = data\n\n        # Add dummy dimensions to the labels so that they can be concatenated with\n        # the images. This is for the discriminator.\n        image_one_hot_labels = one_hot_labels[:, :, None, None]\n        image_one_hot_labels = tf.repeat(\n            image_one_hot_labels, repeats=[ih * iw]\n        )\n        image_one_hot_labels = tf.reshape(\n            image_one_hot_labels, (-1, iw, ih, num_classes)\n        )\n\n        # Sample random points in the latent space and concatenate the labels.\n        # This is for the generator.\n        batch_size = tf.shape(real_images)[0]\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n        random_vector_labels = tf.concat(\n            [random_latent_vectors, one_hot_labels], axis=1\n        )\n\n        # Decode the noise (guided by labels) to fake images.\n        generated_images = self.generator(random_vector_labels)\n\n        # Combine them with real images. Note that we are concatenating the labels\n        # with these images here.\n        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n        combined_images = tf.concat(\n            [fake_image_and_labels, real_image_and_labels], axis=0\n        )\n\n        # Assemble labels discriminating real from fake images.\n        labels = tf.concat(\n            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n        )\n\n        # Train the discriminator.\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(\n            zip(grads, self.discriminator.trainable_weights)\n        )\n\n        # Sample random points in the latent space.\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n        random_vector_labels = tf.concat(\n            [random_latent_vectors, one_hot_labels], axis=1\n        )\n\n        # Assemble labels that say \"all real images\".\n        misleading_labels = tf.zeros((batch_size, 1))\n\n        # Train the generator (note that we should *not* update the weights\n        # of the discriminator)!\n        with tf.GradientTape() as tape:\n            fake_images = self.generator(random_vector_labels)\n            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n            predictions = self.discriminator(fake_image_and_labels)\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        # Monitor loss.\n        self.gen_loss_tracker.update_state(g_loss)\n        self.disc_loss_tracker.update_state(d_loss)\n        return {\n            \"g_loss\": self.gen_loss_tracker.result(),\n            \"d_loss\": self.disc_loss_tracker.result(),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.122849Z","iopub.status.idle":"2022-03-31T13:33:56.123342Z","shell.execute_reply.started":"2022-03-31T13:33:56.123086Z","shell.execute_reply":"2022-03-31T13:33:56.123111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Optimizers**","metadata":{}},{"cell_type":"code","source":"# Define optimizers\nd_optimizer=keras.optimizers.Adam(learning_rate=0.0003)\ng_optimizer=keras.optimizers.Adam(learning_rate=0.0003)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.125124Z","iopub.status.idle":"2022-03-31T13:33:56.12575Z","shell.execute_reply.started":"2022-03-31T13:33:56.125463Z","shell.execute_reply":"2022-03-31T13:33:56.125491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Checkpoints**","metadata":{}},{"cell_type":"code","source":"class GANMonitor(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        \n        # Save the model every 5 epochs \n        if (epoch + 1) % 5 == 0:\n          checkpoint.save(file_prefix = checkpoint_prefix)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.127275Z","iopub.status.idle":"2022-03-31T13:33:56.128243Z","shell.execute_reply.started":"2022-03-31T13:33:56.127952Z","shell.execute_reply":"2022-03-31T13:33:56.127982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cenv == 0:\n    checkpoint_dir = '/kaggle/working/checkpoints'\nif cenv == 1:\n    checkpoint_dir = f'{new_dir}'\n    \ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=g_optimizer,\n                                 discriminator_optimizer=d_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.129631Z","iopub.status.idle":"2022-03-31T13:33:56.130608Z","shell.execute_reply.started":"2022-03-31T13:33:56.130323Z","shell.execute_reply":"2022-03-31T13:33:56.130351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training C-GAN","metadata":{}},{"cell_type":"code","source":"cond_gan = ConditionalGAN(\n    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n)\ncond_gan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n)\n\ncond_gan.fit(dataset, epochs=epoch_t, \n        callbacks=GANMonitor()\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.131675Z","iopub.status.idle":"2022-03-31T13:33:56.132426Z","shell.execute_reply.started":"2022-03-31T13:33:56.132212Z","shell.execute_reply":"2022-03-31T13:33:56.132236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Interpolating between classes with the trained GEN","metadata":{}},{"cell_type":"code","source":"# We first extract the trained generator from our Conditiona GAN.\ntrained_gen = cond_gan.generator\n\n# Choose the number of intermediate images that would be generated in\n# between the interpolation + 2 (start and last images).\nnum_interpolation = 50  # @param {type:\"integer\"}\n\n# Sample noise for the interpolation.\ninterpolation_noise = tf.random.normal(shape=(1, latent_dim))\ninterpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\ninterpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n\n\ndef interpolate_class(first_number, second_number):\n    # Convert the start and end labels to one-hot encoded vectors.\n    first_label = keras.utils.to_categorical([first_number], num_classes)\n    second_label = keras.utils.to_categorical([second_number], num_classes)\n    first_label = tf.cast(first_label, tf.float32)\n    second_label = tf.cast(second_label, tf.float32)\n\n    # Calculate the interpolation vector between the two labels.\n    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n    percent_second_label = tf.cast(percent_second_label, tf.float32)\n    interpolation_labels = (\n        first_label * (1 - percent_second_label) + second_label * percent_second_label\n    )\n\n    # Combine the noise and the labels and run inference with the generator.\n    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n    fake = trained_gen.predict(noise_and_labels)\n    return fake\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.133601Z","iopub.status.idle":"2022-03-31T13:33:56.133972Z","shell.execute_reply.started":"2022-03-31T13:33:56.133764Z","shell.execute_reply":"2022-03-31T13:33:56.133787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create new directory for saving folder\nos.makedirs(path_save_imgs)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.135322Z","iopub.status.idle":"2022-03-31T13:33:56.135737Z","shell.execute_reply.started":"2022-03-31T13:33:56.135578Z","shell.execute_reply":"2022-03-31T13:33:56.135595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve class name based on number\nclasses_list = list(prelim_dataset.class_indices)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:35:02.576467Z","iopub.execute_input":"2022-03-31T13:35:02.576769Z","iopub.status.idle":"2022-03-31T13:35:02.581251Z","shell.execute_reply.started":"2022-03-31T13:35:02.576735Z","shell.execute_reply":"2022-03-31T13:35:02.580323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(num_classes):\n    class_name = classes_list[i]\n    class_dir = f\"{path_save_imgs}/{class_name}\"\n    os.makedirs(class_dir)\n    start_class = i\n    end_class = i\n    fake_images = interpolate_class(start_class, end_class)\n    fake_images *= 255\n    converted_images = fake_images.astype(np.uint8)\n    converted_images = tf.image.resize(converted_images, (64, 64)).numpy().astype(np.uint8)\n    for j in range(num_interpolation):\n        np.save(file=f\"{class_dir}/gen_imgs_{class_name}_{j}.npy\", arr = converted_images[j])\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.141702Z","iopub.status.idle":"2022-03-31T13:33:56.142218Z","shell.execute_reply.started":"2022-03-31T13:33:56.141953Z","shell.execute_reply":"2022-03-31T13:33:56.141979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TESTING\n-----","metadata":{}},{"cell_type":"code","source":"if cenv == 1:\n    test = np.load(\"C:/Users/Max/Documents/image_data/cgan-local-v003/Sfone/gen_imgs_Sfone_49.npy\")\n    plt.imshow(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T13:33:56.143479Z","iopub.status.idle":"2022-03-31T13:33:56.143778Z","shell.execute_reply.started":"2022-03-31T13:33:56.143621Z","shell.execute_reply":"2022-03-31T13:33:56.143636Z"},"trusted":true},"execution_count":null,"outputs":[]}]}