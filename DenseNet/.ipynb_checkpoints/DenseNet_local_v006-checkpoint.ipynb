{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet (2of2)\n",
    "\n",
    "DenseNet 121 without 'imagenet' weights\n",
    "\n",
    "This model freezes all layers, except for the last 8. \n",
    "\n",
    "The model uses 40 epochs, and 'rgb' color channel. The DenseNet (and ResNet) only work with RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KXQu67zVoZAw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size (height x width)\n",
    "ih = 64\n",
    "iw = 64\n",
    "\n",
    "# Grayscale or RGB\n",
    "ch = 'rgb'\n",
    "\n",
    "# Batch size \n",
    "batch_size = 40000\n",
    "\n",
    "# Size of test set (in %)\n",
    "testsize = 0.3\n",
    "\n",
    "# Epochs\n",
    "epoch_t = 40\n",
    "\n",
    "# Where computation is performed: Kaggle (0) or Local (1)\n",
    "cenv = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation environment: Local\n"
     ]
    }
   ],
   "source": [
    "if cenv == 0:\n",
    "    print(\"Computation environment: Kaggle\")\n",
    "if cenv == 1:\n",
    "    print(\"Computation environment: Local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new directory for version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 matches(es) found\n",
      "--------------\n",
      "New folder name: DenseNet-local-v006\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "if cenv == 1:\n",
    "    file_exists = []\n",
    "    vnum = 1\n",
    "    dir = \"C:/Users/Max/Documents/GitHub/DenseNet\"\n",
    "    for files in os.listdir(dir):\n",
    "        if \"DenseNet\" in files: \n",
    "            try:\n",
    "                vnum = max(vnum, int(files[-3:]))\n",
    "            except: \n",
    "                continue\n",
    "            new_vnum = vnum + 1\n",
    "            file_exists.append(True)\n",
    "        else: \n",
    "            file_exists.append(False)\n",
    "    # If this is the first notebook you want to save, a new folder will be created with version #001\n",
    "    if sum(file_exists) == 0:\n",
    "        new_vnum = 1\n",
    "        print(\"No matches found\")\n",
    "\n",
    "    else: \n",
    "        print(f\"{sum(file_exists)} matches(es) found\")\n",
    "        print(\"--------------\")\n",
    "\n",
    "    # Print new folder name\n",
    "    print(f\"New folder name: DenseNet-local-v{new_vnum:03}\")\n",
    "    print(\"--------------\")\n",
    "    \n",
    "    # Create new folder with the name of the notebook and the version number\n",
    "    new_dir = f\"/Users/Max/Documents/GitHub/DenseNet/DenseNet-local-v{new_vnum:03}\"\n",
    "    os.makedirs(new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T09:05:56.933069Z",
     "iopub.status.busy": "2022-03-25T09:05:56.932806Z",
     "iopub.status.idle": "2022-03-25T09:05:56.940533Z",
     "shell.execute_reply": "2022-03-25T09:05:56.939803Z",
     "shell.execute_reply.started": "2022-03-25T09:05:56.93304Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if cenv == 0:\n",
    "    path_root = \"/kaggle/input/thesis-data\"\n",
    "    \n",
    "    # Directory where checkpoints of DCGAN are stored\n",
    "    checkpoint_dir = \"/kaggle/input/checkpoints\" \n",
    "\n",
    "if cenv == 1:\n",
    "    path_root = \"C:/Users/Max/Documents/thesis_data\"\n",
    "    \n",
    "    # Directory where checkpoints of DCGAN are stored\n",
    "    checkpoint_dir = 'C:/Users/Max/Documents/GitHub/dcgan_kaggle_output/dcgan-kaggle-v002/checkpoints'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_si = (ih, iw)\n",
    "\n",
    "if(ch == 'rgb'):\n",
    "    chnum = 3\n",
    "elif(ch == 'grayscale'):\n",
    "    chnum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26548 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = ImageDataGenerator().flow_from_directory(\n",
    "    directory  = path_root, \n",
    "    color_mode = ch, \n",
    "    target_size= (ih,iw), \n",
    "    interpolation=\"bicubic\",\n",
    "    class_mode = 'sparse',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "imgs, labels = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_imgs = tf.keras.applications.resnet.preprocess_input(imgs)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(processed_imgs, labels, test_size=testsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data: 18583 | Shape of training data (18583, 64, 64, 3)\n",
      "Size of training data: 7965  | Shape of training data (7965, 64, 64, 3)\n",
      "Shape of training labels (18583,)\n",
      "Shape of training labels (7965,)\n"
     ]
    }
   ],
   "source": [
    "trainsize = len(X_train)\n",
    "testsize = len(X_test)\n",
    "\n",
    "print(f\"Size of training data: {trainsize} | Shape of training data {X_train.shape}\")\n",
    "print(f\"Size of training data: {testsize}  | Shape of training data {X_test.shape}\")\n",
    "print(f\"Shape of training labels {y_train.shape}\")\n",
    "print(f\"Shape of training labels {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2mRBkTBoig8",
    "outputId": "7aeee00a-bdff-41db-8473-6e04850605b5"
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.DenseNet121(weights = None, include_top = False, input_shape = (64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rWSL-tt4qBRa"
   },
   "outputs": [],
   "source": [
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1000, activation='relu')(x)\n",
    "predictions = layers.Dense(11, activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "s1sYr8cIt0nY"
   },
   "outputs": [],
   "source": [
    "head_model = Model(inputs = base_model.input, outputs = predictions)\n",
    "head_model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in head_model.layers[:-8]:\n",
    "    layer.trainable=False\n",
    "    \n",
    "for layer in head_model.layers[-8:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
    "if cenv == 0:\n",
    "    checkpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n",
    "if cenv == 1:\n",
    "    checkpoint = ModelCheckpoint(f'{new_dir}/model.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "151/291 [==============>...............] - ETA: 14s - loss: 0.6131 - accuracy: 0.8485"
     ]
    }
   ],
   "source": [
    "history = head_model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    batch_size=64, \n",
    "    epochs=epoch_t, \n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks = [anne, checkpoint]) # EPOCHS WAS 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cenv == 0:\n",
    "    best_model = load_model(\"/kaggle/working/model.h5\")\n",
    "if cenv == 1:\n",
    "    best_model = load_model(f\"{new_dir}/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b5bRktf4ydg",
    "outputId": "37f5eb06-7caa-4c5f-b6fd-9b5758a1f057"
   },
   "outputs": [],
   "source": [
    "scores = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Overall CNN Accuracy: {scores[1]}\\n(The number of correct predictions divided by the number of total predictions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_distribution = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = batches.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = (multi_distribution[1]/labels.shape[0])*100\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.bar(classes,perc)\n",
    "if cenv == 0:\n",
    "    plt.savefig(\"multi_data_dist.png\", bbox_inches = 'tight')\n",
    "if cenv == 1:\n",
    "    plt.savefig(f\"{new_dir}/multi_data_dist.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def my_fmt(x):\n",
    "    return '{:.1f}%\\n({:.0f})'.format(x, total*x/100)\n",
    "total = trainsize + testsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.pie(\n",
    "    [trainsize, testsize], \n",
    "    labels = [\"Training\", \"Validation\"], \n",
    "    startangle=90, \n",
    "    counterclock=False, \n",
    "    autopct=my_fmt,\n",
    "    colors = ['gray', 'silver']\n",
    ")\n",
    "\n",
    "plt.title(\"Training and validation data distribution\")\n",
    "\n",
    "if cenv == 0:\n",
    "    plt.savefig(\"train_test_dist.png\", bbox_inches = 'tight')\n",
    "if cenv == 1:\n",
    "    plt.savefig(f\"{new_dir}/train_test_dist.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "id": "yE3OUgo34v_C",
    "outputId": "fd989d09-d97f-478e-e768-0e2e739a17aa"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "\n",
    "axs[0].plot(history.history['loss'])\n",
    "axs[0].plot(history.history['val_loss'])\n",
    "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend(['Train','Val'])\n",
    "\n",
    "axs[1].plot(history.history['accuracy'])\n",
    "axs[1].plot(history.history['val_accuracy'])\n",
    "axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend(['Train', 'Val'])\n",
    "\n",
    "if cenv == 0:\n",
    "    plt.savefig(\"performance_figure.png\", bbox_inches = 'tight')\n",
    "if cenv == 1:\n",
    "    plt.savefig(f\"{new_dir}/performance_figure.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse performance\n",
    "\n",
    "**Multiclass classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable, MSWORD_FRIENDLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass performance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = PrettyTable(['Metric', 'Performance'])\n",
    "t.add_row(['Valididation accuracy', round(scores[1],4)])\n",
    "t.add_row(['Validation loss', round(scores[0],4)])\n",
    "t.header = True\n",
    "t.align = \"l\"\n",
    "t.title = \"Perf. of multi-class classification - DenseNet\"\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving PrettyTable\n",
    "table = t.get_string()\n",
    "\n",
    "if cenv == 0:\n",
    "    with open('multi_performance_table.txt', 'w') as f:\n",
    "        f.write(table)\n",
    "if cenv == 1:\n",
    "    with open(f'{new_dir}/multi_performance_table.txt', 'w') as f:\n",
    "        f.write(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(best_model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test2 = y_test\n",
    "y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_matrix = metrics.confusion_matrix(y_test2, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "   \n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    if cenv == 0:\n",
    "        plt.savefig(\"multi_class_cmatrix.png\")\n",
    "    if cenv == 1:\n",
    "        plt.savefig(f\"{new_dir}/multi_class_cmatrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names= batches.class_indices.keys()\n",
    "confusion_matrix(c_matrix, class_names, figsize = (20,7), fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary classification**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score\n",
    "from prettytable import PrettyTable, MSWORD_FRIENDLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predbin = [] \n",
    "y_truebin = []\n",
    "for count, value in enumerate(y_test2):\n",
    "    if y_test2[count] in range(10): # range(10) is 0 to 9\n",
    "        y_truebin.append(0)\n",
    "    else: y_truebin.append(1)\n",
    "    \n",
    "    if y_pred[count] in range(10):\n",
    "        y_predbin.append(0)\n",
    "    else: y_predbin.append(1)\n",
    "    \n",
    "    continue\n",
    "if len(y_truebin) == len(y_predbin):\n",
    "    print(f\"Length of the observations in test set: {len(y_truebin)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_count = 0\n",
    "bn_count = 0\n",
    "for count, value in enumerate(multi_distribution[1]):\n",
    "    if count in range(10):\n",
    "        rw_count = rw_count + multi_distribution[1][count]\n",
    "    else: \n",
    "        bn_count = bn_count + multi_distribution[1][count]\n",
    "print(f\"Ransomware Occurences: {rw_count}, Benign Occurences: {bn_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "x_lab = ['Ransomware', 'Benign']\n",
    "y_lab = [rw_count, bn_count]\n",
    "ax.bar(x_lab, y_lab)\n",
    "if cenv == 0:\n",
    "    plt.savefig(\"bin_data_dist.png\", bbox_inches = 'tight')\n",
    "if cenv == 1:\n",
    "    plt.savefig(f\"{new_dir}/bin_data_dist.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix_bin = metrics.confusion_matrix(y_truebin, y_predbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_bin(confusion_matrix, class_names_bin, figsize = (5,2), fontsize=7):\n",
    "   \n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names_bin, columns=class_names_bin, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title(\"DenseNet121\")\n",
    "    if cenv == 0:\n",
    "        plt.savefig(\"bin_class_cmatrix.png\", bbox_inches = 'tight')\n",
    "    if cenv == 1:\n",
    "        plt.savefig(f\"{new_dir}/bin_class_cmatrix.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_bin= (\"ransomware\", \"benign\")\n",
    "confusion_matrix_bin(c_matrix_bin, class_names_bin, figsize = (5,2), fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**True Positive Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR = c_matrix_bin[0,0]/(c_matrix_bin[0,0] + c_matrix_bin[0,1]) #True Positive Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC = accuracy_score(y_truebin, y_predbin) # Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = f1_score(y_truebin, y_predbin, labels=0) # F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matthews Correlation Coefficient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCC = matthews_corrcoef(y_truebin, y_predbin) # Matthews Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = PrettyTable(['Metric', 'Performance'])\n",
    "t.add_row(['True Positive Rate', round(TPR,4)])\n",
    "t.add_row(['Accuracy', round(ACC,4)])\n",
    "t.add_row(['F1 Score', round(F1,4)])\n",
    "t.add_row(['Matthews Correlation Coefficient', round(MCC,4)])\n",
    "t.header = True\n",
    "t.align = \"l\"\n",
    "t.title = \"Performance of DenseNet\"\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving PrettyTable\n",
    "table = t.get_string()\n",
    "\n",
    "if cenv == 0:\n",
    "    with open('bin_performance_table.txt', 'w') as f:\n",
    "        f.write(table)\n",
    "if cenv == 1:\n",
    "    with open(f'{new_dir}/bin_performance_table.txt', 'w') as f:\n",
    "        f.write(table)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPkF5cbObNA2gzRa9KkWXrw",
   "include_colab_link": true,
   "name": "ResNet_Transfer_Learning_TensorFlow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
