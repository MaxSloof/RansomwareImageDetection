{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import datasets, layers, models, losses, Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport os","metadata":{"id":"KXQu67zVoZAw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image size (height x width)\nih = 64\niw = 64\n\n# Grayscale or RGB\nch = 'rgb'\n\n# Batch size \nbatch_size = 40000\n\n# Layer adapt\nksize = 4 # Kernel size : was '4' for 64x64 image\nssize = 2 # Stride size : was '2' for 64x64 image\n\n# Size of test set (in %)\ntestsize = 0.3\n\n# Number of epochs in untrainable model\nepoch_unt = 7\n\n# Number of epochs in trainable model\nepoch_t = 8\n\n# Where computation is performed: Kaggle (0) or Local (1)\ncenv = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cenv == 0:\n    print(\"Computation environment: Kaggle\")\nif cenv == 1:\n    print(\"Computation environment: Local\")","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create new directory for version**","metadata":{}},{"cell_type":"code","source":"if cenv == 1:\n    file_exists = []\n    vnum = 1\n    dir = \"C:/Users/Max/Documents/GitHub/ResNet\"\n    for files in os.listdir(dir):\n        if \"ResNet\" in files: \n            try:\n                vnum = max(vnum, int(files[-3:]))\n            except: \n                continue\n            new_vnum = vnum + 1\n            file_exists.append(True)\n        else: \n            file_exists.append(False)\n    # If this is the first notebook you want to save, a new folder will be created with version #001\n    if sum(file_exists) == 0:\n        new_vnum = 1\n        print(\"No matches found\")\n\n    else: \n        print(f\"{sum(file_exists)} matches(es) found\")\n        print(\"--------------\")\n\n    # Print new folder name\n    print(f\"New folder name: ResNet-local-v{new_vnum:03}\")\n    print(\"--------------\")\n    \n    # Create new folder with the name of the notebook and the version number\n    new_dir = f\"/Users/Max/Documents/GitHub/ResNet/ResNet-local-v{new_vnum:03}\"\n    os.makedirs(new_dir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"if cenv == 0:\n    path_root = \"/kaggle/input/thesis-data\"\n    \n    # Directory where checkpoints of DCGAN are stored\n    checkpoint_dir = \"/kaggle/input/checkpoints\" \n\nif cenv == 1:\n    path_root = \"C:/Users/Max/Documents/thesis_data\"\n    \n    # Directory where checkpoints of DCGAN are stored\n    checkpoint_dir = 'C:/Users/Max/Documents/GitHub/dcgan_kaggle_output/dcgan-kaggle-v002/checkpoints'\n    ","metadata":{"execution":{"iopub.execute_input":"2022-03-25T09:05:56.933069Z","iopub.status.busy":"2022-03-25T09:05:56.932806Z","iopub.status.idle":"2022-03-25T09:05:56.940533Z","shell.execute_reply":"2022-03-25T09:05:56.939803Z","shell.execute_reply.started":"2022-03-25T09:05:56.93304Z"},"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_si = (ih, iw)\n\nif(ch == 'rgb'):\n    chnum = 3\nelif(ch == 'grayscale'):\n    chnum = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batches = ImageDataGenerator().flow_from_directory(\n    directory  = path_root, \n    color_mode = ch, \n    target_size= (ih,iw), \n    interpolation=\"bicubic\",\n    class_mode = 'sparse',\n    batch_size=batch_size\n)\nimgs, labels = next(batches)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_imgs = tf.keras.applications.resnet.preprocess_input(imgs)\nlabels = np.array(labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(processed_imgs, labels, test_size=testsize)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainsize = len(X_train)\ntestsize = len(X_test)\n\nprint(f\"Size of training data: {trainsize} | Shape of training data {X_train.shape}\")\nprint(f\"Size of training data: {testsize}  | Shape of training data {X_test.shape}\")\nprint(f\"Shape of training labels {y_train.shape}\")\nprint(f\"Shape of training labels {y_test.shape}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet","metadata":{}},{"cell_type":"code","source":"base_model = tf.keras.applications.ResNet152(weights = 'imagenet', include_top = False, input_shape = (64,64,3))\nfor layer in base_model.layers:\n  layer.trainable = False","metadata":{"id":"d2mRBkTBoig8","outputId":"7aeee00a-bdff-41db-8473-6e04850605b5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = layers.Flatten()(base_model.output)\nx = layers.Dense(1000, activation='relu')(x)\npredictions = layers.Dense(11, activation = 'softmax')(x)","metadata":{"id":"rWSL-tt4qBRa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head_model = Model(inputs = base_model.input, outputs = predictions)\nhead_model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])","metadata":{"id":"s1sYr8cIt0nY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Callbacks","metadata":{}},{"cell_type":"code","source":"anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\nif cenv == 0:\n    checkpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\nif cenv == 1:\n    checkpoint = ModelCheckpoint(f'{new_dir}/model.h5', verbose=1, save_best_only=True)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = head_model.fit(\n    X_train, \n    y_train,\n    batch_size=64, \n    epochs=80, \n    validation_data=(X_test, y_test),\n    callbacks = [anne, checkpoint]) # EPOCHS WAS 40","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cenv == 0:\n    best_model = load_model(\"/kaggle/working/model.h5\")\nif cenv == 1:\n    best_model = load_model(f\"{new_dir}/model.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = best_model.evaluate(X_test, y_test)\nprint(f\"Overall CNN Accuracy: {scores[1]}\\n(The number of correct predictions divided by the number of total predictions)\")","metadata":{"id":"3b5bRktf4ydg","outputId":"37f5eb06-7caa-4c5f-b6fd-9b5758a1f057"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plots","metadata":{}},{"cell_type":"code","source":"multi_distribution = np.unique(labels, return_counts=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = batches.class_indices.keys()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perc = (multi_distribution[1]/labels.shape[0])*100\nplt.xticks(rotation='vertical')\nplt.bar(classes,perc)\nif cenv == 0:\n    plt.savefig(\"multi_data_dist.png\", bbox_inches = 'tight')\nif cenv == 1:\n    plt.savefig(f\"{new_dir}/multi_data_dist.png\", bbox_inches = 'tight')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_fmt(x):\n    return '{:.1f}%\\n({:.0f})'.format(x, total*x/100)\ntotal = trainsize + testsize","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.pie(\n    [trainsize, testsize], \n    labels = [\"Training\", \"Validation\"], \n    startangle=90, \n    counterclock=False, \n    autopct=my_fmt,\n    colors = ['gray', 'silver']\n)\n\nplt.title(\"Training and validation data distribution\")\n\nif cenv == 0:\n    plt.savefig(\"train_test_dist.png\", bbox_inches = 'tight')\nif cenv == 1:\n    plt.savefig(f\"{new_dir}/train_test_dist.png\", bbox_inches = 'tight')","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(2, 1, figsize=(15,15))\n\naxs[0].plot(history.history['loss'])\naxs[0].plot(history.history['val_loss'])\naxs[0].title.set_text('Training Loss vs Validation Loss')\naxs[0].set_xlabel('Epochs')\naxs[0].set_ylabel('Loss')\naxs[0].legend(['Train','Val'])\n\naxs[1].plot(history.history['accuracy'])\naxs[1].plot(history.history['val_accuracy'])\naxs[1].title.set_text('Training Accuracy vs Validation Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Accuracy')\naxs[1].legend(['Train', 'Val'])\n\nif cenv == 0:\n    plt.savefig(\"performance_figure.png\", bbox_inches = 'tight')\nif cenv == 1:\n    plt.savefig(f\"{new_dir}/performance_figure.png\", bbox_inches = 'tight')","metadata":{"id":"yE3OUgo34v_C","outputId":"fd989d09-d97f-478e-e768-0e2e739a17aa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyse performance\n\n**Multiclass classification**","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nimport pandas as pd\nimport seaborn as sns\nfrom prettytable import PrettyTable, MSWORD_FRIENDLY","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Multiclass performance table","metadata":{}},{"cell_type":"code","source":"t = PrettyTable(['Metric', 'Performance'])\nt.add_row(['Valididation accuracy', round(scores[1],4)])\nt.add_row(['Validation loss', round(scores[0],4)])\nt.header = True\nt.align = \"l\"\nt.title = \"Perf. of multi-class classification - ResNet\"\nprint(t)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving PrettyTable\ntable = t.get_string()\n\nif cenv == 0:\n    with open('multi_performance_table.txt', 'w') as f:\n        f.write(table)\nif cenv == 1:\n    with open(f'{new_dir}/multi_performance_table.txt', 'w') as f:\n        f.write(table)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.argmax(best_model.predict(X_test), axis=-1)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test2 = y_test\ny_test2","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_matrix = metrics.confusion_matrix(y_test2, y_pred)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n   \n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    if cenv == 0:\n        plt.savefig(\"multi_class_cmatrix.png\")\n    if cenv == 1:\n        plt.savefig(f\"{new_dir}/multi_class_cmatrix.png\")","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names= batches.class_indices.keys()\nconfusion_matrix(c_matrix, class_names, figsize = (20,7), fontsize=14)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Binary classification**\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predbin = [] \ny_truebin = []\nfor count, value in enumerate(y_test2):\n    if y_test2[count] in range(10): # range(10) is 0 to 9\n        y_truebin.append(0)\n    else: y_truebin.append(1)\n    \n    if y_pred[count] in range(10):\n        y_predbin.append(0)\n    else: y_predbin.append(1)\n    \n    continue\nif len(y_truebin) == len(y_predbin):\n    print(f\"Length of the observations in test set: {len(y_truebin)}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rw_count = 0\nbn_count = 0\nfor count, value in enumerate(multi_distribution[1]):\n    if count in range(10):\n        rw_count = rw_count + multi_distribution[1][count]\n    else: \n        bn_count = bn_count + multi_distribution[1][count]\nprint(f\"Ransomware Occurences: {rw_count}, Benign Occurences: {bn_count}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nx_lab = ['Ransomware', 'Benign']\ny_lab = [rw_count, bn_count]\nax.bar(x_lab, y_lab)\nif cenv == 0:\n    plt.savefig(\"data_dist.png.png\", bbox_inches = 'tight')\nif cenv == 1:\n    plt.savefig(f\"{new_dir}/bin_data_dist.png\", bbox_inches = 'tight')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_matrix_bin = metrics.confusion_matrix(y_truebin, y_predbin)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def confusion_matrix_bin(confusion_matrix, class_names_bin, figsize = (5,2), fontsize=7):\n   \n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names_bin, columns=class_names_bin, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.title(\"ResNet152\")\n    if cenv == 0:\n        plt.savefig(\"bin_class_cmatrix.png\", bbox_inches = 'tight')\n    if cenv == 1:\n        plt.savefig(f\"{new_dir}/bin_class_cmatrix.png\", bbox_inches = 'tight')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names_bin= (\"ransomware\", \"benign\")\nconfusion_matrix_bin(c_matrix_bin, class_names_bin, figsize = (5,2), fontsize=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**True Positive Rate**","metadata":{}},{"cell_type":"code","source":"TPR = c_matrix_bin[0,0]/(c_matrix_bin[0,0] + c_matrix_bin[0,1]) #True Positive Rate","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Accuracy**","metadata":{}},{"cell_type":"code","source":"ACC = accuracy_score(y_truebin, y_predbin) # Accuracy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**F1 Score**","metadata":{}},{"cell_type":"code","source":"F1 = f1_score(y_truebin, y_predbin, labels=0) # F1 Score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Matthews Correlation Coefficient**","metadata":{}},{"cell_type":"code","source":"MCC = matthews_corrcoef(y_truebin, y_predbin) # Matthews Correlation Coefficient","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = PrettyTable(['Metric', 'Performance'])\nt.add_row(['True Positive Rate', round(TPR,4)])\nt.add_row(['Accuracy', round(ACC,4)])\nt.add_row(['F1 Score', round(F1,4)])\nt.add_row(['Matthews Correlation Coefficient', round(MCC,4)])\nt.header = True\nt.align = \"l\"\nt.title = \"Performance of ResNet\"\nprint(t)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving PrettyTable\ntable = t.get_string()\n\nif cenv == 0:\n    with open('bin_performance_table.txt', 'w') as f:\n        f.write(table)\nif cenv == 1:\n    with open(f'{new_dir}/bin_performance_table.txt', 'w') as f:\n        f.write(table)","metadata":{},"execution_count":null,"outputs":[]}]}