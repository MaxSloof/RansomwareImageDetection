{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Deep Convolutional Generative Adversarial Network  (1of2)","metadata":{"id":"Yqp2aX78LtH0"}},{"cell_type":"markdown","source":"**OVERVIEW**\n\nThis model uses the parameters as in the 'CHANGE' box + *ReLU* as activation layer in both the gen. and disc. ","metadata":{}},{"cell_type":"markdown","source":"# CHANGE","metadata":{}},{"cell_type":"markdown","source":"_____________________________________________________________________","metadata":{}},{"cell_type":"code","source":"# Image size (height x width)\nih = 64\niw = 64\n\n# Grayscale or RGB\nch = 'grayscale'\n\n# Layer adapt\nksize = 4 # Kernel size : was '4' for 64x64 image\nssize = 2 # Stride size : was '2' for 64x64 image\n\n# Batch size\nbatch_size = 32\n\n# Number of epochs\nepoch_t = 5\n\n# Where computation is performed: Kaggle (0) or Local (1)\ncenv = 0\n\n# Do you want to restore from checkpoint\nrestore = False\n\n# Are you going to use a TPU?\nuse_tpu = 'n'","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:00:46.837813Z","iopub.status.busy":"2022-03-21T17:00:46.837492Z","iopub.status.idle":"2022-03-21T17:00:46.844141Z","shell.execute_reply":"2022-03-21T17:00:46.843074Z","shell.execute_reply.started":"2022-03-21T17:00:46.837772Z"},"id":"nXzDemd6yFMN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_____________________________________________________________________","metadata":{}},{"cell_type":"code","source":"if cenv == 0:\n    print(\"Computation environment: Kaggle\")\nif cenv == 1:\n    print(\"Computation environment: Local\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup","metadata":{"id":"MQ6hXbgPLtH2"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nimport cv2\nimport random as rd\nimport PIL","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:00:38.662595Z","iopub.status.busy":"2022-03-21T17:00:38.662185Z","iopub.status.idle":"2022-03-21T17:00:46.835078Z","shell.execute_reply":"2022-03-21T17:00:46.833898Z","shell.execute_reply.started":"2022-03-21T17:00:38.662502Z"},"id":"waMV_df_LtH3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create directories for saving output**","metadata":{}},{"cell_type":"code","source":"if cenv == 1:\n    file_exists = []\n    vnum = 1\n    dir = \"C:/Users/Max/Documents/GitHub/dcgan\"\n    for files in os.listdir(dir):\n        if \"dcgan\" in files: \n            try:\n                vnum = max(vnum, int(files[-3:]))\n            except: \n                continue\n            new_vnum = vnum + 1\n            file_exists.append(True)\n        else: \n            file_exists.append(False)\n    # If this is the first notebook you want to save, a new folder will be created with version #001\n    if sum(file_exists) == 0:\n        new_vnum = 1\n        print(\"No matches found\")\n\n    else: \n        print(f\"{sum(file_exists)} matches(es) found\")\n        print(\"--------------\")\n\n    # Print new folder name\n    print(f\"New folder name: dcgan-local-v{new_vnum:03}\")\n    print(\"--------------\")\n    \n    # Create new folder with the name of the notebook and the version number\n    new_dir = f\"/Users/Max/Documents/GitHub/dcgan/dcgan-local-v{new_vnum:03}\"\n    os.makedirs(new_dir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cenv == 0:\n    try: \n        checkpoint_dir = \"/kaggle/working/checkpoints\"\n        os.makedirs(checkpoint_dir)\n        print(\"Path for checkpoints has been created!\")\n    except:\n        print(\"Path already exists\")\nif cenv == 1:\n    try:\n        checkpoint_dir = f\"{new_dir}/checkpoint\"\n        os.makedirs(checkpoint_dir)\n        print(\"Local path for checkpoints has been created\")\n    except:\n        print(\"Local path already exists\")","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:00:46.892938Z","iopub.status.busy":"2022-03-21T17:00:46.89187Z","iopub.status.idle":"2022-03-21T17:00:46.903291Z","shell.execute_reply":"2022-03-21T17:00:46.902375Z","shell.execute_reply.started":"2022-03-21T17:00:46.892865Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cenv == 0:\n    try:\n        gen_img_dir = \"/kaggle/working/generated_images\"\n        os.makedirs(gen_img_dir)\n        print(\"Path for generated images has been created!\")\n    except:\n        print(\"Path for generating images already exists\")\nif cenv == 1:\n    try:\n        gen_img_dir = f\"{new_dir}/generated_images\"\n        os.makedirs(gen_img_dir)\n        print(\"Local path for checkpoints has been created\")\n    except:\n        print(\"Local path already exists\")","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:00:46.905513Z","iopub.status.busy":"2022-03-21T17:00:46.904614Z","iopub.status.idle":"2022-03-21T17:00:46.91629Z","shell.execute_reply":"2022-03-21T17:00:46.915258Z","shell.execute_reply.started":"2022-03-21T17:00:46.905474Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data**","metadata":{"id":"uOZNby3TLtH4"}},{"cell_type":"code","source":"# Overwrite if TPU is used\nif use_tpu == 'y' or use_tpu == 'Y':\n    batch_size = 16 * tpu_strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:00:46.918273Z","iopub.status.busy":"2022-03-21T17:00:46.917998Z","iopub.status.idle":"2022-03-21T17:00:46.93376Z","shell.execute_reply":"2022-03-21T17:00:46.932989Z","shell.execute_reply.started":"2022-03-21T17:00:46.918231Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_tpu == 'y' or use_tpu == 'Y': \n    # Step 1: Get the credentail from the Cloud SDK\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    user_credential = user_secrets.get_gcloud_credential()\n    user_secrets.set_tensorflow_credential(user_credential)\n\n    # Step 3: Use a familiar call to get the GCS path of the dataset\n    !gcloud config set project 'solid-topic-344315'\n    \n    path_root = 'gs://thesis_data_max/classified_data'\n    \n\n    \nelse: \n    if cenv == 0:\n        path_root = \"/kaggle/input/thesis-data\"\n        \n        #Directory from which checkpoints can be restored if you do GAN in multiple iterations\n        checkpoint_restore_directory = '/kaggle/input/dcgan-tweaking-kaggle/checkpoints'\n    \n    if cenv == 1:\n        path_root = \"C:/Users/Max/Documents/thesis_data\"\n        \n        #Directory from which checkpoints can be restored if you do GAN in multiple iterations\n        checkpoint_restore_directory = ''","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:00:46.935677Z","iopub.status.busy":"2022-03-21T17:00:46.93512Z","iopub.status.idle":"2022-03-21T17:00:46.953529Z","shell.execute_reply":"2022-03-21T17:00:46.952239Z","shell.execute_reply.started":"2022-03-21T17:00:46.935637Z"},"id":"4H4AwAFpLtH4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a dataset from our folder, and rescale the images to the [0-1] range:","metadata":{"id":"JP_TdOVnLtH5"}},{"cell_type":"code","source":"im_si = (ih, iw)\n\nif(ch == 'rgb'):\n    chnum = 3\nelif(ch == 'grayscale'):\n    chnum = 1\n","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:00:52.987697Z","iopub.status.busy":"2022-03-21T17:00:52.987345Z","iopub.status.idle":"2022-03-21T17:00:52.995238Z","shell.execute_reply":"2022-03-21T17:00:52.992751Z","shell.execute_reply.started":"2022-03-21T17:00:52.987659Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (use_tpu == 'y' or use_tpu == 'Y'):\n    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n        GCS_DS_PATH, \n        label_mode = None,\n        color_mode = ch,\n        image_size = im_si,\n        interpolation='bicubic',\n        batch_size = batch_size\n)\n    \nif (use_tpu == 'n' or use_tpu == 'N'):\n    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n        path_root, \n        label_mode = None,\n        color_mode = ch,\n        image_size = im_si,\n        interpolation='bicubic',\n        batch_size = batch_size\n    )\n\ndataset = dataset.map(lambda x : x / 255.0)","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:00:52.997209Z","iopub.status.busy":"2022-03-21T17:00:52.996443Z","iopub.status.idle":"2022-03-21T17:01:14.530276Z","shell.execute_reply":"2022-03-21T17:01:14.529131Z","shell.execute_reply.started":"2022-03-21T17:00:52.997144Z"},"id":"WH5fIdgBnZE5","outputId":"2957b61c-4951-407c-a889-77ed834b57a8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's display a sample image:","metadata":{"id":"bk2Y9PcvLtH6"}},{"cell_type":"markdown","source":"## Create the discriminator\n\nIt maps a 64x64 image to a binary classification score.","metadata":{"id":"219PDLAMLtH7"}},{"cell_type":"code","source":"def create_discriminator():\n  return keras.Sequential(\n      [\n        \n          layers.Conv2D(ih, kernel_size=ksize, strides=ssize, padding=\"same\",\n                        input_shape=(ih, iw, chnum)),\n          layers.ReLU(),\n          layers.Conv2D(2*ih, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.ReLU(),\n          layers.Conv2D(2*ih, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.ReLU(),\n          layers.Flatten(),\n          layers.Dropout(0.2),\n          layers.Dense(1, activation=\"sigmoid\"),\n      ],\n      name=\"discriminator\",\n  )\n","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.531484Z","iopub.status.busy":"2022-03-21T17:01:14.531278Z","iopub.status.idle":"2022-03-21T17:01:14.542158Z","shell.execute_reply":"2022-03-21T17:01:14.541059Z","shell.execute_reply.started":"2022-03-21T17:01:14.531458Z"},"id":"xUEQGyFpLtH8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create the generator\n\nIt mirrors the discriminator, replacing `Conv2D` layers with `Conv2DTranspose` layers.","metadata":{"id":"OoTIdSsDLtH8"}},{"cell_type":"code","source":"latent_dim = ih\nsih = ih//8\nsiw = iw//8\n\ndef create_generator():\n  return keras.Sequential(\n      [\n          keras.layers.InputLayer(input_shape=(latent_dim)),\n          \n          layers.Dense(sih * siw * latent_dim),\n          layers.Reshape((sih, siw, latent_dim)),\n          layers.Conv2DTranspose(latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.ReLU(),\n          layers.Conv2DTranspose(2*latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.ReLU(),\n          layers.Conv2DTranspose(4*latent_dim, kernel_size=ksize, strides=ssize, padding=\"same\"),\n          layers.ReLU(),\n          layers.Conv2D(chnum, kernel_size=ksize+1, padding=\"same\", activation=\"sigmoid\"),\n      ],\n      name=\"generator\",\n  )\n","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.544721Z","iopub.status.busy":"2022-03-21T17:01:14.54392Z","iopub.status.idle":"2022-03-21T17:01:14.556778Z","shell.execute_reply":"2022-03-21T17:01:14.555719Z","shell.execute_reply.started":"2022-03-21T17:01:14.544667Z"},"id":"oJWFNzjjLtH8","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_tpu == 'y' or use_tpu == 'Y':\n    with tpu_strategy.scope():\n        generator = create_generator()\n        discriminator = create_discriminator()\nelse:  \n    generator = create_generator()\n    discriminator = create_discriminator()","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.560313Z","iopub.status.busy":"2022-03-21T17:01:14.560054Z","iopub.status.idle":"2022-03-21T17:01:14.798311Z","shell.execute_reply":"2022-03-21T17:01:14.797233Z","shell.execute_reply.started":"2022-03-21T17:01:14.560284Z"},"id":"eAzWstRrJTnV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator.summary()","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.800219Z","iopub.status.busy":"2022-03-21T17:01:14.799831Z","iopub.status.idle":"2022-03-21T17:01:14.811255Z","shell.execute_reply":"2022-03-21T17:01:14.810003Z","shell.execute_reply.started":"2022-03-21T17:01:14.800171Z"},"id":"ixCCxiGLHgmV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.summary()","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.813461Z","iopub.status.busy":"2022-03-21T17:01:14.812966Z","iopub.status.idle":"2022-03-21T17:01:14.830657Z","shell.execute_reply":"2022-03-21T17:01:14.829776Z","shell.execute_reply.started":"2022-03-21T17:01:14.813415Z"},"id":"qF-AyFSjHzoY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Override `train_step`","metadata":{"id":"35QhQ42WLtH9"}},{"cell_type":"code","source":"class GAN(keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(GAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(GAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n\n    @property\n    def metrics(self):\n        return [self.d_loss_metric, self.g_loss_metric]\n\n    def train_step(self, real_images):\n        # Sample random points in the latent space\n        \n        batch_size = tf.shape(real_images)[0]\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Decode them to fake images\n        generated_images = self.generator(random_latent_vectors)\n\n        # Combine them with real images\n        combined_images = tf.concat([generated_images, real_images], axis=0)\n\n        # Assemble labels discriminating real from fake images\n        labels = tf.concat(\n            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n        )\n        # Add random noise to the labels - important trick!\n        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n\n        # Train the discriminator\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(\n            zip(grads, self.discriminator.trainable_weights)\n        )\n\n        # Sample random points in the latent space\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Assemble labels that say \"all real images\"\n        misleading_labels = tf.zeros((batch_size, 1))\n\n        # Train the generator (note that we should *not* update the weights\n        # of the discriminator)!\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(self.generator(random_latent_vectors))\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        # Update metrics\n        self.d_loss_metric.update_state(d_loss)\n        self.g_loss_metric.update_state(g_loss)\n        return {\n            \"d_loss\": self.d_loss_metric.result(),\n            \"g_loss\": self.g_loss_metric.result(),\n        }\n  \n","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.83256Z","iopub.status.busy":"2022-03-21T17:01:14.832303Z","iopub.status.idle":"2022-03-21T17:01:14.851556Z","shell.execute_reply":"2022-03-21T17:01:14.85032Z","shell.execute_reply.started":"2022-03-21T17:01:14.832521Z"},"id":"y8nmAfrtLtH9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Other GAN Script**","metadata":{"id":"xQUSDLa9LtH-"}},{"cell_type":"code","source":"# This method returns a helper function to compute cross entropy loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.854321Z","iopub.status.busy":"2022-03-21T17:01:14.85397Z","iopub.status.idle":"2022-03-21T17:01:14.878511Z","shell.execute_reply":"2022-03-21T17:01:14.877376Z","shell.execute_reply.started":"2022-03-21T17:01:14.854277Z"},"id":"bnGLeB0_LtH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(real_output, fake_output, d_loss):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    d_loss.append(total_loss)\n    return total_loss","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.88156Z","iopub.status.busy":"2022-03-21T17:01:14.8798Z","iopub.status.idle":"2022-03-21T17:01:14.895039Z","shell.execute_reply":"2022-03-21T17:01:14.894192Z","shell.execute_reply.started":"2022-03-21T17:01:14.881503Z"},"id":"GnZ9x59bLtH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator_loss(fake_output, g_loss):\n    fake_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n    g_loss.append(fake_loss)\n    return fake_loss","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.897401Z","iopub.status.busy":"2022-03-21T17:01:14.897055Z","iopub.status.idle":"2022-03-21T17:01:14.910447Z","shell.execute_reply":"2022-03-21T17:01:14.909703Z","shell.execute_reply.started":"2022-03-21T17:01:14.897353Z"},"id":"pvt697zkLtH_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.912734Z","iopub.status.busy":"2022-03-21T17:01:14.912125Z","iopub.status.idle":"2022-03-21T17:01:14.927244Z","shell.execute_reply":"2022-03-21T17:01:14.926223Z","shell.execute_reply.started":"2022-03-21T17:01:14.91268Z"},"id":"58LhymTSLtH_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a callback that periodically saves generated images","metadata":{"id":"puaQCbHtLtH_"}},{"cell_type":"code","source":"class GANMonitor(keras.callbacks.Callback):\n    def __init__(self, num_img=3, latent_dim=latent_dim):\n        self.num_img = num_img\n        self.latent_dim = latent_dim\n\n    def on_epoch_end(self, epoch, logs=None):\n        start = time.time()\n        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n        generated_images = self.model.generator(random_latent_vectors)\n        generated_images *= 255\n        generated_images.numpy()\n        for i in range(self.num_img):\n            img = keras.preprocessing.image.array_to_img(generated_images[i])\n            if cenv == 0:\n                 img.save(f\"{gen_img_dir}/generated_img_%03d_%d.png\" % (epoch, i))\n            if cenv == 1:\n                img.save(f\"{gen_img_dir}/generated_img_%03d_%d.png\" % (epoch, i))\n    \n        # Save the model every 15 epochs (WAS 15)\n        if (epoch + 1) % 2 == 0:\n          checkpoint.save(file_prefix = checkpoint_prefix)\n\n","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.929356Z","iopub.status.busy":"2022-03-21T17:01:14.92906Z","iopub.status.idle":"2022-03-21T17:01:14.945248Z","shell.execute_reply":"2022-03-21T17:01:14.944502Z","shell.execute_reply.started":"2022-03-21T17:01:14.929323Z"},"id":"8jTG8X3xLtH_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Restore checkpoints if they exists**","metadata":{}},{"cell_type":"code","source":"checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=create_generator(),\n                                 discriminator=create_discriminator())","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:14.947348Z","iopub.status.busy":"2022-03-21T17:01:14.946615Z","iopub.status.idle":"2022-03-21T17:01:15.106593Z","shell.execute_reply":"2022-03-21T17:01:15.105942Z","shell.execute_reply.started":"2022-03-21T17:01:14.94729Z"},"id":"QwKJcZWrLtH_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if(os.path.exists(checkpoint_restore_directory)):\n    print(\"A checkpoint was found!\")\n    ckpt_exists = True # NOT RESTORING FROM CHECKPOINTS\nelse: \n    print(\"Checkpoint was not found!\")\n    ckpt_exists = False","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:15.115013Z","iopub.status.busy":"2022-03-21T17:01:15.114411Z","iopub.status.idle":"2022-03-21T17:01:15.129338Z","shell.execute_reply":"2022-03-21T17:01:15.128285Z","shell.execute_reply.started":"2022-03-21T17:01:15.114974Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if ckpt_exists == True and restore == True:\n    epochs = 16\n    chkpt_restore_path = tf.train.latest_checkpoint(checkpoint_restore_directory)\n    print(chkpt_restore_path)\n    num_ckpt = chkpt_restore_path[-1:]\n    checkpoint.restore(chkpt_restore_path)","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:15.131299Z","iopub.status.busy":"2022-03-21T17:01:15.130545Z","iopub.status.idle":"2022-03-21T17:01:15.141823Z","shell.execute_reply":"2022-03-21T17:01:15.140815Z","shell.execute_reply.started":"2022-03-21T17:01:15.131254Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if ckpt_exists == True and restore == True:\n    if use_tpu == 'y' or use_tpu == 'Y':\n        with tpu_strategy.scope():\n            gan = GAN(discriminator=checkpoint.discriminator, generator=checkpoint.generator, latent_dim=latent_dim)\n\n            gan.compile(\n            d_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n            g_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n            loss_fn=keras.losses.BinaryCrossentropy(reduction = tf.keras.losses.Reduction.NONE),\n            )\n\n    else: \n        gan = GAN(discriminator=checkpoint.discriminator, generator=checkpoint.generator, latent_dim=latent_dim)\n\n        gan.compile(\n        d_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n        g_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n        loss_fn=keras.losses.BinaryCrossentropy(),\n        )\n\n    gan.fit(\n      dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n    )","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:15.143508Z","iopub.status.busy":"2022-03-21T17:01:15.143254Z","iopub.status.idle":"2022-03-21T17:01:15.155214Z","shell.execute_reply":"2022-03-21T17:01:15.154484Z","shell.execute_reply.started":"2022-03-21T17:01:15.143478Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the end-to-end model","metadata":{"id":"_Bn3n_AaLtIA"}},{"cell_type":"code","source":"if restore == False:\n    epochs = epoch_t  # In practice, use ~100 epochs\n\n    if use_tpu == 'y' or use_tpu == 'Y':\n        with tpu_strategy.scope():\n            gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n\n            gan.compile(\n            d_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n            g_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n            loss_fn=keras.losses.BinaryCrossentropy(reduction = tf.keras.losses.Reduction.NONE),\n            )\n\n    else: \n        gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n\n        gan.compile(\n        d_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n        g_optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Was 0.0001\n        loss_fn=keras.losses.BinaryCrossentropy(),\n        )\n\n    gan.fit(\n      dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n    )","metadata":{"execution":{"iopub.execute_input":"2022-03-21T17:01:15.156898Z","iopub.status.busy":"2022-03-21T17:01:15.156515Z","iopub.status.idle":"2022-03-21T17:03:41.125017Z","shell.execute_reply":"2022-03-21T17:03:41.123751Z","shell.execute_reply.started":"2022-03-21T17:01:15.156848Z"},"id":"7atjQsdbLtIA","outputId":"201f7c7d-f6ef-487d-9843-51ef8f267c67","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if restore == True and ckpt_exists == False:\n    print(\"Restore checkpoint cannot be located\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in dataset:\n  i = rd.randint(0,26458)\n  plt.imshow((x.numpy() * 255).astype(\"int32\")[0], cmap='gray')\n  break","metadata":{"execution":{"iopub.status.busy":"2022-03-21T17:03:41.126072Z","iopub.status.idle":"2022-03-21T17:03:41.126986Z","shell.execute_reply":"2022-03-21T17:03:41.126767Z","shell.execute_reply.started":"2022-03-21T17:03:41.126741Z"},"id":"IWm3DeULK_BH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}