{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de546011",
   "metadata": {},
   "source": [
    "# Conditional GAN\n",
    "\n",
    "Used to generate new training data for the ransomware families to overcome the skewed distribution of training data towards the benign samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176d8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d338ac",
   "metadata": {},
   "source": [
    "**Change parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b44d3f",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d37ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Color mode\n",
    "ch = 'grayscale'\n",
    "\n",
    "# Image size\n",
    "iw, ih = 64,64\n",
    "im_size = (iw,ih)\n",
    "\n",
    "# Latent dim size\n",
    "latent_dim = 128\n",
    "\n",
    "# Number of Epochs\n",
    "epoch_t = 1000\n",
    "\n",
    "# Computation environment: Kaggle (0) or Local (1)\n",
    "cenv = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "785911e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "is_cuda_gpu_available = tf.config.list_physical_devices('GPU')\n",
    "print(is_cuda_gpu_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9f4387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd651cb4",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd315bc2",
   "metadata": {},
   "source": [
    "Automatic notebook preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50855d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(ch == 'rgb'):\n",
    "    chnum = 3\n",
    "elif(ch == 'grayscale'):\n",
    "    chnum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "193e04b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 matches(es) found\n",
      "--------------\n",
      "New folder name: cgan-local-v017\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "if cenv == 1:\n",
    "    file_exists = []\n",
    "    vnum = 1\n",
    "    dir = \"C:/Users/Max/Documents/GitHub/conditional_gan\"\n",
    "    for files in os.listdir(dir):\n",
    "        if \"cgan\" in files:\n",
    "            try:\n",
    "                vnum = max(vnum, int(files[-3:]))\n",
    "            except: \n",
    "                continue\n",
    "            new_vnum = vnum + 1\n",
    "            file_exists.append(True)\n",
    "        else: \n",
    "            file_exists.append(False)\n",
    "    # If this is the first notebook you want to save, a new folder will be created with version #001\n",
    "    if sum(file_exists) == 0:\n",
    "        new_vnum = 1\n",
    "        print(\"No matches found\")\n",
    "\n",
    "    else: \n",
    "        print(f\"{sum(file_exists)} matches(es) found\")\n",
    "        print(\"--------------\")\n",
    "\n",
    "    # Print new folder name\n",
    "    print(f\"New folder name: cgan-local-v{new_vnum:03}\")\n",
    "    print(\"--------------\")\n",
    "    \n",
    "    # Create new folder with the name of the notebook and the version number\n",
    "    new_dir = f\"C://Users/Max/Documents/GitHub/conditional_gan/cgan_checkpoint-local-v{new_vnum:03}\"\n",
    "    os.makedirs(new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30853b",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d54d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cenv == 1:\n",
    "    path_root = \"C:/Users/Max/Documents/image_data/data_original\"\n",
    "    path_save_imgs = f\"C:/Users/Max/Documents/image_data/cgan-ckpt-local-v012\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16291bdf",
   "metadata": {},
   "source": [
    "**Create Conditional GAN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250f6a3",
   "metadata": {},
   "source": [
    "Calculate number of input channel for Gen and Disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c8c4b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 11\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + 10\n",
    "discriminator_in_channels = chnum + 10\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5518b3",
   "metadata": {},
   "source": [
    "# Creating discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5807858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((iw, ih, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d69a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        layers.Dense(8 * 8 * generator_in_channels),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((8, 8, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f2b6070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        6400      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 375,681\n",
      "Trainable params: 375,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8019d328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8832)              1227648   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 138)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 16, 16, 128)       282752    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 1)         6273      \n",
      "=================================================================\n",
      "Total params: 2,041,217\n",
      "Trainable params: 2,041,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1fa8cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[ih * iw]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, iw, ih, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e70546",
   "metadata": {},
   "source": [
    "**Optimizers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa94c67",
   "metadata": {},
   "source": [
    "**Checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf8cba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers\n",
    "d_optimizer=keras.optimizers.Adam(learning_rate=0.0003)\n",
    "g_optimizer=keras.optimizers.Adam(learning_rate=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af608a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        # Save the model every 5 epochs \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "          checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b649da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cenv == 0:\n",
    "    checkpoint_dir = '/kaggle/working/checkpoints'\n",
    "if cenv == 1:\n",
    "    checkpoint_dir = f'C:/Users/Max/Documents/conditional_gan/cgan-local-v008/ckpt-128'\n",
    "    \n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=g_optimizer,\n",
    "                                 discriminator_optimizer=d_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c715c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x27ad2dc68b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db7c93",
   "metadata": {},
   "source": [
    "# Training C-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2338e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=checkpoint.discriminator, generator=checkpoint.generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=checkpoint.discriminator_optimizer,\n",
    "    g_optimizer=checkpoint.generator_optimizer,\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6263e9",
   "metadata": {},
   "source": [
    "# Create new training images using the Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a0397cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first extract the trained generator from our Conditiona GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 150  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = tf.cast(first_label, tf.float32)\n",
    "    second_label = tf.cast(second_label, tf.float32)\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "780b224a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'C:/Users/Max/Documents/image_data/cgan-ckpt-local-v012'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16928/1068588373.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create new directory for saving folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_save_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\master_thesis\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'C:/Users/Max/Documents/image_data/cgan-ckpt-local-v012'"
     ]
    }
   ],
   "source": [
    "# Create new directory for saving folder\n",
    "os.makedirs(path_save_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0de5e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve class name based on number\n",
    "classes_list = list(os.listdir(path_root))[1:]\n",
    "num_classes = len(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44079f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reveton.A'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "36b3e346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51754ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images = interpolate_class(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8453e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images *= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34523c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27c823e3ee0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoP0lEQVR4nO2da6xdxZXn/+tesPED47cxNmAIhthAMGAIBEIMDB1PhECRQqtbYoQiRlYmmVFa05MMzCij6ZFGYjJSq+fDaBTTzXSSZrpNukl4hPCycdIgAjHhjTE24IDxxcYGY4ONX3fNh3vO5r8Xt9ats33uPrb3+knWrXOqdtXatXf5rFWrapWoKoIgOPrp67UAQRDUQwz2IGgIMdiDoCHEYA+ChhCDPQgaQgz2IGgIhzTYRWSpiKwTkQ0icku3hAqCoPtIVT+7iPQDeA3ANQA2AfgdgD9V1Ve6J14QBN3imEO49mIAG1T1DQAQkX8AcD2A5GCfNGmSzpgxAwCwffv2Ul5/f3+RnjhxYjLv448/LtLTp08vlTt48GBSWK5j3759RfqEE05I1rF79+5kfZ988kmRnjBhQimP6z/22GNLeccck+7yjz76aFh5d+3aVSrX7kMA+OCDD0p5IlKkZ82aNWzdAPDhhx8Wadvf27ZtK9IzZ84s0vv37y+VO3DgQJG299nX96nSyPLz91be4447Likjlzv++ONL5fi6HTt2lPKmTJlSpPm5cP8C/nPn+x43blwpj/uA742/B4CxY8cWafsDy8+G3w++BgAGBweTee33cceOHdi9e7dgGA5lsM8B8DZ93gTgi94FM2bMwA9/+EMAwE9+8pNS3qRJk4r0pZdeWsqbOnVqkX766aeL9De/+c1SOX7x7UvFL8jbb38q9rXXXlsqxy/LM888U8rjOl977bUi/cUvlm/7D3/4Q5HmAQeUByo/PAB48sknizT3x+rVq0vlvvWtbxXpn/3sZ6U8flm+973vFenHH3+8VO6Xv/xlkf7yl79cyrvjjjuK9Le//e0ivXnz5lI57u8TTzyxlMeD4rHHHivSdqDyoPv85z9fynvggQeKNP9nsmTJklI5vu4Xv/hFKe+GG24o0m+99VaRtv/J79y5s0g/++yzpTx+XxYtWlTK27JlS5EeP358kX7//fdL5ebPn1+k+T8doPxs+D+nM844o1Ru7969RfqUU04p5b3++usAgB/96EdIcSg2+3D/e3zGJhCRZSKyRkTWcIcGQVAvh/LLvgnAyfR5LoDNtpCqLgewHADmzZun7V/Oc889t1TujTfeKNL8ywiUVaLTTz+9SPMvIQCsX7++SPP/kED5F3ZgYKBI2/9lWSVkkwEo/+/PaiVrG0DZRFm3bl0p76KLLkIK1mBYlbTawZo1a4r02rVrS3kLFy4s0vzL+5vf/KZU7uabby7S/IsHlFX33/72t1ltWVOAf81PPfXUIs2/kgCwZ8+eIs3PxdbJ74T91eRfc6vePvzww0WazRP7y87vn9UK+f177rnnSnn8zFg9t2bC1q1bi7Q1Yfk9u+qqq4q0NfmeeuqpIs3vOvBpv1pzjTmUX/bfAZgvIqeJyBgAfwLg3kOoLwiCUaTyL7uqHhCRfwvgIQD9AO5Q1Ze7JlkQBF3lUNR4qOoDAB4YsWAQBD2nsp+9CrNnz9a2rfi5z32ulPerX/2Ky5Xy2K7mctbu51nlV14pewB5hn/Dhg1Fmu1foDx7u2LFilIe22FsG5522mmlcmwPsm0PlO3QBQsWlPJuv/32Is2z8ZdffnmpHM9M2/p5zoHtXNsWe0PmzJlTyps8eXKR5tnzK664olSO+87a0fx82X5nbwRQtnPnzZtXyuPZZ35m1tXJz3bTpk2lvN///vdFmuctbrzxxlI5tqOt643t4/POO6+Ux8+JnwXPvgPACy+8UKTtHAl7gKZNm1akv/KVr5TKsXvQekbacx8rVqzAli1bhnW9xXLZIGgIMdiDoCHUqsYvXLhQf/rTnwL4rHuN1W6rRn3jG98o0k888USRtiu6WL21ZgK7Z1htuuSSS5Jy2EUevJCG3WHsfgHKLiq7yo/dd6ym2rInnXRSkebVerY9q85xn7A5Yd2I7F6zbrONGzcWaVb/rYuR3VW2r55//vkifcEFFxTpk08+uVSO27Z99dJLLxVpfk+t+cYLW84555xSHrvKXnzxxSJtF26xW866OtmMfPnl8hw0m0Ash3Xp8vtu15ucffbZRfrMM88s0g8++GCp3JVXXlmkrYut7Xq78847Q40PgqYTgz0IGkIM9iBoCIfkZ++UnTt34tFHHwXwWZudl01ali9fXqTZxWNtPN64Yt0WbJOxzWd3jXGddkkiL6PkZbB2Iwzbq9dff30pb8yYMUXa2tF8Hbtx2Ia27dklw0uXLi3SbF/OnTu3VI7dUHbHGtuebF/ed999ybbYNQaUbWd+1tbt9O677xZpnqewdfIyY5YPKL87q1atKuWx/LzxyC5F5bbsnAA/C7vrjd2P7PZ87733SuV4roLvGSi/c2zr2/kNfr8vvPDCUl7b/WuXCzPxyx4EDSEGexA0hFpdb9OmTdOvfvWrAD7df9uGVUm7QorVL14hZXcWMXbXG+9cYveUvX9WEa16yyvLeP+2XcXG92bdZqzq8U4ooLxCit1mVjXj/rHqItfBKqetg91+nguT5bCr5FgVZlceUO7HVIAHoOxmZRPHts118L5xoHzPNoAJq8V8n3bVYCqABFB21do87kd+LtY1xivjrPnG7xLfszVX2OS0cQHa/bNhwwbs2bMnXG9B0GRisAdBQ6hVjR87dqy2Z4WtmsMbCuzmfs5jlcpT460pwPHMvHhgrAZa9ZbVR54BtnLY6xhW+a1KyHVyno1nxmq2XYXHajKrxVZ95uu8uHB8b3ZlI+fZe+HP3B9WVed7tqYGq+DWVGK82G+sFqf617Zl4batmcDt8Xtq32/uKxuOjE07rs+ubGT1n80CZvPmzdi7d2+o8UHQZGKwB0FDiMEeBA2hVpt9zJgx2nYzWDdOyjUGlO0rLzY834u1yfg6z9bn66wdl5LD2pNsk1l72Otvvs6zE1l+rz7Os3Kk2vLybFu2zhw5qvYVX+eVszKmbH37Pfexd1+2fu/ecmXk9rx3mPPs3Ee77d27d+PgwYNhswdBk4nBHgQNodaNMAcPHixcZ1Y19dRsVvFz1SYPT4X13GYpVcy6UjwZvesYVu26obZ65o+9pkq/euqtVzffm9dXjO23XHm9cp65kque53w/HFXModQ757Ubv+xB0BBisAdBQ4jBHgQNoVabXVULm9i6FdhOtzvFPBuVYdvKs73ZbWGXV+a6XXJdXp49711n5apCN2TMtVdz7WhvniLXZveoas/nugdz6+iE1LP2+sPmee7kNiP+sovIHSKyVUReou+misgjIrK+9XeKV0cQBL0nR43/WwBLzXe3AFipqvMBrGx9DoLgMCZrBZ2IzANwv6qe0/q8DsASVR0QkdkAVqvqWSPV09/fr+0dPlbNZvXZuolYjepEDXTkSLbFdVRVK3PVYE9drKJK27K5LsCq5Lqrck2vXDpxjVWpsxP1uRv9yO++5xbOqePgwYNQ1a6uoJulqgMA0Po7c4TyQRD0mFGfoBORZQCWtdKj3VwQBAmqDvYtIjKb1PitqYKquhzAcgDo6+vT9syjt4Iud/ZzmLaKtKducVu5M9ZV2+rkulw5uqH6doOqfVelXG4duSZPlVVxI+VVJfW+d2L+5MhVVY2/F8BNrfRNAO6pWE8QBDWR43r7ewBPAjhLRDaJyM0AbgNwjYisB3BN63MQBIcxte5n7+vr03b8NG/RSFU1nsmdUa2qIndj9raqKtmNWfCjlapq/JHWV6nNS4ODg8nZ+NpX0LUH+Wi4T2xb3c6rU4666zxa6cautCOBnPETa+ODoCHEYA+ChlCrGs/kBjs4EjiSZT/aaMqzsPeZM88Vv+xB0BBisAdBQ4jBHgQNoWc2uxfH/Eijbp/t0epLP9J934c78cseBA0hBnsQNITa1fi2+m7Vdi+gRBWqqoRVlqJakyRXfhs3LBW8wpMx9z69cl5buYE+vL7idG6s/OHay7ku16V7NJmRucQvexA0hBjsQdAQalXjRaRQC63a5MWgq0LVXWNVdkblqrC2bK7q6B3PNBphjnPj2HWrvdQ13d6ByHghp49WL0D8sgdBQ4jBHgQNIQZ7EDSE2m329rFPNlJNN447qoJ1wbDt5s0deMdEpeKAj1RHKmZ4J0cqp/Jy27JlPRedd5/ssstty5PRc0t6z6JKUJQjcSVfW+Y4sjkIghjsQdAUag04KSLaVu86CV5RRUZPffNWXOW22406vBV0XP+4ceNK5Xbv3p2sM+WWs2157js+5ZZP1LV1sIzWDPPMkJy2bP186u/evXuT9dn+Zpm5rT179iTr6GS14Wget9VJHe37HI3jn4IgOMKIwR4EDSEGexA0hNpdb3y0LNM+PAIA9u3b95nrhqOTs7D48/jx44u0tX/ZxssN6sf2pKV9RHUbtkvHjh1byuM+4SOtrS3LtqeVkevctWtXUka2h21/831yW7lHTAPAxIkTizTb2LYP2db3bPvjjz8+KS/fm62D+5TtdM/NZ+cm+FnYvNzdg7lzGFWPJO9K3HgROVlEHhORtSLysoh8t/X9VBF5RETWt/5OGbG1IAh6Ro4afwDAn6vqAgCXAPiOiCwEcAuAlao6H8DK1ucgCA5TRlTjVXUAwEArvUtE1gKYA+B6AEtaxX4MYDWA/+jVJSKFum5VWFZfWG3qBFZlrLqVUudsudz6Oe2p8Z7aZ91V3CfeqrMTTjihSH/88cdJGSdPnlykrbnCpoy3+o3dfjt37iyV43vh+oDPmh5t2CwAyn1g6+D3gE0Baxrxs7V1sCnDqvukSZNK5ey9MVV2SXaiqqeuq3oWYIqOJuhEZB6A8wE8BWBW6z+C9n8IMztuPQiC2sieoBORiQD+CcCfqerO3DXHIrIMwLJWuoqMQRB0gaxfdhE5FkMD/U5Vvbv19RYRmd3Knw1g63DXqupyVV2sqotjsAdB7xjxl12GRujfAFirqn9JWfcCuAnAba2/92TUVdhbbEsBvo1aJTKLt7uKbWzrAmS72bp4GK7D2onsdvLsM7apgbL78Z133inS1j7z3GFcdsKECUX6lFNOKZXbtGlTkfZ2jbFNPWVK2eHCfWfnH0488cQizf1obWPOs3LwfXquMW7LLoPlOQ3uG1uO67Ry5O7M43vxlkLbOZ7UO23ntbz3MYccNf4yAP8KwIsi8lzru/+EoUF+l4jcDOAtADcckiRBEIwqObPxjwNI6d9Xd1ecIAhGi1p3vfX19WlbNenEvZYKIuGpsLm73jw3joXdUFy/VbdYVbUuntQqOQCYOfNThwar2RbPbcYqIqt99jmzHF68ds+E4nLeCj0vMAnXweYPkF655r2z1hXJ1+Wu1rPuwdx+rBIgEyj3Va7LzpZr3+f+/fsxODgYu96CoMnEYA+ChtCzuPF2ZtGLG5+KdVY1zjir3VbNZt5///3SZ54t57Z4RRtQln/q1KlJGT/66KNS3rvvvjvsdfY+eWbdqq2bN28u0jx7bmef+bNVW1NBNOwqPFbdbT9ynVu2bEm25cFqPMthZ7pnzJhRpN9+++1SHved96z53qxZ483UpwJp2Pv0Vk6m3n1vNt7zNqWIX/YgaAgx2IOgIcRgD4KGUKvrrb+/X9vuK9su22fd2PVmXUFsC/GKK+t645V9NtAj20xsq9ly7Bo7+eSTS3nTp08v0uvXry/lseuN++C9994rlTv33HOTdbA9yPW9+uqrpXKnn356kbZuvg8//LBIT5s2rUjb+QG2S3m+webx3ASv6rPyeqsj+X3xVqfZPH5OLJN3boG3Y9Lm8XXeMd78ntkdgamzCjoJVtG27/fs2YODBw+G6y0ImkwM9iBoCLW63oD8I3QZVslTRwKN1A6rVex2su6vk046KVk/q4SnnnpqkbYuElaRrZrNci1YsKCUxyriqlWrirR1RbI6bd2DvArt2WefLdJf+MIXkMKL+f7WW28VaetiTG0CAdLuTS9euzXf2Dzid8DKO2fOnGFlB4A333yzSHM/WnlzVyValxq77Fgua0Z68e9SrmV29QLld6fKsebxyx4EDSEGexA0hBjsQdAQarfZ2zaVFxvec614O9tyjxBOtQsAW7d+GnDH2kVsQ3Jb27ZtK5Vj15V1V/ES1hdeeKGUxy5BXhLLMdMB4Ne//nWRtss1zzzzzCLNbjO7VPT1118v0tZWZhm9oJLspmQ3H1DuH7Y9bZ+yXLavUnM11h5md559nrzsmPtjw4YNSGHrTwUCBcrvBLvUvIAjNo/7JxWww5az8xbtfo0jm4MgiMEeBE2h1hV0xx57rLbVqg8++KCUl3skL+PJ7u2uOv/884v0unXrSnms6llTg2PG8e6yhQsXlsqxOmdjv7EL5vLLLy/lPfHEE0WaVevt27eXyp1zzjlF+qGHHirlzZo1q0hzEI2LLrqoVI7V7CeffLKUx6u9WF6r7nM5605i1Zefp3223Ffc90B5txzvbLMqrPes2aRiU86qyOyC9Xa2sWvWysJ9Zd9vdol6LjV25XnlLG3Ta/Pmzdi7d2+soAuCJhODPQgaQq2z8YODg4Wa4oXkteSelJm6xtb/yiuvFGm7iYVnmK26yGoVz0zb2fJUAAlb59NPP13K4z5h1d3GZvM2/LCpwTLy7Lstd9ZZZ5XyOIw135tdrcfqsw2LzX3Az8LWweq+ndFnVZjVfVbpAWDHjh1F2qq+bMrws7arAdkTYDdH8Wy/rZ+9C56MXvhylpGfrd0ww/1o5Wi/VzEbHwRBDPYgaAox2IOgIdTqejvmmGO0bX/a4588uzwVV9vb+WODJKSus3XMnz+/SFs3Ea9w44AP1113Xakcr3Cz9bPtZu3Gr3/960X60UcfLdKeHWpX77F7bOPGjUXaurW8AI5sp/OzGBgYKJXzdnlxXmo1HVBeQWcDWvJnL778okWLivTatWtLedw/fJ9eEAr7zPg5WfdjymVs79MLzpIKWGHvk+cwbH+3n9MhBa8QkeNE5GkReV5EXhaRv2h9P1VEHhGR9a2/U0aqKwiC3pGjxu8FcJWqngdgEYClInIJgFsArFTV+QBWtj4HQXCY0pEaLyLjATwO4N8A+AmAJao60DqyebWqnuVd39/fr223hnVrsWpjNzN4x96k4JVkQHklFauVF154Yakcq2J2YwarlamjoIDy5gurzrG7yrrDeBMLx3TzYvLxKjMrP7flbS6yzyIVJMG6gvje7GpDrsPb3MHy5h7FZfvbO8qKXXv8PL0jr3JisLdJHUtl+5Tvzeur3GPL7HvVrvOQj38Skf7WCa5bATyiqk8BmKWqAy1hBwDMdKoIgqDHZA12VT2oqosAzAVwsYicM8IlBSKyTETWiMiaOicDgyAo05HrTVV3AFgNYCmALS31Ha2/WxPXLFfVxaq6OFcFD4Kg+4xos4vIDAD7VXWHiIwD8DCA/wHgKwC2q+ptInILgKmq+n2vrv7+fm27xKxbKxV/uyVDMo9hm8YGWmB7e+7cuUXaBou84IILirSNtc7uQnbDWReJ3aXGsBvHBl/kZaqpYItAOY48u+Fs2VTADqBsf6eO/wXKNrZ3Bp/NSx317D1bayvnHrHsHSvNWDuXYTvam9/InU/y7H6vr1hGWwfLmHK97du3L2mz56yNnw3gxyLSjyFN4C5VvV9EngRwl4jcDOAtADdk1BUEQY8YcbCr6gsAzh/m++0Arh4NoYIg6D49ixvvqVRWzfFUM4bVIev6SMURszutOIDEeeedV8p74403ijQfDWyDJ3DbdlXY2WefXaTtDjBW3Xm1mnUjspngqZXecUSp45DtZ2+Voqeep9x3Vt7cFZHerrHUEdO2LKc9c9C+b55bLnX0lK2fXW/WhOU+4LQtx31g+7H9Dnpu2lgbHwQNIQZ7EDSEWtX4/v7+YpOFVTe8Y51Ss8PezK41E1hFZjXbrgrjeHJeDLorrriiSD/22GOlcnydF5DBqv88y87eBFvOM4G4D1iOTsJus/romVD8XLxAH1zOU9U9k8Tz1ngbXLg9T933Ton1goXwdZ5pxH1q+4CfL9dhn7v37rf7212Bl8wJguCoIgZ7EDSEGOxB0BBqtdlVtbC9rFuBAybY3WYMrzqzq+TYRcXHJgNlW4hdaitWrCiV+9KXvlSkn3rqqVIey8xyWBuaj3N+7bXXSnm82s7auRycknez2XkFvm+7Co/tPK7fC9bg4dmAuUFCc11euXleu57ryTv22ZPDW0WYujcro7e6LjVfZeXgtuw7l+Oejl/2IGgIMdiDoCHUqsaLSKF+8HE7QFlF8VRTdn9ZdZ8DPtjjjlj1Xbp0aZG+++67S+U4BvkZZ5xRynvzzTeLNKvj11xzTancfffdhxQcE83WzzHjWKW3G2tSKjJQVvm9WHusSlqVNrWiqxMV3HNDMd7qulR7nnrr1eGp+J4K7rmFU/1j+9vblJRSwa28rLrba3K2j8cvexA0hBjsQdAQYrAHQUOoPW582+a27iSO8+4Ff/DinbP9ZJepzpkzp0izvWPtIl5Wa4/dZdfb9OnTi7S9F7bLuRxQdv/YXW8sF++Wmz17dqkcu/OsvZ2y/3LdZEC+ne6VS7nsRvt9y7X7R6O9qn2VmtPwdgjaZbvtXZ0fffQRDhw4EEc2B0GTicEeBA2hVjV+zJgx2l7lZuOde3JYlaWNt4PKxoNndZdVdxuD7gc/+EGRtm65VatWDVvHggULSuXYzWfvk2PXWRPCHl00nOxAOQa+NSEY70gtz12VU5+9rqopEJRJuT0t1oRtmwJeDLr4ZQ+ChhCDPQgaQq0r6AYHB4uVc/aoH+9oHhtEIgWri/Z0U57h5+OZrIp8++23F2mOOWdl5pV2diWfd8QTY2fIOVS1F3iC1f/clVTdmHEfqc7cvCCP3NiLwKdmmRtq/ZAlCoLgiCAGexA0hBjsQdAQanW98fFPNp464+0Y8uwYdtFNmzatlMfHJLFNPWnSpFI57g+7go6vY/ud3WmAfzwTrxS0ATZefvnlIp0KlGjlYDecxTsK2HNbBkce7eerqlDVQ3O9tY5tflZE7m99nioij4jI+tbfKSPVEQRB7+hEjf8uAF71cQuAlao6H8DK1ucgCA5TstR4EZkL4McA/juAf6+q14rIOgBLVHWgdWTzalU9y6unv79f2+qvdad5G/9zYVXVCxbAKr6nZltTg9VnVq050ATgnz7KareNC86ypOLc2892FV7VOGvB0cOhqvF/BeD7ANh4nKWqA63KBwDMHOa6IAgOE0Yc7CJyLYCtqvpMlQZEZJmIrBGRNfFrEgS9I2cF3WUArhORrwE4DsAkEfk7AFtEZDap8VuHu1hVlwNYDgyp8V2SOwiCDsk5n/1WALcCgIgsAfAfVPVGEfmfAG4CcFvr7z0ZdRW2orWpvSWxVXZQeeeB8ZyAjV/P9re1h9kGPumkk4q0te15ua+tg+/TBqXgst68BZfzAnhwH9idg7nHLQdHD4eyqOY2ANeIyHoA17Q+B0FwmNLRRhhVXQ1gdSu9HcDV3RcpCILRoNYVdH19fdp2N1k1Nfd4H3dXjxOfnK9jVd3Gr2es6ssqM+d56j4fSQWU487ZwBksP5sGto533nmnSNt+ZDXeO+aYy9n+9o5zDg5PurqCLgiCI5sY7EHQEGoNXgF8qhZ6s81VTQtWOT2Vno+XsqvMWD23K+N4g4t3mizXaY+y4phxVka+b/YSsNoO+HHK+Igg7wgm/uzNxkecudGnG/3Yfp7euIpf9iBoCDHYg6AhxGAPgoZQq+tNRLTtvqrqXuuSHMOmR2o7dZ1Xh7Xn2Wa3fZBy541G0MeqRxUFhyfheguCoCAGexA0hNpdb6xu9Aqv7dSGGaA7G3L4s93EklLdu6GOe9fVffJpkEcnzyXnmcUvexA0hBjsQdAQYrAHQUM4bFxvvbITc48rBsoyestxc3ffdWOZqle/V0fu7sHY9XbkEa63IGg4MdiDoCHU7nprM9o7qGzgiVQMdS9WXTfcWl6sPavuc1mW19bhmQIMq+BW3lzzJVbTHT54z6L9LnlmV/yyB0FDiMEeBA2hZ2r8aOMdfeSpQ7mzz1yuEzXb20CTUru9GHHdMDW8vE68FUE1urFaMue9jV/2IGgIMdiDoCHEYA+ChlCrzd7X11ccRWwDMVY9prmTttt4Nmn7SGngs0dDpWwmay9x0EfrXuP7tLa+N8+QIndnlG2L5ch1g1YN9FFnMJIj0T1Yl8xZg11ENgLYBeAggAOqulhEpgJYAWAegI0A/lhVPxgdMYMgOFQ6UeOvVNVFqrq49fkWACtVdT6Ala3PQRAcpmRthGn9si9W1W303ToAS+jI5tWqepZXT19fn7bVZKu2c+CGqqvrct1EvLrOqs7eJpAq6qK3ks87WZXTtpyngue65Zhu9Pdob5jphqp+pKv7Ht2MQacAHhaRZ0RkWeu7Wao60GpgAMDMQ5Q3CIJRJHeC7jJV3SwiMwE8IiKv5jbQ+s9hWStdQcQgCLpB1i+7qm5u/d0K4OcALgawpaW+o/V3a+La5aq6mGz9IAh6wIi/7CIyAUCfqu5qpf8IwH8DcC+AmwDc1vp7TycN22OOqwZaSGFdXlw/u9fskc25S0W5fs+9lrv7ztbDctj5jdTuONue7eNUW97x2V45L0gHk2sr2/pS8xbefXnuwVw34mgE4PT6wJtD6rR+T9YcNX4WgJ+3KjsGwP9T1QdF5HcA7hKRmwG8BeCGSlIGQVALIw52VX0DwHnDfL8dwNWjIVQQBN2n1hV0qppUwcaMGVOk+YikTusfLg2UVcKPP/64SOfuPPPwVC/PNea5/bx4d95qQ88tx+S6yqoGx8iNhZfbFtOJCl6l/tHAa3u0V4+2ibXxQdAQYrAHQUOIwR4EDaH2uPFt+7Mb7rUR2krW70WLYbdWrovHi1TjyeG5mjhty3mumpQd7e2wy42m08kzSwXuzL3Gkuuy89yITK6LrltUOUPQ9oc3z9KuY3BwMOLGB0HTicEeBA2h8Uc2W3WOVazclVSeeuvFpffUeL7Oqm+eqya1qq1qf+eqt54Ls0pbXv1eDHyvT6u65bqxWy63P7xdizmr8NxVk1kSBEFwxBODPQgaQu1qfFudGe3jn3LppK3cjR9cJ8ejA/xZdk8dTdXvbaqoqoKn8jqJgV/lJNjclYK2HPdx7kaSbgTAsPV0Ywt3VVMm537ilz0IGkIM9iBoCDHYg6Ah1L6C7nBwvXUba0NWXQVVZcedJ4vXVpUdZp7N7l2Xe1+e+847StsL5sEcru9cNwKqtvvgwIEDsYIuCJpODPYgaAhH7ZHNVamyyspTb73VbtYt521OSeGtGMstNxpBIzw3US7sRvRMEq9cFRPCWxGZ298euXEJvT5NnWngxk3sSMogCI5YYrAHQUOIwR4EDaFnNnsvAwN67il243j2mLc7yVsu67mG2JZjW99bRuodF807oDpZzprrvvOWqabi6nux562MXOfxxx9fpDlgqL1u+vTppbxt24rjCd1gnyk3n82z5B4FznmdnC+Yoso8SPyyB0FDiMEeBA2hZ8ErvOOQRxtPbaoSd91zkUycOLGU9/777yfrT8Wg62TlGh9ttW/fvmS53PjtXlvjx48v0h9++GGyjtx78fLGjRtXpHft2pWUafv27Uk5cuOzW9fY3r17k2WrHIttzQQ2UXbs2FGkO1lt2O4fe5wZk/XLLiKTReQfReRVEVkrIpeKyFQReURE1rf+TsmpKwiC3pCrxv8vAA+q6ucxdBTUWgC3AFipqvMBrGx9DoLgMGXEjTAiMgnA8wBOVyosIusALFHVgdaRzatV9awR6tK2CuNteqiyKmmYtkqfU6qpt4nFqnMpFd+qZV4I59wjk1LtWpm9fuQjtawqmrt5JDcwBLcF+J4AJjdENKfHjh1bKsfHhVk5+L69wCHebLkXBjrXe+PBbbP8Vo6cMNz79+/H4OBg5Y0wpwN4D8D/FZFnReSvW0c3z1LVgZYQAwBmZtQVBEGPyBnsxwC4AMD/UdXzAXyMDlR2EVkmImtEZE1FGYMg6AI5g30TgE2q+lTr8z9iaPBvaanvaP3dOtzFqrpcVRer6uJuCBwEQTWygleIyD8D+Nequk5E/iuACa2s7ap6m4jcAmCqqn7fq6evr0/bNom36iz32KVce8+WzYm/DfjuQbatbFvs8vKOXbJ5bB97q+TYZrXuNS/efKqctam5D/g+9+zZk6zD2rKpwJfW3vbmSGx7qbY8m5qfDddvn5l3THiVwJ22fr5ve1+p3Wy2Di8IabsPPvnkk6TNnutn/3cA7hSRMQDeAPBNDGkFd4nIzQDeAnBDZl1BEPSArMGuqs8BGE4Nv7qr0gRBMGrUGoOur69P26qqVbf4s1Vvc1c+mbZKn1Nqa24gAStXrjlh83glmFUdu1F/yiVoTaOUWwtIH4HluQqty4tVVa7flvOO2+JnwXm8cg8ob4yxzzNl1tjn7PU3m1feqkRvZWbu8VUsv22L83ilJABMmDBkWW/btg379u2LGHRB0GRisAdBQ4jBHgQNofZdbyn7MzfAQa4bxNo0KRvS1nHCCScUaRskge1eLwghu1ms7cZyTJs2rZTHSzt5Z5fXH7ZtnhNgm4/vy9bvue88dw+3ZWWcOnVqkeadWJ77zpKy020dkydPLtJ2WTCXZTvd2vZe8Aqu0+5i5Dxvx6QXLDL1vth3mHfH2WfW7h/vecUvexA0hBjsQdAQ6j7+6T0AfwAwHcC2EYrXQchRJuQoczjI0akMp6rqjOEyah3sRaMiaw6HtfIhR8hxuMvRTRlCjQ+ChhCDPQgaQq8G+/IetWsJOcqEHGUOBzm6JkNPbPYgCOon1PggaAi1DnYRWSoi60RkQyvgRV3t3iEiW0XkJfqu9lDYInKyiDzWCsf9soh8txeyiMhxIvK0iDzfkuMveiEHydPfim94f6/kEJGNIvKiiDzXDqHWIzlGLWx7bYNdRPoB/G8A/xLAQgB/KiILa2r+bwEsNd/1IhT2AQB/rqoLAFwC4DutPqhblr0ArlLV8wAsArBURC7pgRxtvouh8ORteiXHlaq6iFxdvZBj9MK2q2ot/wBcCuAh+nwrgFtrbH8egJfo8zoAs1vp2QDW1SULyXAPgGt6KQuA8QB+D+CLvZADwNzWC3wVgPt79WwAbAQw3XxXqxwAJgF4E625tG7LUacaPwfA2/R5U+u7XtHTUNgiMg/A+QCe6oUsLdX5OQwFCn1EhwKK9qJP/grA9wHw7pBeyKEAHhaRZ0RkWY/kGNWw7XUO9uGiZzTSFSAiEwH8E4A/U9WdvZBBVQ+q6iIM/bJeLCLn1C2DiFwLYKuqPlN328NwmapegCEz8zsickUPZDiksO0jUedg3wTgZPo8F8DmGtu3ZIXC7jYiciyGBvqdqnp3L2UBAFXdAWA1huY06pbjMgDXichGAP8A4CoR+bseyAFV3dz6uxXAzwFc3AM5Dils+0jUOdh/B2C+iJzWilL7JwDurbF9y70Abmqlb8KQ/TyqyNCm5r8BsFZV/7JXsojIDBGZ3EqPA/AvALxatxyqequqzlXVeRh6H1ap6o11yyEiE0Tk+HYawB8BeKluOVT1XQBvi0j7GLWrAbzSNTlGe+LDTDR8DcBrAF4H8J9rbPfvAQwA2I+h/z1vBjANQxND61t/p9Ygx+UYMl1eAPBc69/X6pYFwBcAPNuS4yUA/6X1fe19QjItwacTdHX3x+kYOs/weQAvt9/NHr0jiwCsaT2bXwCY0i05YgVdEDSEWEEXBA0hBnsQNIQY7EHQEGKwB0FDiMEeBA0hBnsQNIQY7EHQEGKwB0FD+P8P4ZA9IkaEkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(fake_images[70],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79dfad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images for class: BetterSurf\n",
      "Generating images for class: Eksor.A\n",
      "Generating images for class: Obfuscator.AFQ\n",
      "Generating images for class: Occamy.C\n",
      "Generating images for class: OnLineGames.CTB\n",
      "Generating images for class: Reveton.A\n",
      "Generating images for class: Sfone\n",
      "Generating images for class: VB.IL\n",
      "Generating images for class: Zbot\n",
      "Generating images for class: Zbot!CI\n"
     ]
    }
   ],
   "source": [
    "# Create images for every class and store in seperate folder\n",
    "for i in range(num_classes):\n",
    "    class_name = classes_list[i]\n",
    "    class_dir = f\"{path_save_imgs}/{class_name}\"\n",
    "    os.makedirs(class_dir)\n",
    "    start_class = i\n",
    "    end_class = i+1\n",
    "    fake_images = interpolate_class(start_class, end_class)\n",
    "    fake_images *= 255\n",
    "    converted_images = fake_images.astype(np.uint8)\n",
    "    converted_images = tf.image.resize(converted_images, (64, 64)).numpy().astype(np.uint8)\n",
    "    print(\"Generating images for class: {name}\".format(name=class_name))\n",
    "    for j in range(num_interpolation):\n",
    "        np_array = np.squeeze(converted_images[j], axis=2)\n",
    "        im = Image.fromarray((np_array))\n",
    "        im.save(f\"{class_dir}/gen_imgs_{class_name}_{j}.png\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96644c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
